
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>AI Act Beslishulp</title>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@1.0.2/css/bulma.min.css">
        <script src='https://unpkg.com/mermaid@11.0.2/dist/mermaid.min.js'></script>

        <!-- Custom Styles -->
        <style>
            /* Tooltip styling */
            .mermaidTooltip {
                display: none; /* Hides any remaining tooltips */
            }

            /* Modal centering and responsiveness */
            .modal.is-active {
                display: flex;
                justify-content: center;
                align-items: center;
            }

            .modal-content {
                max-width: 80vw; /* Makes modal responsive to screen size */
                max-height: 80vh; /* Ensures modal fits within the viewport */
                overflow-y: auto; /* Allows scrolling inside modal if content is too long */
                position: relative;
                padding: 20px;
                background-color: white;
                border-radius: 10px;
            }
        </style>
    </head>
    <body class="has-background-white-ter">

        <!-- Modal -->
        <div id="model1" class="modal">
            <div class="modal-background"></div>
            <div class="modal-content">
                <div id="modelcontent1"></div>
            </div>
            <button id="modealclose1" class="modal-close is-large" aria-label="close"></button>
        </div>

        <!-- Diagram (placeholder) -->
        <pre class="mermaid has-background-white-ter">
            ---
title: Beslishulp AI-verordening
---
%%{
	init: {
		"theme": "base",
		"themeVariables": {
			"primaryColor": "#007bc7",
			"primaryTextColor": "#000000",
			"primaryBorderColor": "#007bc7",
			"lineColor": "#154273",
			"secondaryColor": "#CCE7F4"
		}
	}
}%%

flowchart TB
	classDef secondaryStyle fill:#FFFFFF,stroke:#39870c
	q-1.1(("1.1: Algoritme"))
click q-1.1 callback "Bevat de (beoogde) toepassing een algoritme?"
	q-1.2(("1.2: Verantwoordelijkheid"))
click q-1.2 callback "Ontwikkelen jullie de toepassing in eigen beheer of is/wordt deze ontwikkeld door een andere partij?"
	q-1.3(("1.3: In gebruik"))
click q-1.3 callback "Is de toepassing al in gebruik of niet?"
	q-1.4.1(("1.4.1: AI-systeem"))
click q-1.4.1 callback "Is jouw (beoogde) toepassing een AI-systeem?"
	q-1.4.2(("1.4.2: GPAI-systeem of GPAI-model"))
click q-1.4.2 callback "Is jouw (beoogde) toepassing een AI-model voor algemene doeleinden of AI-systeem voor algemene doeleinden?"
	q-1.5(("1.5: Uitzonderingsgrond AI-verordening"))
click q-1.5 callback "Is er voor de (beoogde) toepassing sprake van een uitzonderingsgrond?"
	q-1.6.1(("1.6.1: Definitie AI-systeem - Beslisregels"))
click q-1.6.1 callback "Is jouw (beoogde) toepassing gebaseerd op door mensen gedefinieerde regels om operaties te automatiseren, waarbij deze regels niet zijn afgeleid uit data of kennis?"
	q-1.6.2(("1.6.2: Definitie AI-systeem - Inferentie"))
click q-1.6.2 callback "Maakt jouw (beoogde) toepassing inferenties?"
	q-1.6.3(("1.6.3: Definitie AI-systeem - Omgeving"))
click q-1.6.3 callback "Kan jouw (beoogde) toepassing de omgeving beinvloeden?"
	q-2.0(("2.0: Tussenscherm"))
click q-2.0 callback "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing."
	q-2.1(("2.1: Verboden AI-systeem"))
click q-2.1 callback "Valt de toepassing onder een van de verboden systemen uit Artikel 5 van de AI-verordening?"
	q-2.2(("2.2: Uitzondering Verboden AI-systeem"))
click q-2.2 callback "Is er sprake van een van de twee uitzonderingen voor verboden systemen?"
	q-2.3(("2.3: Hoog-risico Bijlage I A en B"))
click q-2.3 callback "Is het AI-systeem bedoeld om te worden gebruikt als een veiligheidscomponent van een product dat valt onder de lijst in Bijlage I?"
	q-2.4(("2.4: Hoog risico Bijlage III"))
click q-2.4 callback "Valt het AI-systeem onder een van de hoog-risico systemen uit Bijlage III van de AI-verordening?"
	q-2.5(("2.5: Profilering"))
click q-2.5 callback "Voert het AI-systeem profilering van natuurlijke personen uit?"
	q-2.6(("2.6: Uitzondering Hoog risico bijlage III"))
click q-2.6 callback "Is er sprake van een uitzondering op de lijst van hoog-risico AI-systemen (uit bijlage III)?"
	q-2.7.1(("2.7.1: Conformiteitsbeoordeling Bijlage 1A"))
click q-2.7.1 callback "Is het verplicht om de conformiteitsbeoordeling door een derde partij, zoals een conformiteitsbeoordelingsinstantie, uit te laten voeren?"
	q-2.7.2(("2.7.2: Conformiteitsbeoordeling Bijlage III"))
click q-2.7.2 callback "Is het verplicht om de conformiteitsbeoordeling door een derde partij, zoals een conformiteitsbeoordelingsinstantie, uit te laten voeren?"
	q-2.8(("2.8: Systeemrisico"))
click q-2.8 callback "Is er sprake van een systeemrisico?"
	q-2.9(("2.9: Transparantieverplichting"))
click q-2.9 callback "Moet het AI-systeem voldoen aan de transparantieverplichtingen?"
	q-2.10(("2.10: Uitzondering Transparantieverplichting"))
click q-2.10 callback "Is er een uitzondering mogelijk op de transparantieverplichtingen?"
	q-2.11(("2.11: Open of vrije licentie"))
click q-2.11 callback "Wordt de toepassing onder een open of vrije licentie gedeeld en zijn de broncodes en parameters openbaar voor eenieder?"
	c-11.0{{"Je hebt geantwoord dat er geen sprake is van een algoritme, hierdoor is de AI-verordening niet voor jou van toepassing. Op basis van je antwoorden is het niet nodig om door te gaan naar Stap 2 – bepalen risicogroep. "}}
c-11.0:::secondaryStyle
click c-11.0 callback "Houd je aan bestaande wet- en regelgeving (bijv. AVG wanneer je persoonsgegevens verwerkt)."
	c-11.1{{"Op basis van jouw antwoorden op de vragen is de AI-verordening niet op jou van toepassing, omdat het algoritme niet valt onder de definitie van een AI-systeem of AI-model volgens de AI-verordening."}}
c-11.1:::secondaryStyle
click c-11.1 callback "Controleer of het algoritme als impactvol kan worden aangemerkt en of publicatie in het algoritmeregister aanbevolen is volgens de Handreiking Algoritmeregister. Zorg er ook voor dat het algoritme voldoet aan de geldende wet- en regelgeving, zoals de AVG wanneer persoonsgegevens worden verwerkt."
	c-11.2{{"Op basis van jouw antwoorden op de vragen is de AI-verordening niet op jou van toepassing, omdat je een uitzonderingsgrond hebt geselecteerd en buiten het toepassingsgebied valt."}}
c-11.2:::secondaryStyle
click c-11.2 callback "Zorg ervoor dat het algoritme voldoet aan bestaande wet- en regelgeving (bijv. AVG wanneer het algoritme persoonsgegevens verwerkt). Verder dien je te registreren in het algoritmeregister."
	c-11.3{{"Op basis van jouw antwoorden op de vragen is de AI-verordening niet op jou van toepassing, omdat je geen aanbieder, gebruiksverantwoordelijke, importeur of distributeur bent. Controleer echter zorgvuldig of een van deze rollen mogelijk toch op jou van toepassing is."}}
c-11.3:::secondaryStyle
click c-11.3 callback "Er is geen sprake van een verplichting."
	c-12.0.0{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent aanbieder van een verboden AI-systeem."}}
c-12.0.0:::secondaryStyle
click c-12.0.0 callback "Het AI-systeem moet van de markt worden gehaald. <strong>Let op: </strong> dit verbod geldt vanaf 1 februari 2025."
	c-12.0.1{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een hoog-risico AI-systeem met transparantieverplichtingen."}}
c-12.0.1:::secondaryStyle
click c-12.0.1 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br><br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking. <br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen voor aanbieder van een hoog risico AI-systeem (Artikel 16):</strong><br> • Aanbieders zorgen ervoor dat hun AI-systemen met een hoog risico in overeenstemming zijn met de eisen van afdeling 2<br> • Aanbieders vermelden op het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, naargelang het geval, hun naam, geregistreerde handelsnaam of geregistreerd merk en hun contactadres<br> • Aanbieders beschikken over een systeem voor kwaliteitsbeheer dat in overeenstemming is met Artikel 17 (systeem voor kwaliteitsbeheer)<br> • Aanbieders bewaren de in Artikel 18 (bewaring van documentatie) bedoelde documentatie<br> • Aanbieders bewaren de in Artikel 19 bedoelde logs die automatisch door hun AI-systemen met een hoog risico zijn gegenereerd, wanneer zij hierover de controle hebben<br> • Aanbieders zorgen ervoor dat voor het AI-systeem met een hoog risico de desbetreffende in Artikel 43 bedoelde conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld<br> • Aanbieders stellen een EU-conformiteitsverklaring op, in overeenstemming met Artikel 47. In het geval van het label 'beoordeling door derde partij' dient de uitvoering door een conformiteitsbeoordelingsinstantie te worden verzorgd. In het geval dat het AI-systeem gebruikmaakt van biometrie en wordt ingezet door rechtshandhavingsinstanties, immigratie- of asielautoriteiten, of door instellingen, organen of instanties van de Unie, treedt de markttoezichtautoriteit op als conformiteitsbeoordelingsinstantie. <br> • Aanbieders brengen de CE-markering aan op het Ai-systeem met een hoog risico of, waneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan deze verordening is voldaan, overeenkomstig Artikel 48<br> • Aanbieders leven de registratieverplichtingen als bedoeld in Artikel 49 lid 1, na<br> • Aanbieders nemen de noodzakelijke corrigerende maatregelen en verstrekken de uit hoofde van Artikel 20 vereiste informatie<br> • Aanbieders tonen op een met redenen omkleed verzoek van een nationale bevoegde autoriteit de overeenstemming aan van het AI-systeem met een hoog risico met de eisen van afdeling 2<br> • Aanbieders zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>
<strong>Verplichtingen voor aanbieders en gebruiksverantwoordelijken van AI-systemen met transparantieverplichtingen (Artikel 50):</strong><br> • Aanbieders zorgen ervoor dat AI-systemen die voor directe interactie met natuurlijke personen zijn bedoeld, zodanig worden ontworpen en ontwikkeld dat de betrokken natuurlijke personen worden geinformeerd dat zij interageren met een AI-systeem, tenzij dit duidelijk is vanuit het oogpunt van een normaal geinformeerde en redelijk omzichtige en oplettende natuurlijke persoon, rekening houdend met de omstandigheden en de gebruikscontext.<br> • Aanbieders van (GP)AI-systemen, die synthetische audio, beeld, video- of tekstinhoud genereren, zorgen ervoor dat de outputs van het AI-systeem worden gemarkeerd in een machineleesbaar formaat en detecteerbaar zijn als kunstmatig gegenereerd of gemanipuleerd. Aanbieders zorgen ervoor dat hun technische oplossingen doeltreffend, interoperabel robuust en betrouwbaar zijn voor zover dat technisch haalbaar is, rekening houdend met de specifieke kenmerken en beperkingen van de verschillende soorten content, de uitvoeringskosten en de algemeen erkende stand van de techniek, zoals tot uiting kan komen in relevante technische normen.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br>"
	c-12.0.2{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een hoog-risico AI-systeem."}}
c-12.0.2:::secondaryStyle
click c-12.0.2 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • Bevordering van AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor de vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen voor aanbieder van een hoog risico AI-systeem (Artikel 16):</strong><br> • Aanbieders zorgen ervoor dat hun AI-systemen met een hoog risico in overeenstemming zijn met de eisen van afdeling 2<br> • Aanbieders vermelden op het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, naargelang het geval, hun naam, geregistreerde handelsnaam of geregistreerd merk en hun contactadres<br> • Aanbieders beschikken over een systeem voor kwaliteitsbeheer dat in overeenstemming is met Artikel 17 (systeem voor kwaliteitsbeheer)<br> • Aanbieders bewaren de in Artikel 18 (bewaring van documentatie) bedoelde documentatie<br> • Aanbieders bewaren de in Artikel 19 bedoelde logs die automatisch door hun AI-systemen met een hoog risico zijn gegenereerd, wanneer zij hierover de controle hebben<br> • Aanbieders zorgen ervoor dat voor het AI-systeem met een hoog risico de desbetreffende in Artikel 43 bedoelde conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld<br> • Aanbieders stellen een EU-conformiteitsverklaring op, in overeenstemming met Artikel 47. In het geval van het label 'beoordeling door derde partij' dient de uitvoering door een conformiteitsbeoordelingsinstantie te worden verzorgd. In het geval dat het AI-systeem gebruikmaakt van biometrie en wordt ingezet door rechtshandhavingsinstanties, immigratie- of asielautoriteiten, of door instellingen, organen of instanties van de Unie, treedt de markttoezichtautoriteit op als conformiteitsbeoordelingsinstantie. <br> • Aanbieders brengen de CE-markering aan op het Ai-systeem met een hoog risico of, waneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan deze verordening is voldaan, overeenkomstig Artikel 48<br> • Aanbieders leven de registratieverplichtingen als bedoeld in Artikel 49 lid 1, na<br> • Aanbieders nemen de noodzakelijke corrigerende maatregelen en verstrekken de uit hoofde van Artikel 20 vereiste informatie<br> • Aanbieders tonen op een met redenen omkleed verzoek van een nationale bevoegde autoriteit de overeenstemming aan van het AI-systeem met een hoog risico met de eisen van afdeling 2<br> • Aanbieders zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br>"
	c-12.0.3{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een niet-hoog-risico AI-systeem met transparantieverplichtingen."}}
c-12.0.3:::secondaryStyle
click c-12.0.3 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • Bevordering van AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor de vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen voor aanbieders en gebruiksverantwoordelijken van AI-systemen met transparantieverplichtingen (Artikel 50):</strong><br> • Aanbieders zorgen ervoor dat AI-systemen die voor directe interactie met natuurlijke personen zijn bedoeld, zodanig worden ontworpen en ontwikkeld dat de betrokken natuurlijke personen worden geinformeerd dat zij interageren met een AI-systeem, tenzij dit duidelijk is vanuit het oogpunt van een normaal geinformeerde en redelijk omzichtige en oplettende natuurlijke persoon, rekening houdend met de omstandigheden en de gebruikscontext.<br> • Aanbieders van (GP)AI-systemen, die synthetische audio, beeld, video- of tekstinhoud genereren, zorgen ervoor dat de outputs van het AI-systeem worden gemarkeerd in een machineleesbaar formaat en detecteerbaar zijn als kunstmatig gegenereerd of gemanipuleerd. Aanbieders zorgen ervoor dat hun technische oplossingen doeltreffend, interoperabel robuust en betrouwbaar zijn voor zover dat technisch haalbaar is, rekening houdend met de specifieke kenmerken en beperkingen van de verschillende soorten content, de uitvoeringskosten en de algemeen erkende stand van de techniek, zoals tot uiting kan komen in relevante technische normen.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br>"
	c-12.0.4{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een niet-hoog-risico AI-systeem."}}
c-12.0.4:::secondaryStyle
click c-12.0.4 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • Bevordering van AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor de vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br>"
	c-12.1.1{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een hoog-risico AI-systeem voor algemene doeleinden met transparantieverplichtingen."}}
c-12.1.1:::secondaryStyle
click c-12.1.1 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • Bevordering van AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor de vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen voor aanbieder van een hoog risico AI-systeem (Artikel 16):</strong><br> • Aanbieders zorgen ervoor dat hun AI-systemen met een hoog risico in overeenstemming zijn met de eisen van afdeling 2<br> • Aanbieders vermelden op het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, naargelang het geval, hun naam, geregistreerde handelsnaam of geregistreerd merk en hun contactadres<br> • Aanbieders beschikken over een systeem voor kwaliteitsbeheer dat in overeenstemming is met Artikel 17 (systeem voor kwaliteitsbeheer)<br> • Aanbieders bewaren de in Artikel 18 (bewaring van documentatie) bedoelde documentatie<br> • Aanbieders bewaren de in Artikel 19 bedoelde logs die automatisch door hun AI-systemen met een hoog risico zijn gegenereerd, wanneer zij hierover de controle hebben<br> • Aanbieders zorgen ervoor dat voor het AI-systeem met een hoog risico de desbetreffende in Artikel 43 bedoelde conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld<br> • Aanbieders stellen een EU-conformiteitsverklaring op, in overeenstemming met Artikel 47. In het geval van het label 'beoordeling door derde partij' dient de uitvoering door een conformiteitsbeoordelingsinstantie te worden verzorgd. In het geval dat het AI-systeem gebruikmaakt van biometrie en wordt ingezet door rechtshandhavingsinstanties, immigratie- of asielautoriteiten, of door instellingen, organen of instanties van de Unie, treedt de markttoezichtautoriteit op als conformiteitsbeoordelingsinstantie. <br> • Aanbieders brengen de CE-markering aan op het Ai-systeem met een hoog risico of, waneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan deze verordening is voldaan, overeenkomstig Artikel 48<br> • Aanbieders leven de registratieverplichtingen als bedoeld in Artikel 49 lid 1, na<br> • Aanbieders nemen de noodzakelijke corrigerende maatregelen en verstrekken de uit hoofde van Artikel 20 vereiste informatie<br> • Aanbieders tonen op een met redenen omkleed verzoek van een nationale bevoegde autoriteit de overeenstemming aan van het AI-systeem met een hoog risico met de eisen van afdeling 2<br> • Aanbieders zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br> <strong>Verplichtingen voor aanbieders en gebruiksverantwoordelijken van AI-systemen met transparantieverplichtingen (Artikel 50):</strong><br> • Aanbieders zorgen ervoor dat AI-systemen die voor directe interactie met natuurlijke personen zijn bedoeld, zodanig worden ontworpen en ontwikkeld dat de betrokken natuurlijke personen worden geinformeerd dat zij interageren met een AI-systeem, tenzij dit duidelijk is vanuit het oogpunt van een normaal geinformeerde en redelijk omzichtige en oplettende natuurlijke persoon, rekening houdend met de omstandigheden en de gebruikscontext.<br> • Aanbieders van (GP)AI-systemen, die synthetische audio, beeld, video- of tekstinhoud genereren, zorgen ervoor dat de outputs van het AI-systeem worden gemarkeerd in een machineleesbaar formaat en detecteerbaar zijn als kunstmatig gegenereerd of gemanipuleerd. Aanbieders zorgen ervoor dat hun technische oplossingen doeltreffend, interoperabel robuust en betrouwbaar zijn voor zover dat technisch haalbaar is, rekening houdend met de specifieke kenmerken en beperkingen van de verschillende soorten content, de uitvoeringskosten en de algemeen erkende stand van de techniek, zoals tot uiting kan komen in relevante technische normen.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br> <strong>Verplichtingen voor de aanbieder van het AI-model voor algemene doeleinden, waarop het AI-systeem voor algemene doeleinden is gebaseerd (Artikel 53 en Artikel 54): </strong><br> • De technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan<br> • Informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren<br> • Beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën<br> • Een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br> <i>Geldig vanaf (Artikel 111 en Overweging 179):</i><br> • Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br> • Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
	c-12.1.2{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een hoog-risico AI-systeem voor algemene doeleinden."}}
c-12.1.2:::secondaryStyle
click c-12.1.2 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • Bevordering van AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor de vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen voor aanbieder van een hoog risico AI-systeem (Artikel 16):</strong><br> • Aanbieders zorgen ervoor dat hun AI-systemen met een hoog risico in overeenstemming zijn met de eisen van afdeling 2<br> • Aanbieders vermelden op het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, naargelang het geval, hun naam, geregistreerde handelsnaam of geregistreerd merk en hun contactadres<br> • Aanbieders beschikken over een systeem voor kwaliteitsbeheer dat in overeenstemming is met Artikel 17 (systeem voor kwaliteitsbeheer)<br> • Aanbieders bewaren de in Artikel 18 (bewaring van documentatie) bedoelde documentatie<br> • Aanbieders bewaren de in Artikel 19 bedoelde logs die automatisch door hun AI-systemen met een hoog risico zijn gegenereerd, wanneer zij hierover de controle hebben<br> • Aanbieders zorgen ervoor dat voor het AI-systeem met een hoog risico de desbetreffende in Artikel 43 bedoelde conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld<br> • Aanbieders stellen een EU-conformiteitsverklaring op, in overeenstemming met Artikel 47. In het geval van het label 'beoordeling door derde partij' dient de uitvoering door een conformiteitsbeoordelingsinstantie te worden verzorgd. In het geval dat het AI-systeem gebruikmaakt van biometrie en wordt ingezet door rechtshandhavingsinstanties, immigratie- of asielautoriteiten, of door instellingen, organen of instanties van de Unie, treedt de markttoezichtautoriteit op als conformiteitsbeoordelingsinstantie. <br> • Aanbieders brengen de CE-markering aan op het Ai-systeem met een hoog risico of, waneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan deze verordening is voldaan, overeenkomstig Artikel 48<br> • Aanbieders leven de registratieverplichtingen als bedoeld in Artikel 49 lid 1, na<br> • Aanbieders nemen de noodzakelijke corrigerende maatregelen en verstrekken de uit hoofde van Artikel 20 vereiste informatie<br> • Aanbieders tonen op een met redenen omkleed verzoek van een nationale bevoegde autoriteit de overeenstemming aan van het AI-systeem met een hoog risico met de eisen van afdeling 2<br> • Aanbieders zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br> <strong>Verplichtingen voor de aanbieder van het AI-model voor algemene doeleinden, waarop het AI-systeem voor algemene doeleinden is gebaseerd (Artikel 53 en Artikel 54):</strong><br> • De technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan<br> • Informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren<br> • Beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën<br> • Een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br> <i>Geldig vanaf (Artikel 111 en Overweging 179):</i><br> • Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br> • Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
	c-12.1.3{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een niet-hoog-risico AI-systeem voor algemene doeleinden met transparantieverplichtingen."}}
c-12.1.3:::secondaryStyle
click c-12.1.3 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • Bevordering van AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor de vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen voor aanbieders en gebruiksverantwoordelijken van AI-systemen met transparantieverplichtingen (Artikel 50):</strong><br> • Aanbieders zorgen ervoor dat AI-systemen die voor directe interactie met natuurlijke personen zijn bedoeld, zodanig worden ontworpen en ontwikkeld dat de betrokken natuurlijke personen worden geinformeerd dat zij interageren met een AI-systeem, tenzij dit duidelijk is vanuit het oogpunt van een normaal geinformeerde en redelijk omzichtige en oplettende natuurlijke persoon, rekening houdend met de omstandigheden en de gebruikscontext.<br> • Aanbieders van (GP)AI-systemen, die synthetische audio, beeld, video- of tekstinhoud genereren, zorgen ervoor dat de outputs van het AI-systeem worden gemarkeerd in een machineleesbaar formaat en detecteerbaar zijn als kunstmatig gegenereerd of gemanipuleerd. Aanbieders zorgen ervoor dat hun technische oplossingen doeltreffend, interoperabel robuust en betrouwbaar zijn voor zover dat technisch haalbaar is, rekening houdend met de specifieke kenmerken en beperkingen van de verschillende soorten content, de uitvoeringskosten en de algemeen erkende stand van de techniek, zoals tot uiting kan komen in relevante technische normen.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br> <strong>Verplichtingen voor de aanbieder van het AI-model voor algemene doeleinden, waarop het AI-systeem voor algemene doeleinden is gebaseerd (Artikel 53 en Artikel 54):</strong><br> • De technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan<br> • Informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren<br> • Beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën<br> • Een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br> <i>Geldig vanaf (Artikel 111 en Overweging 179):</i><br> • Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br> • Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
	c-12.1.4{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een niet-hoog-risico AI-systeem voor algemene doeleinden."}}
c-12.1.4:::secondaryStyle
click c-12.1.4 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • Bevordering van AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor de vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen voor de aanbieder van het AI-model voor algemene doeleinden, waarop het AI-systeem voor algemene doeleinden is gebaseerd (Artikel 53 en Artikel 54):</strong><br> • De technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan<br> • Informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren<br> • Beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën<br> • Een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br> <i>Geldig vanaf (Artikel 111 en Overweging 179):</i><br> • Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br> • Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
	c-12.2.1{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een AI-model voor algemene doeleinden met een systeemrisico."}}
c-12.2.1:::secondaryStyle
click c-12.2.1 callback " <strong>Verplichtingen voor alle AI-modellen voor algemene doeleinden:</strong><br> • Praktijkcodes (Artikel 56)<br><br> <i>Geldig vanaf:</i><br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden (Artikel 53 en Artikel 54):</strong><br> • De technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan.<br> • Informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.<br> • Beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën.<br> • Een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br> <i>Geldig vanaf (Artikel 111 en Overweging 179):</i><br> • Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br> • Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br> <strong>Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico (Artikel 55):</strong><br> • Het uitvoeren van een modelevaluatie overeenkomstig gestandaardiseerde protocollen en instrumenten die de stand van de techniek weerspiegelen, met inbegrip van het uitvoeren en documenteren van tests gericht op het ontdekken van kwetsbaarheden van het model met als doel om systeemrisico’s in kaart te brengen en te beperken.<br> • Het beoordelen en beperken van mogelijke systeemrisico’s op Unieniveau, met inbegrip van de bronnen daarvan, die kunnen voortvloeien uit de ontwikkeling, het in de handel brengen of het gebruik van AI-modellen voor algemene doeleinden met een systeemrisico.<br> • Het bijhouden, documenteren en onverwijld rapporteren (aan het AI-bureau (en in voorkomende gevallen aan de nationale bevoegde autoriteiten)) van relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen.<br> • Het zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden en de fysieke infrastructuur van het model.<br><br> <i>Geldig vanaf (Artikel 111 en Overweging 179):</i><br> • Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br> • Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
	c-12.2.2{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een open-source AI-model voor algemene doeleinden."}}
c-12.2.2:::secondaryStyle
click c-12.2.2 callback " <strong>Verplichtingen voor alle AI-modellen voor algemene doeleinden:</strong><br> • Praktijkcodes (Artikel 56)<br><br> <i>Geldig vanaf:</i><br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden (Artikel 53 en Artikel 54):</strong><br> • Beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën.<br> • Een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br>
Door overweging 104 voor open-source AI-modellen voor algemene doeleinden hoef je niet te voldoen aan (delen van Artikel 53 en Artikel 54): <br> • De technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan.<br> • Informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.<br><br> <i>Geldig vanaf (Artikel 111 en Overweging 179):</i><br> • Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br> • Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
	c-12.2.3{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een AI-model voor algemene doeleinden."}}
c-12.2.3:::secondaryStyle
click c-12.2.3 callback " <strong>Verplichtingen voor alle AI-modellen voor algemene doeleinden:</strong><br> • Praktijkcodes (Artikel 56)<br><br> <strong>Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden (Artikel 53 en Artikel 54):</strong><br> • De technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan. <br> • Informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren. <br> • Beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën.<br> • Een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br>
Aangezien het geen open-source toepassing is, gelden er geen uitzonderingen. <br><br> <strong>Geldig vanaf (Artikel 111 en Overweging 179 ):</strong><br> • Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br> • Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
	c-13.0.0{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent gebruiksverantwoordelijke van een verboden AI-systeem."}}
c-13.0.0:::secondaryStyle
click c-13.0.0 callback "Het gebruik van het AI-systeem moet worden stop gezet. <strong>Let op: </strong>  dit geldt vanaf 1 februari 2025."
	c-13.0.1{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke van een hoog-risico AI-systeem met transparantieverplichtingen. "}}
c-13.0.1:::secondaryStyle
click c-13.0.1 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br><br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico (Artikel 26 en Artikel 27):</strong><br> • Het nemen van passende technische en organisatorische maatregelen om te waarborgen dat dergelijke systemen in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd worden gebruikt<br> • Het opdragen van menselijk toezicht aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen<br> • Het ervoor zorgen dat, voor zover de gebruikersverantwoordelijke controle heeft over de inputdata, de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico<br> • Het monitoren van de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en in voorkomend geval het in kennis stellen van de aanbieders overeenkomstig Artikel 72.<br> • Het bewaren van de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder controle van de gebruiksverantwoordelijke vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden<br> • Voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico<br> • Gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in Artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in Artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis<br> • Indien van toepassing, gebruiken gebruiksverantwoordelijken van AI-systemen met een hoog risico de informatie die op grond van Artikel 13 van deze verordening wordt verstrekt om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren<br> • De gebruiksverantwoordelijke van een AI-systeem met een hoog risico voor biometrische identificatie op afstand verzoekt achteraf in het kader van een onderzoek waarbij gericht wordt gezocht naar een persoon die wordt verdacht van of veroordeeld is voor het plegen van een strafbaar feit, vooraf of zonder onnodige vertraging en uiterlijk 48 uur na het feit, om toestemming van een gerechtelijke instantie of administratieve instantie, van wie de beslissing bindend is en onderworpen is aan rechterlijke toetsing, voor het gebruik van dat systeem, behalve wanneer het wordt gebruikt voor de initiële identificatie van een potentiële verdachte op basis van objectieve en verifieerbare feiten die rechtstreeks verband houden met het strafbare feit. Elk gebruik wordt beperkt tot hetgeen strikt noodzakelijk is voor het onderzoek naar een specifiek strafbaar feit<br> • Gebruiksverantwoordelijken van in bijlage III bedoelde AI-systemen met een hoog risico die beslissingen met betrekking tot natuurlijke personen nemen of helpen nemen, informeren de natuurlijke personen dat het AI-systeem met een hoog risico op hen wordt toegepast.<br> • Gebruiksverantwoordelijken werken samen met de relevante bevoegde autoriteiten bij alle door deze autoriteiten genomen maatregelen met betrekking tot een AI-systeem met een hoog risico met het oog op de uitvoering van deze verordening.<br> • Gebruiksverantwoordelijken die publiekrechtelijke organen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruikt in krediet/verzekering (bijlage III, 5, c en d) een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren (Artikel 27).<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br> <strong>Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systemen (Artikel 50):</strong><br> • Gebruiksverantwoordelijken van een systeem voor het herkennen van emoties of een systeem voor biometrische categorisering informeren de daaraan blootgestelde natuurlijke personen over de werking van het systeem en verwerken de persoonsgegevens in overeenstemming met Verordening (EU) 2016/679, Verordening (EU) 2018/1725 en Richtlijn (EU) 2016/680, indien van toepassing<br> • Gebruiksverantwoordelijken van een AI-systeem dat beeld-, audio- of videocontent genereert of bewerkt die een deepfake vormt, maken bekend dat de content kunstmatig is gegenereerd of gemanipuleerd. Wanneer de content deel uitmaakt van een kennelijk artistiek, creatief, satirisch, fictief of analoog werk of programma, zijn de transparantieverplichtingen beperkt tot de openbaarmaking van het bestaan van dergelijke gegenereerde of bewerkte content op een passende wijze die de weergave of het genot van het werk niet belemmert.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
	c-13.0.2{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke van een hoog-risico AI-systeem."}}
c-13.0.2:::secondaryStyle
click c-13.0.2 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br><br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico (Artikel 26 en Artikel 27):</strong><br> • Het nemen van passende technische en organisatorische maatregelen om te waarborgen dat dergelijke systemen in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd worden gebruikt<br> • Het opdragen van menselijk toezicht aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen<br> • Het ervoor zorgen dat, voor zover de gebruikersverantwoordelijke controle heeft over de inputdata, de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico<br> • Het monitoren van de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en in voorkomend geval het in kennis stellen van de aanbieders overeenkomstig Artikel 72.<br> • Het bewaren van de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder controle van de gebruiksverantwoordelijke vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden<br> • Voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico<br> • Gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in Artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in Artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis<br> • Indien van toepassing, gebruiken gebruiksverantwoordelijken van AI-systemen met een hoog risico de informatie die op grond van Artikel 13 van deze verordening wordt verstrekt om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren<br> • De gebruiksverantwoordelijke van een AI-systeem met een hoog risico voor biometrische identificatie op afstand verzoekt achteraf in het kader van een onderzoek waarbij gericht wordt gezocht naar een persoon die wordt verdacht van of veroordeeld is voor het plegen van een strafbaar feit, vooraf of zonder onnodige vertraging en uiterlijk 48 uur na het feit, om toestemming van een gerechtelijke instantie of administratieve instantie, van wie de beslissing bindend is en onderworpen is aan rechterlijke toetsing, voor het gebruik van dat systeem, behalve wanneer het wordt gebruikt voor de initiële identificatie van een potentiële verdachte op basis van objectieve en verifieerbare feiten die rechtstreeks verband houden met het strafbare feit. Elk gebruik wordt beperkt tot hetgeen strikt noodzakelijk is voor het onderzoek naar een specifiek strafbaar feit<br> • Gebruiksverantwoordelijken van in bijlage III bedoelde AI-systemen met een hoog risico die beslissingen met betrekking tot natuurlijke personen nemen of helpen nemen, informeren de natuurlijke personen dat het AI-systeem met een hoog risico op hen wordt toegepast.<br> • Gebruiksverantwoordelijken werken samen met de relevante bevoegde autoriteiten bij alle door deze autoriteiten genomen maatregelen met betrekking tot een AI-systeem met een hoog risico met het oog op de uitvoering van deze verordening.<br> • Gebruiksverantwoordelijken die publiekrechtelijke organen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruikt in krediet/verzekering (bijlage III, 5, c en d) een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren (Artikel 27).<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
	c-13.0.3{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke van een niet-hoog-risico AI-systeem met transparantieverplichtingen."}}
c-13.0.3:::secondaryStyle
click c-13.0.3 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br><br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systemen (Artikel 50):</strong><br> • Gebruiksverantwoordelijken van een systeem voor het herkennen van emoties of een systeem voor biometrische categorisering informeren de daaraan blootgestelde natuurlijke personen over de werking van het systeem en verwerken de persoonsgegevens in overeenstemming met Verordening (EU) 2016/679, Verordening (EU) 2018/1725 en Richtlijn (EU) 2016/680, indien van toepassing<br> • Gebruiksverantwoordelijken van een AI-systeem dat beeld-, audio- of videocontent genereert of bewerkt die een deepfake vormt, maken bekend dat de content kunstmatig is gegenereerd of gemanipuleerd. Wanneer de content deel uitmaakt van een kennelijk artistiek, creatief, satirisch, fictief of analoog werk of programma, zijn de transparantieverplichtingen beperkt tot de openbaarmaking van het bestaan van dergelijke gegenereerde of bewerkte content op een passende wijze die de weergave of het genot van het werk niet belemmert.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
	c-13.0.4{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke van een niet-hoog-risico AI-systeem."}}
c-13.0.4:::secondaryStyle
click c-13.0.4 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br><br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>"
	c-13.1.1{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke van een hoog-risico AI-systeem voor algemene doeleinden met transparantieverplichtingen."}}
c-13.1.1:::secondaryStyle
click c-13.1.1 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br><br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico (Artikel 26 en Artikel 27):</strong><br> • Het nemen van passende technische en organisatorische maatregelen om te waarborgen dat dergelijke systemen in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd worden gebruikt<br> • Het opdragen van menselijk toezicht aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen<br> • Het ervoor zorgen dat, voor zover de gebruikersverantwoordelijke controle heeft over de inputdata, de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico<br> • Het monitoren van de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en in voorkomend geval het in kennis stellen van de aanbieders overeenkomstig Artikel 72.<br> • Het bewaren van de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder controle van de gebruiksverantwoordelijke vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden<br> • Voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico<br> • Gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in Artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in Artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis<br> • Indien van toepassing, gebruiken gebruiksverantwoordelijken van AI-systemen met een hoog risico de informatie die op grond van Artikel 13 van deze verordening wordt verstrekt om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren<br> • De gebruiksverantwoordelijke van een AI-systeem met een hoog risico voor biometrische identificatie op afstand verzoekt achteraf in het kader van een onderzoek waarbij gericht wordt gezocht naar een persoon die wordt verdacht van of veroordeeld is voor het plegen van een strafbaar feit, vooraf of zonder onnodige vertraging en uiterlijk 48 uur na het feit, om toestemming van een gerechtelijke instantie of administratieve instantie, van wie de beslissing bindend is en onderworpen is aan rechterlijke toetsing, voor het gebruik van dat systeem, behalve wanneer het wordt gebruikt voor de initiële identificatie van een potentiële verdachte op basis van objectieve en verifieerbare feiten die rechtstreeks verband houden met het strafbare feit. Elk gebruik wordt beperkt tot hetgeen strikt noodzakelijk is voor het onderzoek naar een specifiek strafbaar feit<br> • Gebruiksverantwoordelijken van in bijlage III bedoelde AI-systemen met een hoog risico die beslissingen met betrekking tot natuurlijke personen nemen of helpen nemen, informeren de natuurlijke personen dat het AI-systeem met een hoog risico op hen wordt toegepast.<br> • Gebruiksverantwoordelijken werken samen met de relevante bevoegde autoriteiten bij alle door deze autoriteiten genomen maatregelen met betrekking tot een AI-systeem met een hoog risico met het oog op de uitvoering van deze verordening.<br> • Gebruiksverantwoordelijken die publiekrechtelijke organen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruikt in krediet/verzekering (bijlage III, 5, c en d) een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren (Artikel 27).<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br> <strong>Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systemen (Artikel 50):</strong><br> • Gebruiksverantwoordelijken van een systeem voor het herkennen van emoties of een systeem voor biometrische categorisering informeren de daaraan blootgestelde natuurlijke personen over de werking van het systeem en verwerken de persoonsgegevens in overeenstemming met Verordening (EU) 2016/679, Verordening (EU) 2018/1725 en Richtlijn (EU) 2016/680, indien van toepassing<br> • Gebruiksverantwoordelijken van een AI-systeem dat beeld-, audio- of videocontent genereert of bewerkt die een deepfake vormt, maken bekend dat de content kunstmatig is gegenereerd of gemanipuleerd. Wanneer de content deel uitmaakt van een kennelijk artistiek, creatief, satirisch, fictief of analoog werk of programma, zijn de transparantieverplichtingen beperkt tot de openbaarmaking van het bestaan van dergelijke gegenereerde of bewerkte content op een passende wijze die de weergave of het genot van het werk niet belemmert.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
	c-13.1.2{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke van een hoog-risico AI-systeem voor algemene doeleinden."}}
c-13.1.2:::secondaryStyle
click c-13.1.2 callback " <strong>Verplichtingen voor alle AI-systemen: </strong><br> • AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br><br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico (Artikel 26 en Artikel 27):</strong><br> • Het nemen van passende technische en organisatorische maatregelen om te waarborgen dat dergelijke systemen in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd worden gebruikt<br> • Het opdragen van menselijk toezicht aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen<br> • Het ervoor zorgen dat, voor zover de gebruikersverantwoordelijke controle heeft over de inputdata, de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico<br> • Het monitoren van de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en in voorkomend geval het in kennis stellen van de aanbieders overeenkomstig Artikel 72.<br> • Het bewaren van de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder controle van de gebruiksverantwoordelijke vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden<br> • Voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico<br> • Gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in Artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in Artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis<br> • Indien van toepassing, gebruiken gebruiksverantwoordelijken van AI-systemen met een hoog risico de informatie die op grond van Artikel 13 van deze verordening wordt verstrekt om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren<br> • De gebruiksverantwoordelijke van een AI-systeem met een hoog risico voor biometrische identificatie op afstand verzoekt achteraf in het kader van een onderzoek waarbij gericht wordt gezocht naar een persoon die wordt verdacht van of veroordeeld is voor het plegen van een strafbaar feit, vooraf of zonder onnodige vertraging en uiterlijk 48 uur na het feit, om toestemming van een gerechtelijke instantie of administratieve instantie, van wie de beslissing bindend is en onderworpen is aan rechterlijke toetsing, voor het gebruik van dat systeem, behalve wanneer het wordt gebruikt voor de initiële identificatie van een potentiële verdachte op basis van objectieve en verifieerbare feiten die rechtstreeks verband houden met het strafbare feit. Elk gebruik wordt beperkt tot hetgeen strikt noodzakelijk is voor het onderzoek naar een specifiek strafbaar feit<br> • Gebruiksverantwoordelijken van in bijlage III bedoelde AI-systemen met een hoog risico die beslissingen met betrekking tot natuurlijke personen nemen of helpen nemen, informeren de natuurlijke personen dat het AI-systeem met een hoog risico op hen wordt toegepast.<br> • Gebruiksverantwoordelijken werken samen met de relevante bevoegde autoriteiten bij alle door deze autoriteiten genomen maatregelen met betrekking tot een AI-systeem met een hoog risico met het oog op de uitvoering van deze verordening.<br> • Gebruiksverantwoordelijken die publiekrechtelijke organen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruikt in krediet/verzekering (bijlage III, 5, c en d) een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren (Artikel 27).<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
	c-13.1.3{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke van een niet-hoog-risico AI-systeem voor algemene doeleinden met transparantieverplichtingen."}}
c-13.1.3:::secondaryStyle
click c-13.1.3 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br><br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systemen (Artikel 50):</strong><br> • Gebruiksverantwoordelijken van een systeem voor het herkennen van emoties of een systeem voor biometrische categorisering informeren de daaraan blootgestelde natuurlijke personen over de werking van het systeem en verwerken de persoonsgegevens in overeenstemming met Verordening (EU) 2016/679, Verordening (EU) 2018/1725 en Richtlijn (EU) 2016/680, indien van toepassing<br> • Gebruiksverantwoordelijken van een AI-systeem dat beeld-, audio- of videocontent genereert of bewerkt die een deepfake vormt, maken bekend dat de content kunstmatig is gegenereerd of gemanipuleerd. Wanneer de content deel uitmaakt van een kennelijk artistiek, creatief, satirisch, fictief of analoog werk of programma, zijn de transparantieverplichtingen beperkt tot de openbaarmaking van het bestaan van dergelijke gegenereerde of bewerkte content op een passende wijze die de weergave of het genot van het werk niet belemmert.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
	c-13.1.4{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke van een niet-hoog-risico AI-systeem voor algemene doeleinden."}}
c-13.1.4:::secondaryStyle
click c-13.1.4 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br><br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> "
	c-13.2.1{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke van een AI-model voor algemene doeleinden."}}
c-13.2.1:::secondaryStyle
click c-13.2.1 callback " <strong>Verplichtingen voor alle AI-modellen voor algemene doeleinden:</strong><br> • Praktijkcodes (Artikel 56)<br><br> <i>Geldig vanaf (Artikel 111 en Overweging 179):</i><br> • Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br> • Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br> Als gebruiksverantwoordelijke van een AI-model voor algemene doeleinden gelden er geen verplichtingen vanuit een mogelijk systeemrisico. Het is echter belangrijk om te realiseren dat als een AI-model voor algemene doeleinden verder wordt ontwikkeld het in een AI-systeem voor algemene doeleinden kan veranderen en er mogelijk minimale transparantieverplichtingen van toepassing zijn. Daarnaast kan het systeem, afhankelijk van de specifieke toepassing, als een hoog-risico AI-systeem worden geclassificeerd."
	c-14.0.0{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent aanbieder en gebruiksverantwoordelijke van een verboden AI-systeem."}}
c-14.0.0:::secondaryStyle
click c-14.0.0 callback "Het AI-systeem moet van de markt worden gehaald en het gebruik ervan stop gezet. <strong>Let op: </strong>  dit geldt vanaf 1 februari 2025."
	c-14.0.1{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke en aanbieder van een hoog-risico AI-systeem met transparantieverplichtingen."}}
c-14.0.1:::secondaryStyle
click c-14.0.1 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br><br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen voor aanbieder van een hoog risico AI-systeem (Artikel 16):</strong><br> • Aanbieders zorgen ervoor dat hun AI-systemen met een hoog risico in overeenstemming zijn met de eisen van afdeling 2<br> • Aanbieders vermelden op het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, naargelang het geval, hun naam, geregistreerde handelsnaam of geregistreerd merk en hun contactadres<br> • Aanbieders beschikken over een systeem voor kwaliteitsbeheer dat in overeenstemming is met Artikel 17 (systeem voor kwaliteitsbeheer)<br> • Aanbieders bewaren de in Artikel 18 (bewaring van documentatie) bedoelde documentatie<br> • Aanbieders bewaren de in Artikel 19 bedoelde logs die automatisch door hun AI-systemen met een hoog risico zijn gegenereerd, wanneer zij hierover de controle hebben<br> • Aanbieders zorgen ervoor dat voor het AI-systeem met een hoog risico de desbetreffende in Artikel 43 bedoelde conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld<br> • Aanbieders stellen een EU-conformiteitsverklaring op, in overeenstemming met Artikel 47. In het geval van het label 'beoordeling door derde partij' dient de uitvoering door een conformiteitsbeoordelingsinstantie te worden verzorgd. In het geval dat het AI-systeem gebruikmaakt van biometrie en wordt ingezet door rechtshandhavingsinstanties, immigratie- of asielautoriteiten, of door instellingen, organen of instanties van de Unie, treedt de markttoezichtautoriteit op als conformiteitsbeoordelingsinstantie. <br> • Aanbieders brengen de CE-markering aan op het Ai-systeem met een hoog risico of, waneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan deze verordening is voldaan, overeenkomstig Artikel 48<br> • Aanbieders leven de registratieverplichtingen als bedoeld in Artikel 49 lid 1, na<br> • Aanbieders nemen de noodzakelijke corrigerende maatregelen en verstrekken de uit hoofde van Artikel 20 vereiste informatie<br> • Aanbieders tonen op een met redenen omkleed verzoek van een nationale bevoegde autoriteit de overeenstemming aan van het AI-systeem met een hoog risico met de eisen van afdeling 2<br> • Aanbieders zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br> <strong>Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico (Artikel 26 en Artikel 27):</strong><br> • Het nemen van passende technische en organisatorische maatregelen om te waarborgen dat dergelijke systemen in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd worden gebruikt<br> • Het opdragen van menselijk toezicht aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen<br> • Het ervoor zorgen dat, voor zover de gebruikersverantwoordelijke controle heeft over de inputdata, de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico<br> • Het monitoren van de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en in voorkomend geval het in kennis stellen van de aanbieders overeenkomstig Artikel 72.<br> • Het bewaren van de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder controle van de gebruiksverantwoordelijke vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden<br> • Voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico<br> • Gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in Artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in Artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis<br> • Indien van toepassing, gebruiken gebruiksverantwoordelijken van AI-systemen met een hoog risico de informatie die op grond van Artikel 13 van deze verordening wordt verstrekt om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren<br> • De gebruiksverantwoordelijke van een AI-systeem met een hoog risico voor biometrische identificatie op afstand verzoekt achteraf in het kader van een onderzoek waarbij gericht wordt gezocht naar een persoon die wordt verdacht van of veroordeeld is voor het plegen van een strafbaar feit, vooraf of zonder onnodige vertraging en uiterlijk 48 uur na het feit, om toestemming van een gerechtelijke instantie of administratieve instantie, van wie de beslissing bindend is en onderworpen is aan rechterlijke toetsing, voor het gebruik van dat systeem, behalve wanneer het wordt gebruikt voor de initiële identificatie van een potentiële verdachte op basis van objectieve en verifieerbare feiten die rechtstreeks verband houden met het strafbare feit. Elk gebruik wordt beperkt tot hetgeen strikt noodzakelijk is voor het onderzoek naar een specifiek strafbaar feit<br> • Gebruiksverantwoordelijken van in bijlage III bedoelde AI-systemen met een hoog risico die beslissingen met betrekking tot natuurlijke personen nemen of helpen nemen, informeren de natuurlijke personen dat het AI-systeem met een hoog risico op hen wordt toegepast.<br> • Gebruiksverantwoordelijken werken samen met de relevante bevoegde autoriteiten bij alle door deze autoriteiten genomen maatregelen met betrekking tot een AI-systeem met een hoog risico met het oog op de uitvoering van deze verordening.<br> • Gebruiksverantwoordelijken die publiekrechtelijke organen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruikt in krediet/verzekering (bijlage III, 5, c en d) een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren (Artikel 27).<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br> <strong>Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systemen (Artikel 50):</strong><br> • Gebruiksverantwoordelijken van een systeem voor het herkennen van emoties of een systeem voor biometrische categorisering informeren de daaraan blootgestelde natuurlijke personen over de werking van het systeem en verwerken de persoonsgegevens in overeenstemming met Verordening (EU) 2016/679, Verordening (EU) 2018/1725 en Richtlijn (EU) 2016/680, indien van toepassing<br> • Gebruiksverantwoordelijken van een AI-systeem dat beeld-, audio- of videocontent genereert of bewerkt die een deepfake vormt, maken bekend dat de content kunstmatig is gegenereerd of gemanipuleerd. Wanneer de content deel uitmaakt van een kennelijk artistiek, creatief, satirisch, fictief of analoog werk of programma, zijn de transparantieverplichtingen beperkt tot de openbaarmaking van het bestaan van dergelijke gegenereerde of bewerkte content op een passende wijze die de weergave of het genot van het werk niet belemmert.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
	c-14.0.2{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke en aanbieder van een hoog-risico AI-systeem."}}
c-14.0.2:::secondaryStyle
click c-14.0.2 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br><br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen voor aanbieder van een hoog risico AI-systeem (Artikel 16):</strong><br> • Aanbieders zorgen ervoor dat hun AI-systemen met een hoog risico in overeenstemming zijn met de eisen van afdeling 2<br> • Aanbieders vermelden op het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, naargelang het geval, hun naam, geregistreerde handelsnaam of geregistreerd merk en hun contactadres<br> • Aanbieders beschikken over een systeem voor kwaliteitsbeheer dat in overeenstemming is met Artikel 17 (systeem voor kwaliteitsbeheer)<br> • Aanbieders bewaren de in Artikel 18 (bewaring van documentatie) bedoelde documentatie<br> • Aanbieders bewaren de in Artikel 19 bedoelde logs die automatisch door hun AI-systemen met een hoog risico zijn gegenereerd, wanneer zij hierover de controle hebben<br> • Aanbieders zorgen ervoor dat voor het AI-systeem met een hoog risico de desbetreffende in Artikel 43 bedoelde conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld<br> • Aanbieders stellen een EU-conformiteitsverklaring op, in overeenstemming met Artikel 47. In het geval van het label 'beoordeling door derde partij' dient de uitvoering door een conformiteitsbeoordelingsinstantie te worden verzorgd. In het geval dat het AI-systeem gebruikmaakt van biometrie en wordt ingezet door rechtshandhavingsinstanties, immigratie- of asielautoriteiten, of door instellingen, organen of instanties van de Unie, treedt de markttoezichtautoriteit op als conformiteitsbeoordelingsinstantie. <br> • Aanbieders brengen de CE-markering aan op het Ai-systeem met een hoog risico of, waneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan deze verordening is voldaan, overeenkomstig Artikel 48<br> • Aanbieders leven de registratieverplichtingen als bedoeld in Artikel 49 lid 1, na<br> • Aanbieders nemen de noodzakelijke corrigerende maatregelen en verstrekken de uit hoofde van Artikel 20 vereiste informatie<br> • Aanbieders tonen op een met redenen omkleed verzoek van een nationale bevoegde autoriteit de overeenstemming aan van het AI-systeem met een hoog risico met de eisen van afdeling 2<br> • Aanbieders zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br> <strong>Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico (Artikel 26 en Artikel 27):</strong><br> • Het nemen van passende technische en organisatorische maatregelen om te waarborgen dat dergelijke systemen in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd worden gebruikt<br> • Het opdragen van menselijk toezicht aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen<br> • Het ervoor zorgen dat, voor zover de gebruikersverantwoordelijke controle heeft over de inputdata, de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico<br> • Het monitoren van de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en in voorkomend geval het in kennis stellen van de aanbieders overeenkomstig Artikel 72.<br> • Het bewaren van de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder controle van de gebruiksverantwoordelijke vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden<br> • Voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico<br> • Gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in Artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in Artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis<br> • Indien van toepassing, gebruiken gebruiksverantwoordelijken van AI-systemen met een hoog risico de informatie die op grond van Artikel 13 van deze verordening wordt verstrekt om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren<br> • De gebruiksverantwoordelijke van een AI-systeem met een hoog risico voor biometrische identificatie op afstand verzoekt achteraf in het kader van een onderzoek waarbij gericht wordt gezocht naar een persoon die wordt verdacht van of veroordeeld is voor het plegen van een strafbaar feit, vooraf of zonder onnodige vertraging en uiterlijk 48 uur na het feit, om toestemming van een gerechtelijke instantie of administratieve instantie, van wie de beslissing bindend is en onderworpen is aan rechterlijke toetsing, voor het gebruik van dat systeem, behalve wanneer het wordt gebruikt voor de initiële identificatie van een potentiële verdachte op basis van objectieve en verifieerbare feiten die rechtstreeks verband houden met het strafbare feit. Elk gebruik wordt beperkt tot hetgeen strikt noodzakelijk is voor het onderzoek naar een specifiek strafbaar feit<br> • Gebruiksverantwoordelijken van in bijlage III bedoelde AI-systemen met een hoog risico die beslissingen met betrekking tot natuurlijke personen nemen of helpen nemen, informeren de natuurlijke personen dat het AI-systeem met een hoog risico op hen wordt toegepast.<br> • Gebruiksverantwoordelijken werken samen met de relevante bevoegde autoriteiten bij alle door deze autoriteiten genomen maatregelen met betrekking tot een AI-systeem met een hoog risico met het oog op de uitvoering van deze verordening.<br> • Gebruiksverantwoordelijken die publiekrechtelijke organen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruikt in krediet/verzekering (bijlage III, 5, c en d) een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren (Artikel 27).<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
	c-14.0.3{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke en aanbieder van een niet-hoog-risico AI-systeem met transparantieverplichtingen."}}
c-14.0.3:::secondaryStyle
click c-14.0.3 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br><br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systemen (Artikel 50):</strong><br> • Gebruiksverantwoordelijken van een systeem voor het herkennen van emoties of een systeem voor biometrische categorisering informeren de daaraan blootgestelde natuurlijke personen over de werking van het systeem en verwerken de persoonsgegevens in overeenstemming met Verordening (EU) 2016/679, Verordening (EU) 2018/1725 en Richtlijn (EU) 2016/680, indien van toepassing<br> • Gebruiksverantwoordelijken van een AI-systeem dat beeld-, audio- of videocontent genereert of bewerkt die een deepfake vormt, maken bekend dat de content kunstmatig is gegenereerd of gemanipuleerd. Wanneer de content deel uitmaakt van een kennelijk artistiek, creatief, satirisch, fictief of analoog werk of programma, zijn de transparantieverplichtingen beperkt tot de openbaarmaking van het bestaan van dergelijke gegenereerde of bewerkte content op een passende wijze die de weergave of het genot van het werk niet belemmert.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
	c-14.0.4{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke en aanbieder van een niet-hoog-risico AI-systeem."}}
c-14.0.4:::secondaryStyle
click c-14.0.4 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br><br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>"
	c-14.1.1{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke en aanbieder van een hoog-risico AI-systeem voor algemene doeleinden met transparantieverplichtingen."}}
c-14.1.1:::secondaryStyle
click c-14.1.1 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br><br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen voor aanbieder van een hoog risico AI-systeem (Artikel 16):</strong><br> • Aanbieders zorgen ervoor dat hun AI-systemen met een hoog risico in overeenstemming zijn met de eisen van afdeling 2<br> • Aanbieders vermelden op het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, naargelang het geval, hun naam, geregistreerde handelsnaam of geregistreerd merk en hun contactadres<br> • Aanbieders beschikken over een systeem voor kwaliteitsbeheer dat in overeenstemming is met Artikel 17 (systeem voor kwaliteitsbeheer)<br> • Aanbieders bewaren de in Artikel 18 (bewaring van documentatie) bedoelde documentatie<br> • Aanbieders bewaren de in Artikel 19 bedoelde logs die automatisch door hun AI-systemen met een hoog risico zijn gegenereerd, wanneer zij hierover de controle hebben<br> • Aanbieders zorgen ervoor dat voor het AI-systeem met een hoog risico de desbetreffende in Artikel 43 bedoelde conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld<br> • Aanbieders stellen een EU-conformiteitsverklaring op, in overeenstemming met Artikel 47. In het geval van het label 'beoordeling door derde partij' dient de uitvoering door een conformiteitsbeoordelingsinstantie te worden verzorgd. In het geval dat het AI-systeem gebruikmaakt van biometrie en wordt ingezet door rechtshandhavingsinstanties, immigratie- of asielautoriteiten, of door instellingen, organen of instanties van de Unie, treedt de markttoezichtautoriteit op als conformiteitsbeoordelingsinstantie. <br> • Aanbieders brengen de CE-markering aan op het Ai-systeem met een hoog risico of, waneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan deze verordening is voldaan, overeenkomstig Artikel 48<br> • Aanbieders leven de registratieverplichtingen als bedoeld in Artikel 49 lid 1, na<br> • Aanbieders nemen de noodzakelijke corrigerende maatregelen en verstrekken de uit hoofde van Artikel 20 vereiste informatie<br> • Aanbieders tonen op een met redenen omkleed verzoek van een nationale bevoegde autoriteit de overeenstemming aan van het AI-systeem met een hoog risico met de eisen van afdeling 2<br> • Aanbieders zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br> <strong>Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico (Artikel 26 en Artikel 27):</strong><br> • Het nemen van passende technische en organisatorische maatregelen om te waarborgen dat dergelijke systemen in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd worden gebruikt<br> • Het opdragen van menselijk toezicht aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen<br> • Het ervoor zorgen dat, voor zover de gebruikersverantwoordelijke controle heeft over de inputdata, de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico<br> • Het monitoren van de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en in voorkomend geval het in kennis stellen van de aanbieders overeenkomstig Artikel 72.<br> • Het bewaren van de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder controle van de gebruiksverantwoordelijke vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden<br> • Voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico<br> • Gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in Artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in Artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis<br> • Indien van toepassing, gebruiken gebruiksverantwoordelijken van AI-systemen met een hoog risico de informatie die op grond van Artikel 13 van deze verordening wordt verstrekt om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren<br> • De gebruiksverantwoordelijke van een AI-systeem met een hoog risico voor biometrische identificatie op afstand verzoekt achteraf in het kader van een onderzoek waarbij gericht wordt gezocht naar een persoon die wordt verdacht van of veroordeeld is voor het plegen van een strafbaar feit, vooraf of zonder onnodige vertraging en uiterlijk 48 uur na het feit, om toestemming van een gerechtelijke instantie of administratieve instantie, van wie de beslissing bindend is en onderworpen is aan rechterlijke toetsing, voor het gebruik van dat systeem, behalve wanneer het wordt gebruikt voor de initiële identificatie van een potentiële verdachte op basis van objectieve en verifieerbare feiten die rechtstreeks verband houden met het strafbare feit. Elk gebruik wordt beperkt tot hetgeen strikt noodzakelijk is voor het onderzoek naar een specifiek strafbaar feit<br> • Gebruiksverantwoordelijken van in bijlage III bedoelde AI-systemen met een hoog risico die beslissingen met betrekking tot natuurlijke personen nemen of helpen nemen, informeren de natuurlijke personen dat het AI-systeem met een hoog risico op hen wordt toegepast.<br> • Gebruiksverantwoordelijken werken samen met de relevante bevoegde autoriteiten bij alle door deze autoriteiten genomen maatregelen met betrekking tot een AI-systeem met een hoog risico met het oog op de uitvoering van deze verordening.<br> • Gebruiksverantwoordelijken die publiekrechtelijke organen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruikt in krediet/verzekering (bijlage III, 5, c en d) een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren (Artikel 27).<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br> <strong>Verplichtingen voor aanbieders en gebruiksverantwoordelijken van AI-systemen met transparantieverplichtingen (Artikel 50):</strong><br> • Aanbieders zorgen ervoor dat AI-systemen die voor directe interactie met natuurlijke personen zijn bedoeld, zodanig worden ontworpen en ontwikkeld dat de betrokken natuurlijke personen worden geinformeerd dat zij interageren met een AI-systeem, tenzij dit duidelijk is vanuit het oogpunt van een normaal geinformeerde en redelijk omzichtige en oplettende natuurlijke persoon, rekening houdend met de omstandigheden en de gebruikscontext.<br> • Aanbieders van (GP)AI-systemen, die synthetische audio, beeld, video- of tekstinhoud genereren, zorgen ervoor dat de outputs van het AI-systeem worden gemarkeerd in een machineleesbaar formaat en detecteerbaar zijn als kunstmatig gegenereerd of gemanipuleerd. Aanbieders zorgen ervoor dat hun technische oplossingen doeltreffend, interoperabel robuust en betrouwbaar zijn voor zover dat technisch haalbaar is, rekening houdend met de specifieke kenmerken en beperkingen van de verschillende soorten content, de uitvoeringskosten en de algemeen erkende stand van de techniek, zoals tot uiting kan komen in relevante technische normen.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br> <strong>Verplichtingen voor de aanbieder van het AI-model voor algemene doeleinden, waarop het AI-systeem voor algemene doeleinden is gebaseerd (Artikel 53 en Artikel 54):</strong><br> • De technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan<br> • Informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren<br> • Beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën<br> • Een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br> <i>Geldig vanaf (Artikel 111 en Overweging 179):</i><br> • Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br> • Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
	c-14.1.2{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke en aanbieder van een hoog-risico AI-systeem voor algemene doeleinden."}}
c-14.1.2:::secondaryStyle
click c-14.1.2 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br><br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen voor aanbieder van een hoog risico AI-systeem (Artikel 16):</strong><br> • Aanbieders zorgen ervoor dat hun AI-systemen met een hoog risico in overeenstemming zijn met de eisen van afdeling 2<br> • Aanbieders vermelden op het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, naargelang het geval, hun naam, geregistreerde handelsnaam of geregistreerd merk en hun contactadres<br> • Aanbieders beschikken over een systeem voor kwaliteitsbeheer dat in overeenstemming is met Artikel 17 (systeem voor kwaliteitsbeheer)<br> • Aanbieders bewaren de in Artikel 18 (bewaring van documentatie) bedoelde documentatie<br> • Aanbieders bewaren de in Artikel 19 bedoelde logs die automatisch door hun AI-systemen met een hoog risico zijn gegenereerd, wanneer zij hierover de controle hebben<br> • Aanbieders zorgen ervoor dat voor het AI-systeem met een hoog risico de desbetreffende in Artikel 43 bedoelde conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld<br> • Aanbieders stellen een EU-conformiteitsverklaring op, in overeenstemming met Artikel 47. In het geval van het label 'beoordeling door derde partij' dient de uitvoering door een conformiteitsbeoordelingsinstantie te worden verzorgd. In het geval dat het AI-systeem gebruikmaakt van biometrie en wordt ingezet door rechtshandhavingsinstanties, immigratie- of asielautoriteiten, of door instellingen, organen of instanties van de Unie, treedt de markttoezichtautoriteit op als conformiteitsbeoordelingsinstantie. <br> • Aanbieders brengen de CE-markering aan op het Ai-systeem met een hoog risico of, waneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan deze verordening is voldaan, overeenkomstig Artikel 48<br> • Aanbieders leven de registratieverplichtingen als bedoeld in Artikel 49 lid 1, na<br> • Aanbieders nemen de noodzakelijke corrigerende maatregelen en verstrekken de uit hoofde van Artikel 20 vereiste informatie<br> • Aanbieders tonen op een met redenen omkleed verzoek van een nationale bevoegde autoriteit de overeenstemming aan van het AI-systeem met een hoog risico met de eisen van afdeling 2<br> • Aanbieders zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br> <strong>Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico (Artikel 26 en Artikel 27):</strong><br> • Het nemen van passende technische en organisatorische maatregelen om te waarborgen dat dergelijke systemen in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd worden gebruikt<br> • Het opdragen van menselijk toezicht aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen<br> • Het ervoor zorgen dat, voor zover de gebruikersverantwoordelijke controle heeft over de inputdata, de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico<br> • Het monitoren van de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en in voorkomend geval het in kennis stellen van de aanbieders overeenkomstig Artikel 72.<br> • Het bewaren van de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder controle van de gebruiksverantwoordelijke vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden<br> • Voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico<br> • Gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in Artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in Artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis<br> • Indien van toepassing, gebruiken gebruiksverantwoordelijken van AI-systemen met een hoog risico de informatie die op grond van Artikel 13 van deze verordening wordt verstrekt om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren<br> • De gebruiksverantwoordelijke van een AI-systeem met een hoog risico voor biometrische identificatie op afstand verzoekt achteraf in het kader van een onderzoek waarbij gericht wordt gezocht naar een persoon die wordt verdacht van of veroordeeld is voor het plegen van een strafbaar feit, vooraf of zonder onnodige vertraging en uiterlijk 48 uur na het feit, om toestemming van een gerechtelijke instantie of administratieve instantie, van wie de beslissing bindend is en onderworpen is aan rechterlijke toetsing, voor het gebruik van dat systeem, behalve wanneer het wordt gebruikt voor de initiële identificatie van een potentiële verdachte op basis van objectieve en verifieerbare feiten die rechtstreeks verband houden met het strafbare feit. Elk gebruik wordt beperkt tot hetgeen strikt noodzakelijk is voor het onderzoek naar een specifiek strafbaar feit<br> • Gebruiksverantwoordelijken van in bijlage III bedoelde AI-systemen met een hoog risico die beslissingen met betrekking tot natuurlijke personen nemen of helpen nemen, informeren de natuurlijke personen dat het AI-systeem met een hoog risico op hen wordt toegepast.<br> • Gebruiksverantwoordelijken werken samen met de relevante bevoegde autoriteiten bij alle door deze autoriteiten genomen maatregelen met betrekking tot een AI-systeem met een hoog risico met het oog op de uitvoering van deze verordening.<br> • Gebruiksverantwoordelijken die publiekrechtelijke organen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruikt in krediet/verzekering (bijlage III, 5, c en d) een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren (Artikel 27).<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br> <strong>Verplichtingen voor de aanbieder van het AI-model voor algemene doeleinden, waarop het AI-systeem voor algemene doeleinden is gebaseerd (Artikel 53 en Artikel 54):</strong><br> • De technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan<br> • Informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren<br> • Beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën<br> • Een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br> <i>Geldig vanaf (Artikel 111 en Overweging 179):</i><br> • Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br> • Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
	c-14.1.3{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke en aanbieder van een niet-hoog-risico AI-systeem voor algemene doeleinden met transparantieverplichtingen."}}
c-14.1.3:::secondaryStyle
click c-14.1.3 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br><br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen voor aanbieders en gebruiksverantwoordelijken van AI-systemen met transparantieverplichtingen (Artikel 50):</strong><br> • Aanbieders zorgen ervoor dat AI-systemen die voor directe interactie met natuurlijke personen zijn bedoeld, zodanig worden ontworpen en ontwikkeld dat de betrokken natuurlijke personen worden geinformeerd dat zij interageren met een AI-systeem, tenzij dit duidelijk is vanuit het oogpunt van een normaal geinformeerde en redelijk omzichtige en oplettende natuurlijke persoon, rekening houdend met de omstandigheden en de gebruikscontext.<br> • Aanbieders van (GP)AI-systemen, die synthetische audio, beeld, video- of tekstinhoud genereren, zorgen ervoor dat de outputs van het AI-systeem worden gemarkeerd in een machineleesbaar formaat en detecteerbaar zijn als kunstmatig gegenereerd of gemanipuleerd. Aanbieders zorgen ervoor dat hun technische oplossingen doeltreffend, interoperabel robuust en betrouwbaar zijn voor zover dat technisch haalbaar is, rekening houdend met de specifieke kenmerken en beperkingen van de verschillende soorten content, de uitvoeringskosten en de algemeen erkende stand van de techniek, zoals tot uiting kan komen in relevante technische normen.<br><br> <i>Geldig vanaf (Artikel 111):</i><br> • Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br> • Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br> <strong>Verplichtingen voor de aanbieder van het AI-model voor algemene doeleinden, waarop het AI-systeem voor algemene doeleinden is gebaseerd (Artikel 53 en Artikel 54):</strong><br> • De technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan<br> • Informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren<br> • Beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën<br> • Een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br> <i>Geldig vanaf (Artikel 111 en Overweging 179):</i><br> • Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br> • Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
	c-14.1.4{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke en aanbieder van een niet-hoog-risico AI-systeem voor algemene doeleinden."}}
c-14.1.4:::secondaryStyle
click c-14.1.4 callback " <strong>Verplichtingen voor alle AI-systemen:</strong><br> • AI-geletterdheid (Artikel 4)<br> • Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br><br> <i>Geldig vanaf:</i><br> • AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen voor de aanbieder van het AI-model voor algemene doeleinden, waarop het AI-systeem voor algemene doeleinden is gebaseerd (Artikel 53 en Artikel 54):</strong><br> • De technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan<br> • Informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren<br> • Beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën<br> • Een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br> <i>Geldig vanaf (Artikel 111 en Overweging 179):</i><br> • Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br> • Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
	c-14.2.1{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder en gebruiksverantwoordelijke van een AI-model voor algemene doeleinden met een systeemrisico."}}
c-14.2.1:::secondaryStyle
click c-14.2.1 callback " <strong>Verplichtingen voor alle AI-modellen voor algemene doeleinden:</strong><br> • Praktijkcodes (Artikel 56)<br><br> <strong>Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden (Artikel 53 en Artikel 54):</strong><br> • De technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan.<br> • Informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.<br> • Beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën.<br> • Een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br> <strong>Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico (Artikel 55):</strong><br> • Het uitvoeren van een modelevaluatie overeenkomstig gestandaardiseerde protocollen en instrumenten die de stand van de techniek weerspiegelen, met inbegrip van het uitvoeren en documenteren van tests gericht op het ontdekken van kwetsbaarheden van het model met als doel om systeemrisico’s in kaart te brengen en te beperken.<br> • Het beoordelen en beperken van mogelijke systeemrisico’s op Unieniveau, met inbegrip van de bronnen daarvan, die kunnen voortvloeien uit de ontwikkeling, het in de handel brengen of het gebruik van AI-modellen voor algemene doeleinden met een systeemrisico.<br> • Het bijhouden, documenteren en onverwijld rapporteren (aan het AI-bureau (en in voorkomende gevallen aan de nationale bevoegde autoriteiten)) van relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen.<br> • Het zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden en de fysieke infrastructuur van het model.<br><br> <i>Geldig vanaf (Artikel 111 en Overweging 179):</i><br> • Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br> • Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
	c-14.2.2{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder en gebruiksverantwoordelijke van een AI-model voor algemene doeleinden."}}
c-14.2.2:::secondaryStyle
click c-14.2.2 callback " <strong>Verplichtingen voor alle AI-modellen voor algemene doeleinden:</strong><br> • Praktijkcodes (Artikel 56)<br><br> <strong>Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden (Artikel 53 en Artikel 54):</strong><br> • Beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën.<br> • Een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br>
Door overweging 104 voor open-source AI-modellen voor algemene doeleinden hoef je niet te voldoen aan (delen van Artikel 53 en Artikel 54): <br> • De technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan.<br> • Informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.<br><br> <i>Geldig vanaf (Artikel 111 en Overweging 179):</i><br> • Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br> • Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
	c-14.2.3{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder en gebruiksverantwoordelijke van een AI-model voor algemene doeleinden."}}
c-14.2.3:::secondaryStyle
click c-14.2.3 callback " <strong>Verplichtingen voor alle AI-modellen voor algemene doeleinden:</strong><br> • Praktijkcodes (Artikel 56)<br><br> <i>Geldig vanaf:</i><br> • Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br> <strong>Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden (Artikel 53 en Artikel 54):</strong><br> • De technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan. <br> • Informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren. <br> • Beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën.<br> • Een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br>
Aangezien het geen open-source toepassing is, gelden er geen uitzonderingen. <br><br> <i>Geldig vanaf (Artikel 111 en Overweging 179):</i><br> • Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br> • Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
	c-15.0.0{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent importeur van een verboden AI-systeem."}}
c-15.0.0:::secondaryStyle
click c-15.0.0 callback "Het AI-systeem moet van de markt worden gehaald en het gebruik ervan stop gezet. <strong>Let op:</strong>  dit geldt vanaf 1 februari 2025."
	c-15.0.1{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een importeur van een AI-systeem een hoog risico."}}
c-15.0.1:::secondaryStyle
click c-15.0.1 callback " <strong>Verplichtingen voor importeur van een hoog risico AI-systeem (Artikel 23):</strong><br> • Importeurs zorgen ervoor dat een AI-systeem met een hoog risico in overeenstemming is met de verordening voordat het in de handel wordt gebracht door na te gaan of de relevante conformiteitsbeoordelingsprocedure is uitgevoerd (Artikel 43), de technische documentatie is opgesteld (Artikel 11 en bijlage IV), de CE-markering is aangebracht en de EU-conformiteitsverklaring en gebruiksaanwijzingen aanwezig zijn (Artikel 47), en of de aanbieder een gemachtigde heeft aangewezen (Artikel 22, lid 1).<br> • Indien een importeur vermoedt dat het AI-systeem met een hoog risico niet in overeenstemming is met de verordening, vervalst is of vergezeld gaat van vervalste documenten, mag het systeem niet in de handel worden gebracht totdat het aan de eisen voldoet. Als het systeem een risico vormt (Artikel 79, lid 1), moet de importeur de aanbieder, gemachtigden en markttoezichtautoriteiten informeren.<br> • Importeurs moeten hun naam, geregistreerde handelsnaam of merk en contactadres vermelden op de verpakking of in de bijgevoegde documentatie van het AI-systeem met een hoog risico.<br> • Importeurs zorgen ervoor dat de opslag- en vervoersomstandigheden van het AI-systeem met een hoog risico de naleving van de eisen van afdeling 2 niet in gevaar brengen.<br> • Importeurs moeten gedurende tien jaar een kopie bewaren van het door de aangemelde instantie afgegeven certificaat en, indien van toepassing, de gebruiksaanwijzing en de EU-conformiteitsverklaring (Artikel 47).<br> • Bij verzoek van bevoegde autoriteiten moeten importeurs alle benodigde informatie en documentatie verstrekken ter staving van de naleving van de eisen van afdeling 2, in een voor de autoriteit begrijpelijke taal.<br> • Importeurs werken samen met bevoegde autoriteiten bij het nemen van maatregelen om de risico’s van het AI-systeem te verminderen en te beperken.<br>"
	c-15.0.3{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een importeur van een niet-hoog-risico AI-systeem."}}
c-15.0.3:::secondaryStyle
click c-15.0.3 callback "Er zijn geen verplichtingen voor importeurs van niet-hoog-risico AI-systemen, alleen voor hoog-risico. In de bronnen is Artikel 23 opgenomen, deze bevat de verplichtingen voor importeurs van hoog-risico AI-systemen ter informatie ter informatie."
	c-15.1.1{{"Je bent een importeur van een hoog risico AI-systeem voor algemene doeleinden."}}
c-15.1.1:::secondaryStyle
click c-15.1.1 callback " <strong>Verplichtingen voor importeur van een hoog risico AI-systeem (Artikel 23):</strong><br> • Importeurs zorgen ervoor dat een AI-systeem met een hoog risico in overeenstemming is met de verordening voordat het in de handel wordt gebracht door na te gaan of de relevante conformiteitsbeoordelingsprocedure is uitgevoerd (Artikel 43), de technische documentatie is opgesteld (Artikel 11 en bijlage IV), de CE-markering is aangebracht en de EU-conformiteitsverklaring en gebruiksaanwijzingen aanwezig zijn (Artikel 47), en of de aanbieder een gemachtigde heeft aangewezen (Artikel 22, lid 1).<br> • Indien een importeur vermoedt dat het AI-systeem met een hoog risico niet in overeenstemming is met de verordening, vervalst is of vergezeld gaat van vervalste documenten, mag het systeem niet in de handel worden gebracht totdat het aan de eisen voldoet. Als het systeem een risico vormt (Artikel 79, lid 1), moet de importeur de aanbieder, gemachtigden en markttoezichtautoriteiten informeren.<br> • Importeurs moeten hun naam, geregistreerde handelsnaam of merk en contactadres vermelden op de verpakking of in de bijgevoegde documentatie van het AI-systeem met een hoog risico.<br> • Importeurs zorgen ervoor dat de opslag- en vervoersomstandigheden van het AI-systeem met een hoog risico de naleving van de eisen van afdeling 2 niet in gevaar brengen.<br> • Importeurs moeten gedurende tien jaar een kopie bewaren van het door de aangemelde instantie afgegeven certificaat en, indien van toepassing, de gebruiksaanwijzing en de EU-conformiteitsverklaring (Artikel 47).<br> • Bij verzoek van bevoegde autoriteiten moeten importeurs alle benodigde informatie en documentatie verstrekken ter staving van de naleving van de eisen van afdeling 2, in een voor de autoriteit begrijpelijke taal.<br> • Importeurs werken samen met bevoegde autoriteiten bij het nemen van maatregelen om de risico’s van het AI-systeem te verminderen en te beperken.<br>"
	c-15.1.3{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een importeur van een niet-hoog-risico AI-systeem voor algemene doeleinden."}}
c-15.1.3:::secondaryStyle
click c-15.1.3 callback "Er zijn geen verplichtingen voor importeurs van niet-hoog-risico AI-systemen voor algemene doeleinden, alleen voor hoog-risico. In de bronnen is Artikel 23 opgenomen, deze bevat de verplichtingen voor importeurs van hoog-risico AI-systemen ter informatie."
	c-15.2.1{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een importeur van een AI-model voor algemene doeleinden."}}
c-15.2.1:::secondaryStyle
click c-15.2.1 callback "Er zijn geen verplichtingen voor importeurs van AI-modellen voor algemene doeleinden, alleen voor hoog-risico AI-systemen. In de bronnen is Artikel 23 opgenomen, deze bevat de verplichtingen voor importeurs van hoog-risico AI-systemen ter informatie."
	c-16.0.0{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent distributeur van een verboden AI-systeem."}}
c-16.0.0:::secondaryStyle
click c-16.0.0 callback "Het AI-systeem moet van de markt worden gehaald en het gebruik ervan stop gezet. <strong>Let op: </strong>  dit geldt vanaf 1 februari 2025."
	c-16.0.1{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een distributeur van een hoog-risico AI-systeem."}}
c-16.0.1:::secondaryStyle
click c-16.0.1 callback " <strong>Verplichtingen voor distributeur van een hoog risico AI-systeem (Artikel 24):</strong><br> • Distributeurs controleren of het AI-systeem met een hoog risico de vereiste CE-markering heeft, vergezeld gaat van de EU-conformiteitsverklaring en gebruiksinstructies, en of de aanbieder en importeur hun verplichtingen uit Artikel 16 (b en c) en Artikel 23 (3) hebben nageleefd.<br> • Wanneer een distributeur vermoedt dat een AI-systeem met een hoog risico niet voldoet aan de eisen, mag het systeem niet op de markt worden gebracht totdat het in overeenstemming is gebracht met de vereisten en de aanbieder of importeur moet worden geïnformeerd als het systeem een risico vormt (Artikel 79 (1)).<br> • Distributeurs zorgen ervoor dat de opslag- en vervoersomstandigheden van het AI-systeem met een hoog risico geen invloed hebben op de naleving van de eisen van afdeling 2.<br> • Wanneer een distributeur vermoedt dat een AI-systeem met een hoog risico niet voldoet aan de eisen na het op de markt te hebben gebracht, moet de distributeur corrigerende maatregelen nemen of zorgen dat de aanbieder/importeur dit doet, zoals het systeem uit de handel nemen of terugroepen, en de bevoegde autoriteiten informeren.<br> • Distributeurs moeten op verzoek van bevoegde autoriteiten de nodige informatie en documentatie verstrekken om aan te tonen dat het AI-systeem voldoet aan de eisen van afdeling 2.<br> • Distributeurs werken samen met de bevoegde autoriteiten met betrekking tot maatregelen die genomen worden om de risico's van het AI-systeem dat zij op de markt hebben aangeboden te verminderen of te beperken."
	c-16.0.3{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een distributeur van een niet-hoog-risico AI-systeem."}}
c-16.0.3:::secondaryStyle
click c-16.0.3 callback "Er zijn geen verplichtingen voor distributeurs van niet-hoog-risico AI-systemen, alleen voor hoog-risico. In de bronnen is Artikel 24 opgenomen, deze bevat de verplichtingen voor distributeurs van hoog-risico AI-systemen ter informatie."
	c-16.1.1{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een distributeur van een hoog-risico AI-systeem voor algemene doeleinden."}}
c-16.1.1:::secondaryStyle
click c-16.1.1 callback " <strong>Verplichtingen voor distributeur van een hoog risico AI-systeem (Artikel 24):</strong><br> • Distributeurs controleren of het AI-systeem met een hoog risico de vereiste CE-markering heeft, vergezeld gaat van de EU-conformiteitsverklaring en gebruiksinstructies, en of de aanbieder en importeur hun verplichtingen uit Artikel 16 (b en c) en Artikel 23 (3) hebben nageleefd.<br> • Wanneer een distributeur vermoedt dat een AI-systeem met een hoog risico niet voldoet aan de eisen, mag het systeem niet op de markt worden gebracht totdat het in overeenstemming is gebracht met de vereisten en de aanbieder of importeur moet worden geïnformeerd als het systeem een risico vormt (Artikel 79 (1)).<br> • Distributeurs zorgen ervoor dat de opslag- en vervoersomstandigheden van het AI-systeem met een hoog risico geen invloed hebben op de naleving van de eisen van afdeling 2.<br> • Wanneer een distributeur vermoedt dat een AI-systeem met een hoog risico niet voldoet aan de eisen na het op de markt te hebben gebracht, moet de distributeur corrigerende maatregelen nemen of zorgen dat de aanbieder/importeur dit doet, zoals het systeem uit de handel nemen of terugroepen, en de bevoegde autoriteiten informeren.<br> • Distributeurs moeten op verzoek van bevoegde autoriteiten de nodige informatie en documentatie verstrekken om aan te tonen dat het AI-systeem voldoet aan de eisen van afdeling 2.<br> • Distributeurs werken samen met de bevoegde autoriteiten met betrekking tot maatregelen die genomen worden om de risico's van het AI-systeem dat zij op de markt hebben aangeboden te verminderen of te beperken."
	c-16.1.3{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een distributeur van een niet-hoog-risico AI-systeem voor algemene doeleinden."}}
c-16.1.3:::secondaryStyle
click c-16.1.3 callback "Er zijn geen verplichtingen voor distributeurs van niet-hoog-risico AI-systemen, alleen voor hoog-risico. In de bronnen is Artikel 24 opgenomen, deze bevat de verplichtingen voor distributeurs van hoog-risico AI-systemen ter informatie."
	c-16.2.1{{"Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een distributeur van een AI-model voor algemene doeleinden."}}
c-16.2.1:::secondaryStyle
click c-16.2.1 callback "Er zijn geen verplichtingen voor distributeurs van AI-model voor algemene doeleinden, alleen voor hoog-risico AI-systemen. In de bronnen is Artikel 24 opgenomen, deze bevat de verplichtingen voor distributeurs van hoog-risico AI-systemen ter informatie."
	q-1.1 -->|Ja
| q-1.2
	q-1.1 -->|Nee

Opgehaalde labels: geen algoritme| c-11.0
	q-1.2 -->|We ontwikkelen enkel

Opgehaalde labels: aanbieder| q-1.3
	q-1.2 -->|We ontwikkelen, maar gebruiken het niet alleen zelf

Opgehaalde labels: aanbieder, gebruiksverantwoordelijke| q-1.3
	q-1.2 -->|We ontwikkelen en gebruiken het zelf

Opgehaalde labels: aanbieder, gebruiksverantwoordelijke| q-1.3
	q-1.2 -->|We hebben opdracht gegeven om de toepassing te ontwikkelen

Opgehaalde labels: aanbieder| q-1.3
	q-1.2 -->|We gebruiken een extern ontwikkelde toepassing zonder aanpassingen

Opgehaalde labels: gebruiksverantwoordelijke| q-1.3
	q-1.2 -->|We gebruiken een extern ontwikkelde toepassing met aanpassingen

Opgehaalde labels: aanbieder, gebruiksverantwoordelijke| q-1.3
	q-1.2 -->|We importeren van een leverancier buiten de EU

Opgehaalde labels: importeur| q-1.3
	q-1.2 -->|We kopen van een leverancier binnen de EU en verkopen het

Opgehaalde labels: distributeur| q-1.3
	q-1.2 -->|Geen van bovenstaande
| c-11.3
	q-1.3 -->|In gebruik

Opgehaalde labels: in gebruik| q-1.4.1
	q-1.3 -->|In ontwikkeling

Opgehaalde labels: in ontwikkeling| q-1.4.1
	q-1.4.1 -->|Ja, het is een AI-systeem

Opgehaalde labels: AI-systeem| q-1.5
	q-1.4.1 -->|Nee, het is geen AI-systeem
| q-1.4.2
	q-1.4.1 -->|Ik weet het niet
| q-1.6.1
	q-1.4.2 -->|AI-systeem voor algemene doeleinden

Opgehaalde labels: AI-systeem voor algemene doeleinden| q-1.5
	q-1.4.2 -->|AI-model voor algemene doeleinden

Opgehaalde labels: AI-model voor algemene doeleinden
Als: aanbieder of gebruiksverantwoordelijke.| q-1.5
	q-1.4.2 -->|AI-model voor algemene doeleinden

Opgehaalde labels: AI-model voor algemene doeleinden
Als: distributeur.| c-16.2.1
	q-1.4.2 -->|AI-model voor algemene doeleinden

Opgehaalde labels: AI-model voor algemene doeleinden
Als: importeur.| c-15.2.1
	q-1.4.2 -->|Geen van bovenstaande
| c-11.1
	q-1.5 -->|Ja

Opgehaalde labels: uitzondering van toepassing| c-11.2
	q-1.5 -->|Nee

Als: AI-systeem of AI-systeem voor algemene doeleinden of AI-model voor algemene doeleinden.| q-2.0
	q-1.5 -->|Nee

Als: AI-model voor algemene doeleinden en gebruiksverantwoordelijke.| c-13.2.1
	q-1.6.1 -->|Ja
| c-11.1
	q-1.6.1 -->|Nee
| q-1.6.2
	q-1.6.2 -->|Ja
| q-1.6.3
	q-1.6.2 -->|Nee
| c-11.1
	q-1.6.3 -->|Ja

Opgehaalde labels: AI-systeem| q-1.5
	q-1.6.3 -->|Nee
| c-11.1
	q-2.0 -->|Naar risicogroep bepaling

Als: AI-systeem of AI-systeem voor algemene doeleinden.| q-2.1
	q-2.0 -->|Naar risicogroep bepaling

Als: AI-model voor algemene doeleinden.| q-2.8
	q-2.1 -->|Ja
| q-2.2
	q-2.1 -->|Nee
| q-2.3
	q-2.2 -->|Ja

Als: aanbieder of gebruiksverantwoordelijke.| q-2.3
	q-2.2 -->|Ja

Als: distributeur en AI-systeem.| c-16.0.1
	q-2.2 -->|Ja

Als: distributeur en AI-systeem voor algemene doeleinden.| c-16.1.1
	q-2.2 -->|Ja

Als: importeur en AI-systeem.| c-15.0.1
	q-2.2 -->|Ja

Als: importeur en AI-systeem voor algemene doeleinden.| c-15.1.1
	q-2.2 -->|Nee

Opgehaalde labels: verboden AI
Als: aanbieder en gebruiksverantwoordelijke.| c-14.0.0
	q-2.2 -->|Nee

Opgehaalde labels: verboden AI
Als: aanbieder.| c-12.0.0
	q-2.2 -->|Nee

Opgehaalde labels: verboden AI
Als: gebruiksverantwoordelijke.| c-13.0.0
	q-2.2 -->|Nee

Opgehaalde labels: verboden AI
Als: importeur.| c-15.0.0
	q-2.2 -->|Nee

Opgehaalde labels: verboden AI
Als: distributeur.| c-16.0.0
	q-2.3 -->|Ja Sectie A van Bijlage I

Opgehaalde labels: hoog-risico AI
Als: aanbieder of gebruiksverantwoordelijke.| q-2.7.1
	q-2.3 -->|Ja Sectie A van Bijlage I

Opgehaalde labels: hoog-risico AI
Als: distributeur en AI-systeem.| c-16.0.1
	q-2.3 -->|Ja Sectie A van Bijlage I

Opgehaalde labels: hoog-risico AI
Als: distributeur en AI-systeem voor algemene doeleinden.| c-16.1.1
	q-2.3 -->|Ja Sectie A van Bijlage I

Opgehaalde labels: hoog-risico AI
Als: importeur en AI-systeem.| c-15.0.1
	q-2.3 -->|Ja Sectie A van Bijlage I

Opgehaalde labels: hoog-risico AI
Als: importeur en AI-systeem voor algemene doeleinden.| c-15.1.1
	q-2.3 -->|Ja Sectie B van Bijlage I

Opgehaalde labels: hoog-risico AI
Als: aanbieder of gebruiksverantwoordelijke.| q-2.9
	q-2.3 -->|Ja Sectie B van Bijlage I

Opgehaalde labels: hoog-risico AI
Als: distributeur en AI-systeem.| c-16.0.1
	q-2.3 -->|Ja Sectie B van Bijlage I

Opgehaalde labels: hoog-risico AI
Als: distributeur en AI-systeem voor algemene doeleinden.| c-16.1.1
	q-2.3 -->|Ja Sectie B van Bijlage I

Opgehaalde labels: hoog-risico AI
Als: importeur en AI-systeem.| c-15.0.1
	q-2.3 -->|Ja Sectie B van Bijlage I

Opgehaalde labels: hoog-risico AI
Als: importeur en AI-systeem voor algemene doeleinden.| c-15.1.1
	q-2.3 -->|Geen van beide
| q-2.4
	q-2.4 -->|Ja
| q-2.7.2
	q-2.4 -->|Nee

Opgehaalde labels: geen hoog-risico AI
Als: aanbieder of gebruiksverantwoordelijke.| q-2.11
	q-2.4 -->|Nee

Opgehaalde labels: geen hoog-risico AI
Als: distributeur en AI-systeem.| c-16.0.3
	q-2.4 -->|Nee

Opgehaalde labels: geen hoog-risico AI
Als: distributeur en AI-systeem voor algemene doeleinden.| c-16.1.3
	q-2.4 -->|Nee

Opgehaalde labels: geen hoog-risico AI
Als: importeur en AI-systeem.| c-15.0.3
	q-2.4 -->|Nee

Opgehaalde labels: geen hoog-risico AI
Als: importeur en AI-systeem voor algemene doeleinden.| c-15.1.3
	q-2.5 -->|Ja

Opgehaalde labels: hoog-risico AI
Als: aanbieder of gebruiksverantwoordelijke.| q-2.9
	q-2.5 -->|Ja

Opgehaalde labels: hoog-risico AI
Als: distributeur en AI-systeem.| c-16.0.1
	q-2.5 -->|Ja

Opgehaalde labels: hoog-risico AI
Als: distributeur en AI-systeem voor algemene doeleinden.| c-16.1.1
	q-2.5 -->|Ja

Opgehaalde labels: hoog-risico AI
Als: importeur en AI-systeem.| c-15.0.1
	q-2.5 -->|Ja

Opgehaalde labels: hoog-risico AI
Als: importeur en AI-systeem voor algemene doeleinden.| c-15.1.1
	q-2.5 -->|Nee
| q-2.6
	q-2.6 -->|Ja

Opgehaalde labels: geen hoog-risico AI
Als: aanbieder of gebruiksverantwoordelijke.| q-2.11
	q-2.6 -->|Ja

Opgehaalde labels: geen hoog-risico AI
Als: distributeur en AI-systeem.| c-16.0.3
	q-2.6 -->|Ja

Opgehaalde labels: geen hoog-risico AI
Als: distributeur en AI-systeem voor algemene doeleinden.| c-16.1.3
	q-2.6 -->|Ja

Opgehaalde labels: geen hoog-risico AI
Als: importeur en AI-systeem.| c-15.0.3
	q-2.6 -->|Ja

Opgehaalde labels: geen hoog-risico AI
Als: importeur en AI-systeem voor algemene doeleinden.| c-15.1.3
	q-2.6 -->|Nee

Opgehaalde labels: hoog-risico AI
Als: aanbieder of gebruiksverantwoordelijke.| q-2.9
	q-2.6 -->|Nee

Opgehaalde labels: hoog-risico AI
Als: distributeur en AI-systeem.| c-16.0.1
	q-2.6 -->|Nee

Opgehaalde labels: hoog-risico AI
Als: distributeur en AI-systeem voor algemene doeleinden.| c-16.1.1
	q-2.6 -->|Nee

Opgehaalde labels: hoog-risico AI
Als: importeur en AI-systeem.| c-15.0.1
	q-2.6 -->|Nee

Opgehaalde labels: hoog-risico AI
Als: importeur en AI-systeem voor algemene doeleinden.| c-15.1.1
	q-2.7.1 -->|Ja

Opgehaalde labels: beoordeling door derde partij| q-2.9
	q-2.7.1 -->|Nee

Opgehaalde labels: niet van toepassing| q-2.9
	q-2.7.2 -->|Ja

Opgehaalde labels: beoordeling door derde partij| q-2.5
	q-2.7.2 -->|Nee

Opgehaalde labels: niet van toepassing| q-2.5
	q-2.8 -->|Ja

Opgehaalde labels: systeemrisico
Als: aanbieder en gebruiksverantwoordelijke.| c-14.2.1
	q-2.8 -->|Ja

Opgehaalde labels: systeemrisico
Als: gebruiksverantwoordelijke.| c-13.2.1
	q-2.8 -->|Ja

Opgehaalde labels: systeemrisico
Als: aanbieder.| c-12.2.1
	q-2.8 -->|Nee

Opgehaalde labels: geen systeemrisico
Als: aanbieder.| q-2.11
	q-2.8 -->|Nee

Opgehaalde labels: geen systeemrisico
Als: gebruiksverantwoordelijke.| c-13.2.1
	q-2.9 -->|Ja
| q-2.10
	q-2.9 -->|Nee

Opgehaalde labels: geen transparantieverplichting
Als: open-source en geen open-source en hoog-risico AI.| q-2.11
	q-2.9 -->|Nee

Opgehaalde labels: geen transparantieverplichting
Als: AI-systeem of AI-systeem voor algemene doeleinden en open-source en geen hoog-risico AI.| c-11.2
	q-2.9 -->|Nee

Opgehaalde labels: geen transparantieverplichting
Als: aanbieder en gebruiksverantwoordelijke en AI-systeem en hoog-risico AI.| c-14.0.2
	q-2.9 -->|Nee

Opgehaalde labels: geen transparantieverplichting
Als: aanbieder en gebruiksverantwoordelijke en AI-systeem en geen hoog-risico AI.| c-14.0.4
	q-2.9 -->|Nee

Opgehaalde labels: geen transparantieverplichting
Als: aanbieder en gebruiksverantwoordelijke en AI-systeem voor algemene doeleinden en hoog-risico AI.| c-14.1.2
	q-2.9 -->|Nee

Opgehaalde labels: geen transparantieverplichting
Als: aanbieder en gebruiksverantwoordelijke en AI-systeem voor algemene doeleinden en geen hoog-risico AI.| c-14.1.4
	q-2.9 -->|Nee

Opgehaalde labels: geen transparantieverplichting
Als: gebruiksverantwoordelijke en AI-systeem en hoog-risico AI.| c-13.0.2
	q-2.9 -->|Nee

Opgehaalde labels: geen transparantieverplichting
Als: gebruiksverantwoordelijke en AI-systeem en geen hoog-risico AI.| c-13.0.4
	q-2.9 -->|Nee

Opgehaalde labels: geen transparantieverplichting
Als: gebruiksverantwoordelijke en AI-systeem voor algemene doeleinden en hoog-risico AI.| c-13.1.2
	q-2.9 -->|Nee

Opgehaalde labels: geen transparantieverplichting
Als: gebruiksverantwoordelijke en AI-systeem voor algemene doeleinden en geen hoog-risico AI.| c-13.1.4
	q-2.9 -->|Nee

Opgehaalde labels: geen transparantieverplichting
Als: aanbieder en AI-systeem en hoog-risico AI.| c-12.0.2
	q-2.9 -->|Nee

Opgehaalde labels: geen transparantieverplichting
Als: aanbieder en AI-systeem en geen hoog-risico AI.| c-12.0.4
	q-2.9 -->|Nee

Opgehaalde labels: geen transparantieverplichting
Als: aanbieder en AI-systeem voor algemene doeleinden en hoog-risico AI.| c-12.1.2
	q-2.9 -->|Nee

Opgehaalde labels: geen transparantieverplichting
Als: aanbieder en AI-systeem voor algemene doeleinden en geen hoog-risico AI.| c-12.1.4
	q-2.10 -->|Ja

Opgehaalde labels: geen transparantieverplichting
Als: open-source en geen open-source en hoog-risico AI.| q-2.11
	q-2.10 -->|Ja

Opgehaalde labels: geen transparantieverplichting
Als: AI-systeem of AI-systeem voor algemene doeleinden en open-source en geen hoog-risico AI.| c-11.2
	q-2.10 -->|Ja

Opgehaalde labels: geen transparantieverplichting
Als: aanbieder en gebruiksverantwoordelijke en AI-systeem en hoog-risico AI.| c-14.0.2
	q-2.10 -->|Ja

Opgehaalde labels: geen transparantieverplichting
Als: aanbieder en gebruiksverantwoordelijke en AI-systeem en geen hoog-risico AI.| c-14.0.4
	q-2.10 -->|Ja

Opgehaalde labels: geen transparantieverplichting
Als: aanbieder en gebruiksverantwoordelijke en AI-systeem voor algemene doeleinden en hoog-risico AI.| c-14.1.2
	q-2.10 -->|Ja

Opgehaalde labels: geen transparantieverplichting
Als: aanbieder en gebruiksverantwoordelijke en AI-systeem voor algemene doeleinden en geen hoog-risico AI.| c-14.1.4
	q-2.10 -->|Ja

Opgehaalde labels: geen transparantieverplichting
Als: gebruiksverantwoordelijke en AI-systeem en hoog-risico AI.| c-13.0.2
	q-2.10 -->|Ja

Opgehaalde labels: geen transparantieverplichting
Als: gebruiksverantwoordelijke en AI-systeem en geen hoog-risico AI.| c-13.0.4
	q-2.10 -->|Ja

Opgehaalde labels: geen transparantieverplichting
Als: gebruiksverantwoordelijke en AI-systeem voor algemene doeleinden en hoog-risico AI.| c-13.1.2
	q-2.10 -->|Ja

Opgehaalde labels: geen transparantieverplichting
Als: gebruiksverantwoordelijke en AI-systeem voor algemene doeleinden en geen hoog-risico AI.| c-13.1.4
	q-2.10 -->|Ja

Opgehaalde labels: geen transparantieverplichting
Als: aanbieder en AI-systeem en hoog-risico AI.| c-12.0.2
	q-2.10 -->|Ja

Opgehaalde labels: geen transparantieverplichting
Als: aanbieder en AI-systeem en geen hoog-risico AI.| c-12.0.4
	q-2.10 -->|Ja

Opgehaalde labels: geen transparantieverplichting
Als: aanbieder en AI-systeem voor algemene doeleinden en hoog-risico AI.| c-12.1.2
	q-2.10 -->|Ja

Opgehaalde labels: geen transparantieverplichting
Als: aanbieder en AI-systeem voor algemene doeleinden en geen hoog-risico AI.| c-12.1.4
	q-2.10 -->|Nee

Opgehaalde labels: transparantieverplichting
Als: aanbieder en gebruiksverantwoordelijke en AI-systeem en hoog-risico AI.| c-14.0.1
	q-2.10 -->|Nee

Opgehaalde labels: transparantieverplichting
Als: aanbieder en gebruiksverantwoordelijke en AI-systeem en geen hoog-risico AI.| c-14.0.3
	q-2.10 -->|Nee

Opgehaalde labels: transparantieverplichting
Als: aanbieder en gebruiksverantwoordelijke en AI-systeem voor algemene doeleinden en hoog-risico AI.| c-14.1.1
	q-2.10 -->|Nee

Opgehaalde labels: transparantieverplichting
Als: aanbieder en gebruiksverantwoordelijke en AI-systeem voor algemene doeleinden en geen hoog-risico AI.| c-14.1.3
	q-2.10 -->|Nee

Opgehaalde labels: transparantieverplichting
Als: gebruiksverantwoordelijke en AI-systeem en hoog-risico AI.| c-13.0.1
	q-2.10 -->|Nee

Opgehaalde labels: transparantieverplichting
Als: gebruiksverantwoordelijke en AI-systeem en geen hoog-risico AI.| c-13.0.3
	q-2.10 -->|Nee

Opgehaalde labels: transparantieverplichting
Als: gebruiksverantwoordelijke en AI-systeem voor algemene doeleinden en hoog-risico AI.| c-13.1.1
	q-2.10 -->|Nee

Opgehaalde labels: transparantieverplichting
Als: gebruiksverantwoordelijke en AI-systeem voor algemene doeleinden en geen hoog-risico AI.| c-13.1.3
	q-2.10 -->|Nee

Opgehaalde labels: transparantieverplichting
Als: aanbieder en AI-systeem en hoog-risico AI.| c-12.0.1
	q-2.10 -->|Nee

Opgehaalde labels: transparantieverplichting
Als: aanbieder en AI-systeem en geen hoog-risico AI.| c-12.0.3
	q-2.10 -->|Nee

Opgehaalde labels: transparantieverplichting
Als: aanbieder en AI-systeem voor algemene doeleinden en hoog-risico AI.| c-12.1.1
	q-2.10 -->|Nee

Opgehaalde labels: transparantieverplichting
Als: aanbieder en AI-systeem voor algemene doeleinden en geen hoog-risico AI.| c-12.1.3
	q-2.11 -->|Ja

Opgehaalde labels: open-source
Als: AI-systeem of AI-systeem voor algemene doeleinden en geen transparantieverplichting en geen hoog-risico AI.| c-11.2
	q-2.11 -->|Ja

Opgehaalde labels: open-source
Als: aanbieder en gebruiksverantwoordelijke en AI-model voor algemene doeleinden.| c-14.2.2
	q-2.11 -->|Ja

Opgehaalde labels: open-source
Als: aanbieder en AI-model voor algemene doeleinden.| c-12.2.2
	q-2.11 -->|Ja

Opgehaalde labels: open-source
Als: transparantieverplichting en geen transparantieverplichting en AI-model voor algemene doeleinden.| q-2.9
	q-2.11 -->|Nee

Opgehaalde labels: geen open-source
Als: transparantieverplichting en geen transparantieverplichting en AI-model voor algemene doeleinden.| q-2.9
	q-2.11 -->|Nee

Opgehaalde labels: geen open-source
Als: aanbieder en gebruiksverantwoordelijke en AI-systeem en hoog-risico AI.| c-14.0.2
	q-2.11 -->|Nee

Opgehaalde labels: geen open-source
Als: aanbieder en gebruiksverantwoordelijke en AI-systeem en geen hoog-risico AI.| c-14.0.4
	q-2.11 -->|Nee

Opgehaalde labels: geen open-source
Als: aanbieder en gebruiksverantwoordelijke en AI-systeem voor algemene doeleinden en hoog-risico AI.| c-14.1.2
	q-2.11 -->|Nee

Opgehaalde labels: geen open-source
Als: aanbieder en gebruiksverantwoordelijke en AI-systeem voor algemene doeleinden en geen hoog-risico AI.| c-14.1.4
	q-2.11 -->|Nee

Opgehaalde labels: geen open-source
Als: aanbieder en gebruiksverantwoordelijke en AI-model voor algemene doeleinden.| c-14.2.3
	q-2.11 -->|Nee

Opgehaalde labels: geen open-source
Als: gebruiksverantwoordelijke en AI-systeem en hoog-risico AI.| c-13.0.2
	q-2.11 -->|Nee

Opgehaalde labels: geen open-source
Als: gebruiksverantwoordelijke en AI-systeem en geen hoog-risico AI.| c-13.0.4
	q-2.11 -->|Nee

Opgehaalde labels: geen open-source
Als: gebruiksverantwoordelijke en AI-systeem voor algemene doeleinden en hoog-risico AI.| c-13.1.2
	q-2.11 -->|Nee

Opgehaalde labels: geen open-source
Als: gebruiksverantwoordelijke en AI-systeem voor algemene doeleinden en geen hoog-risico AI.| c-13.1.4
	q-2.11 -->|Nee

Opgehaalde labels: geen open-source
Als: aanbieder en AI-systeem en hoog-risico AI.| c-12.0.2
	q-2.11 -->|Nee

Opgehaalde labels: geen open-source
Als: aanbieder en AI-systeem en geen hoog-risico AI.| c-12.0.4
	q-2.11 -->|Nee

Opgehaalde labels: geen open-source
Als: aanbieder en AI-systeem voor algemene doeleinden en hoog-risico AI.| c-12.1.2
	q-2.11 -->|Nee

Opgehaalde labels: geen open-source
Als: aanbieder en AI-systeem voor algemene doeleinden en geen hoog-risico AI.| c-12.1.4
	q-2.11 -->|Nee

Opgehaalde labels: geen open-source
Als: aanbieder en AI-model voor algemene doeleinden.| c-12.2.3
subgraph van_toepassing
q-1.1
c-11.0
q-1.2
c-11.3
q-1.3
q-1.4.1
q-1.4.2
c-16.2.1
c-15.2.1
c-11.1
q-1.5
c-11.2
c-13.2.1
q-1.6.1
q-1.6.2
q-1.6.3
end
subgraph tussenscherm
q-2.0
end
subgraph risicogroep
q-2.1
q-2.2
c-16.0.1
c-16.1.1
c-15.0.1
c-15.1.1
c-14.0.0
c-12.0.0
c-13.0.0
c-15.0.0
c-16.0.0
q-2.3
q-2.4
c-16.0.3
c-16.1.3
c-15.0.3
c-15.1.3
q-2.5
q-2.6
q-2.7.1
q-2.7.2
q-2.8
c-14.2.1
c-13.2.1
c-12.2.1
q-2.9
c-11.2
c-14.0.2
c-14.0.4
c-14.1.2
c-14.1.4
c-13.0.2
c-13.0.4
c-13.1.2
c-13.1.4
c-12.0.2
c-12.0.4
c-12.1.2
c-12.1.4
q-2.10
c-14.0.1
c-14.0.3
c-14.1.1
c-14.1.3
c-13.0.1
c-13.0.3
c-13.1.1
c-13.1.3
c-12.0.1
c-12.0.3
c-12.1.1
c-12.1.3
q-2.11
c-14.2.2
c-12.2.2
c-14.2.3
c-12.2.3
end
classDef secondaryStyle fill:#FFFFFF,stroke:#39870c
class van_toepassing secondaryStyle
class tussenscherm secondaryStyle
class risicogroep secondaryStyle
        </pre>

        <!-- Mermaid initialization -->
        <script>mermaid.initialize({ maxTextSize: 9000000000, startOnLoad: true, securityLevel: 'loose' })</script>

        <!-- JavaScript for tooltip and modal handling -->
        <script>
            // Function to handle modal popup when a node is clicked
            window.callback = function (name) {
                let cookieValue = document.getElementsByClassName("mermaidTooltip");
                let modelcontent1 = document.getElementById("modelcontent1");
                let model1 = document.getElementById("model1");

                // If a tooltip exists, display its content in the modal
                if (cookieValue[0]) {
                    // Hide the tooltip when opening the modal
                    cookieValue[0].style.display = "none";
                    // Set the modal content from the tooltip text
                    modelcontent1.innerHTML = cookieValue[0].innerText.replaceAll("#specialnewline#", "<br>");
                    // Open the modal by adding the 'is-active' class
                    model1.classList.add('is-active');
                }
            };

            // Function to close the modal and restore tooltip visibility
            document.addEventListener('DOMContentLoaded', () => {
                let modealclose1 = document.getElementById("modealclose1");

                // Event listener to close the modal when the close button is clicked
                modealclose1.addEventListener('click', () => {
                    let model1 = document.getElementById("model1");
                    let cookieValue = document.getElementsByClassName("mermaidTooltip");

                    // Close the modal by removing the 'is-active' class
                    model1.classList.remove('is-active');

                    // Restore the tooltip visibility after the modal is closed
                });
            });

        </script>

    </body>
    </html>
    