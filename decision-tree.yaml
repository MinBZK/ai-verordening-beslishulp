version: 1.0.0
name: Beslishulp AI-verordening
questions:
  # Definitie algoritme
  - questionId: "1.1"
    question: "Bevat de (beoogde) toepassing een algoritme?"
    explanation: ""
    category: van_toepassing
    subcategory: "Algoritme"
    sources:
      - source: Aandacht voor Algoritmes, Algemene Rekenkamer, 2021
        url: https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/rapporten/2021/01/26/aandacht-voor-algoritmes
      - source: Handreiking Algoritmeregister
        url: https://www.digitaleoverheid.nl/wp-content/uploads/sites/8/2023/12/Handreiking-Algoritmeregister-versie-1.0.pdf
      - source: Begrippenlijst Algoritmekader
        url: https://minbzk.github.io/Algoritmekader/overhetalgoritmekader/definities/#begrippenlijst
    answers:
      - answer: Ja
        nextQuestionId: "1.2"
      - answer: Nee
        labels:
          - "geen algoritme"
        nextConclusionId: "11.0"
# Rol
  - questionId: "1.2"
    question: "Ontwikkelen jullie de toepassing in eigen beheer of is/wordt deze ontwikkeld door een andere partij?"
    explanation: "Op basis van het antwoord op deze vraag zal je rol worden toegewezen: aanbieder, gebruiksverantwoordelijke, importeur en/of distributeur. "
    category: van_toepassing
    subcategory: "Rol"
    sources:
      - source: Artikel 3 - Definities
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2093-1-1
      - source: Begrippenlijst Algoritmekader
        url: https://minbzk.github.io/Algoritmekader/overhetalgoritmekader/definities/#begrippenlijst
    answers:
      - answer: We ontwikkelen enkel
        labels:
          - "aanbieder"
        nextQuestionId: "1.3"
      - answer: We ontwikkelen, maar gebruiken het niet alleen zelf
        labels:
          - "aanbieder"
          - "gebruiksverantwoordelijke"
        nextQuestionId: "1.3"
      - answer: We ontwikkelen en gebruiken het zelf
        labels:
          - "aanbieder"
          - "gebruiksverantwoordelijke"
        nextQuestionId: "1.3"
      - answer: We hebben opdracht gegeven om de toepassing te ontwikkelen
        labels:
          - "aanbieder"
        subresult: "Tenzij het duidelijk is dat de ontwikkelaar de AI onder hun eigen naam of merk in de handel brengt"
        nextQuestionId: "1.3"
      - answer: We hebben een toepassing gekocht en daarop doorontwikkeld
        labels:
          - "aanbieder"
          - "gebruiksverantwoordelijke"
        nextQuestionId: "1.3"
      - answer: We hebben een toepassing gekocht en gebruiken deze zonder aanpassingen
        labels:
          - "gebruiksverantwoordelijke"
        nextQuestionId: "1.3"
      - answer: We importeren van een leverancier buiten de EU
        labels:
          - "importeur"
        nextQuestionId: "1.3"
      - answer: We kopen van een leverancier binnen de EU en verkopen het
        labels:
          - "distributeur"
        nextQuestionId: "1.3"
      - answer: Geen van bovenstaande
        nextConclusionId: "11.6"

# In gebruik?
  - questionId: "1.3"
    question: "Is de toepassing al in gebruik of niet?"
    explanation: "Dit is van belang omdat er verschillende deadlines zijn voor het voldoen aan de AI-verordening: toepassingen die al in gebruik zijn, moeten uiterlijk in 2030 voldoen. Voor nieuwe toepassingen gelden kortere termijnen, afhankelijk van het type toepassing. In de volgende vragen gaan we het type toepassing bepalen om de exacte deadline te kunnen vaststellen."
    category: van_toepassing
    subcategory: "In gebruik"
    sources:
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
      - source: Overweging 177 - Aanpassingsperiode en uitzonderingen voor bestaande hoogrisico AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_177
      - source: Begrippenlijst Algoritmekader
        url: https://minbzk.github.io/Algoritmekader/overhetalgoritmekader/definities/#begrippenlijst
    answers:
      - answer: In gebruik
        labels:
           - "in gebruik"
        nextQuestionId: "1.4.1"
      - answer: In ontwikkeling
        labels:
          - "in ontwikkeling"
        nextQuestionId: "1.4.1"

 # AI-systeem
  - questionId: "1.4.1"
    question: "Is jouw (beoogde) toepassing een AI-systeem?"
    explanation: "
      Een AI-systeem is een machine-gebaseerd systeem dat autonoom werkt, zichzelf kan aanpassen na inzet, en output levert zoals voorspellingen, inhoud, aanbevelingen of beslissingen. Deze output kan fysieke of virtuele omgevingen beïnvloeden. AI-systemen gebruiken inferentie, waarbij modellen of algoritmen worden afgeleid uit data, en combineren technieken als machinaal leren, logica en kennisrepresentatie. <br><br>
      Let op: Voor een AI-model voor algemene doeleinden geldt een specifieke definitie. <br><br>
      Ben je niet zeker of jouw (beoogde) toepassing onder deze definitie valt? Klik dan op 'Ik weet het niet' en beantwoord maximaal drie aanvullende vragen om het te achterhalen. Tot er verdere duiding vanuit de EU komt over de definitie van een AI-systeem, hanteren we deze vragen."
    category: van_toepassing
    subcategory: "AI-systeem"
    sources:
      - source: Artikel 3 - Definities
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2093-1-1
      - source: Overweging 12 - Begrip "AI-systeem"
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_12
      - source: Overweging 97 - Begrip "AI-model voor algemene doeleinden"
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_97
      - source: Overweging 99 - Generatieve AI-modellen als voorbeeld van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_99
      - source: Overweging 100 - Classificatie van AI-systemen met geïntegreerde AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_100
      - source: Begrippenlijst Algoritmekader
        url: https://minbzk.github.io/Algoritmekader/overhetalgoritmekader/definities/#begrippenlijst
    answers:
        - answer: Ja, het is een AI-systeem
          labels:
            - "AI-systeem"
          nextQuestionId: "1.5"
        - answer: Nee, het is geen AI-systeem
          nextQuestionId: "1.4.2"
        - answer: Ik weet het niet
          nextQuestionId: "1.8.1" # Hulp bij definitie AI-systeem - Beslisregels

# AI-systeem
  - questionId: "1.4.2"
    question: "Is jouw (beoogde) toepassing een AI-model voor algemene doeleinden of AI-systeem voor algemene doeleinden?"
    explanation: "
      - Een AI-model voor algemene doeleinden is een flexibel AI-model, zoals een generatief model, dat ingezet kan worden voor meerdere taken zoals tekst, beeld, audio of video en gemakkelijk integreerbaar is in andere systemen.<br><br>
      - Een AI-systeem voor algemene doeleinden is een systeem dat een AI-model voor algemene doeleinden bevat en breed inzetbaar is, zowel direct als via integratie in andere systemen.<br><br>
      Als jouw toepassing niet binnen een van deze definities valt, is de AI-verordening niet van toepassing. Je wordt vervolgens doorgestuurd naar vragen over de mogelijke classificatie als een impactvol algoritme."
    category: van_toepassing
    subcategory: "GPAI-systeem of GPAI-model"
    sources:
      - source: Artikel 3 - Definities
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2093-1-1
      - source: Overweging 12 - Begrip "AI-systeem"
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_12
      - source: Overweging 97 - Begrip "AI-model voor algemene doeleinden"
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_97
      - source: Overweging 99 - Generatieve AI-modellen als voorbeeld van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_99
      - source: Overweging 100 - Classificatie van AI-systemen met geïntegreerde AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_100
      - source: Begrippenlijst Algoritmekader
        url: https://minbzk.github.io/Algoritmekader/overhetalgoritmekader/definities/#begrippenlijst
    answers:
      - answer: AI-systeem voor algemene doeleinden
        labels:
          - "AI-systeem voor algemene doeleinden"
        nextQuestionId: "1.5"
      - answer: AI-model voor algemene doeleinden
        labels:
          - "AI-model voor algemene doeleinden"
        redirects:
          - nextQuestionId: "1.5"
            if: '"aanbieder" in labels || "gebruiksverantwoordelijke" in labels'
          - nextConclusionId: "16.2.1"
            if: '"distributeur" in labels'
          - nextConclusionId: "15.2.1"
            if: '"importeur" in labels'
      - answer: Geen van bovenstaande
        nextQuestionId: "1.6" # Impactvol algoritme

# Uitzonderingsgrond
  - questionId: "1.5"
    question: "Is er voor de (beoogde) toepassing sprake van een uitzonderingsgrond?"
    explanation: "Uitzonderingsgronden: <br><br>
      - AI-systemen die uitsluitend in de handel worden gebracht, in gebruik worden gesteld of, al dan niet gewijzigd, worden gebruikt voor militaire, defensie- of nationale veiligheidsdoeleinden<br><br>
      - AI-systemen die niet in de Unie in de handel worden gebracht of in gebruik worden gesteld en waarvan de output in de Unie uitsluitend wordt gebruikt voor militaire, defensie- of nationale veiligheidsdoeleinden<br><br>
      - overheidsinstanties in derde landen of internationale organisaties die binnen het toepassingsgebied van de AI-verordening vallen, wanneer deze instanties of organisaties AI-systemen gebruiken in het kader van internationale samenwerking of overeenkomsten met de Unie of een of meer lidstaten op het gebied van rechtshandhaving en justitie<br><br>
      - onderzoeks-, test- of ontwikkelingsactiviteiten met betrekking tot AI-systemen of AI-modellen voor zij in de handel worden gebracht of in gebruik worden gesteld (testen onder reële omstandigheden valt hier niet onder)<br><br>
      - AI-systemen of AI-modellen, met inbegrip van hun output, die specifiek zijn ontwikkeld en in gebruik worden gesteld met wetenschappelijk onderzoek en wetenschappelijke ontwikkeling als enig doel<br><br>"
    category: van_toepassing
    subcategory: "Uitzonderingsgrond AI-verordening"
    sources:
      - source: Artikel 2 - Toepassingsgebied
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e1978-1-1
      - source: Begrippenlijst Algoritmekader
        url: https://minbzk.github.io/Algoritmekader/overhetalgoritmekader/definities/#begrippenlijst
    answers:
      - answer: Ja
        labels:
          - "uitzondering van toepassing"
        nextConclusionId: "11.2"
      - answer: Nee
        redirects:
          - nextQuestionId: "2.0"
            if: '"AI-systeem" in labels || "AI-systeem voor algemene doeleinden" in labels || "AI-model voor algemene doeleinden" in labels'
          - nextConclusionId: "13.2.1"
            if: '"AI-model voor algemene doeleinden" in labels && "gebruiksverantwoordelijke" in labels'

 # Impactvol algoritme
  - questionId: "1.6"
    question: "Is jouw algoritme impactvol, bijvoorbeeld doordat het gevolgen heeft voor burgers of groepen, zoals rechtsgevolgen of profilering?"
    explanation: "Een algoritme is impactvol als het valt onder categorie B van de Handreiking Algoritmeregister, waarbij het gebruik van het algoritme impact heeft op burgers of groepen,
      bijvoorbeeld door rechtsgevolgen (zoals een boete of subsidieafwijzing) of door classificatie van burgers (zoals profilering of risico-indicatie voor controle)."
    category: van_toepassing
    subcategory: "Impactvol algoritme"
    sources:
      - source: Handreiking Algoritmeregister
        url: https://www.digitaleoverheid.nl/wp-content/uploads/sites/8/2023/12/Handreiking-Algoritmeregister-versie-1.0.pdf
    answers:
      - answer: Ja
        nextQuestionId: "1.7"
      - answer: Nee
        labels:
          - "niet-impactvol algoritme"
        nextConclusionId: "11.5"

  - questionId: "1.7"
    question: "Valt de toepassing onder \xE9\xE9n van de uitzonderingsgronden categorie C of D van de Handreiking van het Algoritmeregister?"
    explanation: "Uitzonderingsgronden impactvol algoritme: <br><br>
      - Categorie C: Algoritmes die maatschappelijk relevant zijn of veel aandacht krijgen, zoals complexe modellen, algoritmes in onderzoek, of die vaak door burgers of media worden bevraagd (bijv. stikstofmodellen, toeslagen, of visumaanvragen).<br>
      - Categorie D: Algoritmes die wettelijk of operationeel beschermd zijn, bijvoorbeeld in opsporing, defensie, of handhaving, of die kunnen leiden tot misbruik van informatie, zoals bij bedrijfssubsidies."
    category: van_toepassing
    subcategory: "Uitzonderingsgronden Handreiking Algoritmeregister"
    sources:
      - source: Handreiking Algoritmeregister
        url: https://www.digitaleoverheid.nl/wp-content/uploads/sites/8/2023/12/Handreiking-Algoritmeregister-versie-1.0.pdf
    answers:
      - answer: Ja
        subresult: "Het betreft een algoritme met impact, maar de AI-verordening is niet van toepassing. Je hoeft vanwege uitzonderingsgrond niet te publiceren in het register."
        nextConclusionId: "11.4"
        labels:
          - "impactvol algoritme"
      - answer: Nee
        nextConclusionId: "11.3"
        labels:
          - "impactvol algoritme"

# Hulp bij AI-systeem definitie
  - questionId: "1.8.1"
    question: "Is jouw (beoogde) toepassing gebaseerd op door mensen gedefinieerde regels om operaties te automatiseren, waarbij deze regels niet zijn afgeleid uit data of kennis?"
    explanation: "
      Als je 'Nee' antwoordt, maakt jouw toepassing  gebruik van gegevens, wegingsfactoren, beoordelingen van experts of modellen om operaties te automatiseren. In dit geval is een mogelijkheid dat jouw toepassing onder de definitie van een AI-systeem valt; dit wordt vastgesteld door nog maximaal twee aanvullende vragen te beantwoorden. <br>
      Voorbeelden van AI-systemen:<br>
      - Een automatisch berekende beslisregel zonder menselijke tussenkomst.<br>
      - Een algoritme dat variabelen selecteert om voorspellingen te doen.<br>
      Beide voorbeelden gaan verder dan elementaire gegevensverwerking door leren, redeneren of modelleren toe te passen.<br><br>

      Als je 'Ja' antwoordt, valt jouw toepassing niet onder de definitie van een AI-systeem volgens de AI-verordening. Je wordt doorgestuurd naar vragen over de mogelijke classificatie als een impactvol algoritme.<br>
      Voorbeelden van geen AI-systemen:<br>
      -   Het gemiddelde van een populatie berekenen. <br>
      -   Een dashboard met beschrijvende statistieken.<br>
      Beide voorbeelden beperken zich tot elementaire gegevensverwerking zonder leren, redeneren of modelleren."
    category: van_toepassing
    subcategory: "Definitie AI-systeem - Beslisregels"
    sources:
      - source: Artikel 3 - Definities
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2093-1-1
      - source: Overweging 12 - Begrip "AI-systeem"
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_12
      - source: Effectieve werking van de AIA definitie van een AI-systeem
        url: https://www.linkedin.com/posts/jaapvink_effectieve-werking-van-de-aia-definitie-van-activity-7267476423903264768-a2aG?utm_source=share&utm_medium=member_desktop
      - source: 10 examples of (non) AI systems
        url: https://www.linkedin.com/posts/algorithm-audit_10-examples-of-non-ai-systems-activity-7274353190588891136-FiMD?utm_source=share&utm_medium=member_desktop
    answers:
      - answer: Ja
        nextQuestionId: "1.6" # Impactvol algoritme
      - answer: Nee
        nextQuestionId: "1.8.2" # Hulp bij definitie AI-systeem - Inferentie

# Hulp bij AI-systeem definitie
  - questionId: "1.8.2"
    question: "Maakt jouw (beoogde) toepassing inferenties?"
    explanation: "Dit omvat alle technieken en benaderingen voor inferentie. Geen enkele techniek wordt uitgesloten, inclusief bijvoorbeeld ‘scorecards’ met wegingsfactoren die door experts zijn gedefinieerd of verkregen vanuit een separaat model.<br><br>
      Als je 'Ja' antwoord, is er een mogelijkheid dat jouw toepassing onder de definitie van een AI-systeem valt; dit wordt vastgesteld door één aanvullende vraag te beantwoorden. <br>
      Voorbeelden van AI-systemen: <br>
      - Computer vision systemen. <br>
      - Het gebruik van een statistisch model voor voorspellingen. <br>
      Beide voorbeelden gaan verder dan elementaire gegevensverwerking door leren, redeneren of modelleren toe te passen.<br><br>

      Als je 'Nee' antwoordt, valt jouw toepassing niet onder de definitie van een AI-systeem volgens de AI-verordening. Je wordt dan doorgestuurd naar vragen over de mogelijke classificatie als een impactvol algoritme.<br>
      Voorbeelden van geen AI-systemen: <br>
      - Statistische modellering zonder voorspellingen.<br>
      - Het gemiddelde van een populatie berekenen.<br>
      Beide voorbeelden beperken zich tot elementaire gegevensverwerking zonder leren, redeneren of modelleren.
      "
    category: van_toepassing
    subcategory: "Definitie AI-systeem - Inferentie"
    sources:
      - source: Artikel 3 - Definities
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2093-1-1
      - source: Overweging 12 - Begrip "AI-systeem"
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_12
      - source: Effectieve werking van de AIA definitie van een AI-systeem
        url: https://www.linkedin.com/posts/jaapvink_effectieve-werking-van-de-aia-definitie-van-activity-7267476423903264768-a2aG?utm_source=share&utm_medium=member_desktop
      - source: 10 examples of (non) AI systems
        url: https://www.linkedin.com/posts/algorithm-audit_10-examples-of-non-ai-systems-activity-7274353190588891136-FiMD?utm_source=share&utm_medium=member_desktop
    answers:
      - answer: Ja
        nextQuestionId: "1.8.3" # Hulp bij definitie AI-systeem - Omgeving
      - answer: Nee
        nextQuestionId: "1.6" # Impactvol algoritme


# Hulp bij AI-systeem definitie
  - questionId: "1.8.3"
    question: "Kan jouw (beoogde) toepassing de omgeving beinvloeden?"
    explanation: "Dit betreft systemen waarvan de uitvoer gekoppeld is aan een actie of besluit dat daadwerkelijk de omgeving beïnvloedt. <br><br>
      Als je 'Ja' antwoord, valt jouw toepassing onde de definitie van een 'AI-systeem' en zul je de beslishulp voortzetten. <br>
      Voorbeelden van AI-systemen: <br>
      - Gewogen gemiddelden - en meer geavanceerde vormen van gegevensverwerking - zouden AI-systemen kunnen zijn. <br>
      - Het gebruik van een statistisch model voor voorspellingen zijn AI-systemen. <br>
      Beide voorbeelden gaan verder dan elementaire gegevensverwerking door leren, redeneren of modelleren toe te passen.<br><br>

      Als je 'Nee' antwoordt, valt jouw toepassing niet onder de definitie van een AI-systeem volgens de AI-verordening. Je wordt dan doorgestuurd naar vragen over de mogelijke classificatie als een impactvol algoritme.<br>
      Voorbeelden van geen AI-systemen: <br>
      - Statistische modellering zonder voorspellingen zijn geen AI-systemen.<br>
      - Het gemiddelde van een populatie berekenen is geen AI-systeem.<br>
      Beide voorbeelden beperken zich tot elementaire gegevensverwerking zonder leren, redeneren of modelleren.
      "
    category: van_toepassing
    subcategory: "Definitie AI-systeem - Omgeving"
    sources:
      - source: Artikel 3 - Definities
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2093-1-1
      - source: Overweging 12 - Begrip "AI-systeem"
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_12
      - source: Effectieve werking van de AIA definitie van een AI-systeem
        url: https://www.linkedin.com/posts/jaapvink_effectieve-werking-van-de-aia-definitie-van-activity-7267476423903264768-a2aG?utm_source=share&utm_medium=member_desktop
      - source: 10 examples of (non) AI systems
        url: https://www.linkedin.com/posts/algorithm-audit_10-examples-of-non-ai-systems-activity-7274353190588891136-FiMD?utm_source=share&utm_medium=member_desktop
    answers:
      - answer: Ja
        labels:
          - "AI-systeem"
        nextQuestionId: "1.5" # Uitzonderingsgrond
      - answer: Nee
        nextQuestionId: "1.6" # Impactvol algoritme

# Tussenscherm
  - questionId: "2.0"
    question: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing."
    explanation: "We gaan nu bepalen in welke risicogroep jouw (beoogde) toepassing valt. Hiervoor gaan we maximaal 7 vragen langslopen.<br><br>"
    category: tussenscherm
    subcategory: "Tussenscherm"
    answers:
      - answer: Naar risicogroep bepaling
        redirects:
            - nextQuestionId: "2.1"
              if: '"AI-systeem" in labels || "AI-systeem voor algemene doeleinden" in labels'
            - nextQuestionId: "2.8"
              if: '"AI-model voor algemene doeleinden" in labels'

# Verboden AI systeem
  - questionId: "2.1"
    question: "Valt de toepassing onder een van de verboden systemen uit Artikel 5 van de AI-verordening?"
    explanation: "De volgende AI-praktijken zijn verboden: <br><br>
      -	gebruik kan gaan maken van subliminale technieken om mensen onbewust of bewust kunnen manipuleren, waardoor ze beslissingen nemen die ze anders niet zouden hebben genomen?<br><br>
      -	gebruik kan gaan maken van kwetsbaarheden van individuen of specifieke groepen, zoals leeftijd, handicaps of sociale/economische omstandigheden, om het gedrag van die personen aanzienlijk te verstoren, wat kan leiden tot aanzienlijke schade bij henzelf of anderen?<br><br>
      -	gebruikt kan worden om natuurlijke personen of groepen gedurende een periode te evalueren of te classificeren op basis van hun sociale gedrag of afgeleide persoonlijke kenmerken?<br><br>
      -	gebruikt kan worden voor risicobeoordelingen van natuurlijke personen om het risico op crimineel gedrag te voorspellen, gebaseerd op profilering of persoonlijkheidskenmerken? (Dit geldt niet voor AI-systemen die worden gebruikt om menselijke beoordelingen te ondersteunen, gebaseerd op objectieve en verifieerbare feiten die rechtstreeks verband houden met criminele activiteiten)<br><br>
      -	gebruikt kan worden om databanken voor gezichtsherkenning aan te leggen of aan te vullen door willekeurige gezichtsafbeeldingen van internet of CCTV-beelden te scrapen?<br><br>
      -	gebruikt kan worden om emoties van een persoon op de werkplek of in het onderwijs af te leiden? (Dit is niet van toepassing als het gebruik van het AI-systeem is bedoeld voor medische- of veiligheidsdoeleinden)<br><br>
      -	gebruikt kan worden om natuurlijke personen individueel in categorieën in te delen op basis van biometrische gegevens om ras, politieke opvattingen, lidmaatschap van een vakbond, religieuze of levensbeschouwelijke overtuigingen, seksleven of seksuele geaardheid af te leiden? (Dit verbod geldt niet voor het labelen of filteren van rechtmatig verkregen biometrische datasets, zoals afbeeldingen, op basis van biometrische gegevens, of voor categorisering van biometrische gegevens op het gebied van rechtshandhaving)<br><br>
      -	gebruikt kan worden als een biometrisch systeem in de publieke ruimte voor identificatie op afstand in real-time, met het oog op de rechtshandhaving?"
    category: risicogroep
    subcategory: "Verboden AI-systeem"
    sources:
      - source: Artikel 5 - Verboden AI
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2816-1-1
      - source: Begrippenlijst Algoritmekader
        url: https://minbzk.github.io/Algoritmekader/overhetalgoritmekader/definities/#begrippenlijst
    answers:
      - answer: Ja
        nextQuestionId: "2.2" #uitzondering verboden AI
      - answer: Nee
        nextQuestionId: "2.3" #risicogroep

# Uitzondering verboden AI
  - questionId: "2.2"
    question: "Is er sprake van een van de twee uitzonderingen voor verboden systemen?"
    explanation: "Uitzonderingen voor verboden systemen:<br><br>
      -	Er is sprake van een rechtshandhavingsactiviteit i.v.m. een specifiek misdrijf (terrorisme, mensenhandel, seksuele uitbuiting van kinderen en materiaal over seksueel misbruik van kinderen, illegale handel in verdovende middelen en psychotrope stoffen, illegale handel in wapens, munitie en explosieven, moord, zware mishandeling, illegale handel in menselijke organen en weefsels, illegale handel in nucleaire en radioactieve stoffen, ontvoering, wederrechtelijke vrijheidsberoving en gijzeling, misdrijven die onder de rechtsmacht van het Internationaal Strafhof vallen, kaping van vliegtuigen/schepen, verkrachting, milieucriminaliteit, georganiseerde of gewapende diefstal, sabotage, deelneming aan een criminele organisatie die betrokken is bij een of meer van de bovengenoemde misdrijven).<br>
      -	Er is sprake van gerichte opsporing van specifieke slachtoffers, ontvoering, mensenhandel en seksuele uitbuiting van mensen, vermiste personen; of het voorkomen van bedreigingen voor het leven of de fysieke veiligheid van personen of het reageren op de huidige of voorzienbare dreiging van een terreuraanslag."
    category: risicogroep
    subcategory: "Uitzondering Verboden AI-systeem"
    sources:
      - source: Artikel 5 - Verboden AI
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2816-1-1
      - source: Overweging 33 - Biometrische identificatie voor rechtshandhaving
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_33
      - source: Overweging 34 - Biometrische identificatie in openbare ruimten voor rechtshandhaving
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_34
      - source: Begrippenlijst Algoritmekader
        url: https://minbzk.github.io/Algoritmekader/overhetalgoritmekader/definities/#begrippenlijst
    answers:
      - answer: Ja
        labels:
          - "hoog-risico AI"
        redirects:
         - nextQuestionId: "2.3" #hoog risico bijlage III
           if: '"aanbieder" in labels || "gebruiksverantwoordelijke" in labels'
         - nextConclusionId: "16.0.1"
           if: '"distributeur" in labels && "AI-systeem" in labels'
         - nextConclusionId: "16.1.1"
           if: '"distributeur" in labels && "AI-systeem voor algemene doeleinden" in labels'
         - nextConclusionId: "15.0.1"
           if: '"importeur" in labels && "AI-systeem" in labels'
         - nextConclusionId: "15.1.1"
           if: '"importeur" in labels && "AI-systeem voor algemene doeleinden" in labels'
      - answer: Nee
        labels:
          - "verboden AI"
        redirects:
          - nextConclusionId: "14.0.0"
            if: '"aanbieder" in labels && "gebruiksverantwoordelijke" in labels'
          - nextConclusionId: "12.0.0"
            if: '"aanbieder" in labels'
          - nextConclusionId: "13.0.0"
            if: '"gebruiksverantwoordelijke" in labels'
          - nextConclusionId: "15.0.0"
            if: '"importeur" in labels'
          - nextConclusionId: "16.0.0"
            if: '"distributeur" in labels'


# Rol in of als veiligheidscomponent van een product onder Bijlage I
  - questionId: "2.3"
    question: "Is het AI-systeem bedoeld om te worden gebruikt als een veiligheidscomponent van een product dat valt onder de lijst in Bijlage I?"
    explanation: "
      Specifiek, valt het AI-systeem onder de veiligheidscomponenten van:<br>
      - Sectie A van bijlage I, die wetgevingen omvat zoals richtlijnen voor machines, speelgoedveiligheid, pleziervaartuigen, liften, radioapparatuur, drukapparatuur, medische hulpmiddelen en gasverbrandingstoestellen.<br><br>
      Of valt het AI-systeem onder:<br>
      - Sectie B van bijlage I, die verordeningen bevat voor de beveiliging van de luchtvaart, motorvoertuigen, landbouwvoertuigen, zeeschepen, spoorwegsystemen, en luchtvaartveiligheid?"
    category: risicogroep
    subcategory: "Hoog-risico Bijlage I A en B"
    sources:
          - source: Bijlage I - Lijst van harmonisatiewetgeving van de Unie
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e38-124-1
          - source: Artikel 6.1 - Classificatieregels voor AI-systemen met een hoog risico
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2986-1-1
          - source: Verordening (EG) Nr. 300/2008 - Beveiliging van de burgerluchtvaart
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32008R0300
          - source: Verordening (EU) Nr. 168/2013 - Goedkeuring en toezicht op twee-, driewielers en vierwielers
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32013R0168&qid=1693934047233
          - source: Verordening (EU) Nr. 167/2013 - Goedkeuring en markttoezicht op landbouw- en bosvoertuigen
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32013R0167
          - source: Richtlijn 2014/90/EU - Uitrusting van zeeschepen
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX%3A32014L0090&qid=1693316316907
          - source: Richtlijn 2016/797 - Interoperabiliteit van het spoorwegsysteem in de EU
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32016L0797
          - source: Verordening 2018/858 - Goedkeuring en markttoezicht op motorvoertuigen en aanhangwagens
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32018R0858
          - source: Verordening (EU) 2019/2144 - Typegoedkeuring van motorvoertuigen en aanhangwagens
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32019R2144
          - source:  Verordening (EU) 2018/1139 - Regels voor burgerluchtvaart en EU-agentschap voor luchtvaartveiligheid
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32018R1139
          - source: Richtlijn 2006/42/EG - Machines
            url: https://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=OJ:L:2006:157:0024:0086:NL:PDF
          - source: Richtlijn 2009/48/EG - Veiligheid van speelgoed
            url: https://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=OJ:L:2009:170:0001:0037:nl:PDF
          - source: Richtlijn 2013/53/EU - Pleziervaartuigen en waterscooters
            url: https://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=OJ:L:2013:354:0090:0131:NL:PDF
          - source: Richtlijn 2014/33/EU - Harmonisatie van lidstaatwetgeving over liftveiligheid
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32014L0033
          - source: Richtlijn 2014/43/EU - Harmonisatie van lidstaatwetgeving over explosieveilige apparaten
          - source:  Richtlijn 2014/53/EU - Harmonisatie van lidstaatwetgeving over radioapparatuur
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32014L0053
          - source: Richtlijn 2014/68/EU - Harmonisatie van lidstaatwetgeving over drukapparatuur
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32014L0068
          - source: Verordening 2016/424 - Kabelbaaninstallaties
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32016R0424
          - source: Verordening (EU) 2016/425 - Persoonlijke beschermingsmiddelen
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32016R0425
          - source: Verordening (EU) 2016/426 - Gasverbrandingstoestellen
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32016R0426&from=DE
          - source: Verordening (EU) 2017/745 - Medische hulpmiddelen
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32017R0745
          - source: Verordening (EU) 2017/746 - Medische hulpmiddelen voor in-vitrodiagnostiek
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32017R0746
          - source: Overweging 47 - Veiligheidscomponent
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_47
          - source: Overweging 49 - Veiligheidscomponent
            url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_49
          - source: Begrippenlijst Algoritmekader
            url: https://minbzk.github.io/Algoritmekader/overhetalgoritmekader/definities/#begrippenlijst
    answers:
      - answer: Ja Sectie A van Bijlage I
        labels:
          - "hoog-risico AI"
        redirects:
          - nextQuestionId: "2.7.1" # conformiteitsbeoordeling derde partij
            if: '"aanbieder" in labels || "gebruiksverantwoordelijke" in labels'
          - nextConclusionId: "16.0.1"
            if: '"distributeur" in labels && "AI-systeem" in labels'
          - nextConclusionId: "16.1.1"
            if: '"distributeur" in labels && "AI-systeem voor algemene doeleinden" in labels'
          - nextConclusionId: "15.0.1"
            if: '"importeur" in labels && "AI-systeem" in labels'
          - nextConclusionId: "15.1.1"
            if: '"importeur" in labels && "AI-systeem voor algemene doeleinden" in labels'
      - answer: Ja Sectie B van Bijlage I
        labels:
          - "hoog-risico AI"
        redirects:
          - nextQuestionId: "2.9" #transparantieverplichting
            if: '"aanbieder" in labels || "gebruiksverantwoordelijke" in labels'
          - nextConclusionId: "16.0.1"
            if: '"distributeur" in labels && "AI-systeem" in labels'
          - nextConclusionId: "16.1.1"
            if: '"distributeur" in labels && "AI-systeem voor algemene doeleinden" in labels'
          - nextConclusionId: "15.0.1"
            if: '"importeur" in labels && "AI-systeem" in labels'
          - nextConclusionId: "15.1.1"
            if: '"importeur" in labels && "AI-systeem voor algemene doeleinden" in labels'
      - answer: Geen van beide
        nextQuestionId: "2.4" # Hoog risico bijlage III

# Hoog risico bijlage III
  - questionId: "2.4"
    question: "Valt het AI-systeem onder een van de hoog-risico systemen uit Bijlage III van de AI-verordening?"
    explanation: "Dit betreft een AI-systeem in een van de volgende gebieden:<br><br>
      -	biometrie<br>
      -	kritieke infrastructuur<br>
      -	onderwijs en beroepsopleiding<br>
      -	werkgelegenheid, personeelsbeheer en toegang tot zelfstandige arbeid<br>
      -	toegang tot en gebruik van essentiële particuliere en publieke diensten en uitkeringen<br>
      -	rechtshandhavingsinstanties - migratie-, asiel- en grenstoezichtsbeheer<br>
      -	rechtsbedeling en democratische processen<br>
      Beweeg je muis over de opties om te zien welke systemen hieronder vallen."
    category: risicogroep
    subcategory: "Hoog risico Bijlage III"
    sources:
      - source: Bijlage III - In Artikel 6, lid 2, bedoelde AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e38-127-1
      - source: Artikel 6 (lid 3) - Classificatieregels voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2986-1-1
    answers:
      - answer: Ja
        nextQuestionId: "2.7.2" #conformiteitsbeoordeling derde partij
      - answer: Nee
        labels:
          - "geen hoog-risico AI"
        redirects:
         - nextQuestionId: "2.9" #transparantieverplichting
           if: '"aanbieder" in labels || "gebruiksverantwoordelijke" in labels'
         - nextConclusionId: "16.0.3"
           if: '"distributeur" in labels && "AI-systeem" in labels'
         - nextConclusionId: "16.1.3"
           if: '"distributeur" in labels && "AI-systeem voor algemene doeleinden" in labels'
         - nextConclusionId: "15.0.3"
           if: '"importeur" in labels && "AI-systeem" in labels'
         - nextConclusionId: "15.1.3"
           if: '"importeur" in labels && "AI-systeem voor algemene doeleinden" in labels'

# Profilering
  - questionId: "2.5"
    question: "Voert het AI-systeem profilering van natuurlijke personen uit?"
    explanation: "Bij profilering is er altijd sprake van een hoog risico."
    category: risicogroep
    subcategory: "Profilering"
    sources:
      - source: Bijlage III - Lijst van harmonisatiewetgeving van de Unie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#anx_III
      - source: Artikel 6 (lid 3)- Classificatieregels voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2986-1-1
    answers:
      - answer: Ja
        labels:
          - "hoog-risico AI"
        redirects:
          - nextQuestionId: "2.9" #transparantieverplichting
            if: '"aanbieder" in labels || "gebruiksverantwoordelijke" in labels'
          - nextConclusionId: "16.0.1"
            if: '"distributeur" in labels && "AI-systeem" in labels'
          - nextConclusionId: "16.1.1"
            if: '"distributeur" in labels && "AI-systeem voor algemene doeleinden" in labels'
          - nextConclusionId: "15.0.1"
            if: '"importeur" in labels && "AI-systeem" in labels'
          - nextConclusionId: "15.1.1"
            if: '"importeur" in labels && "AI-systeem voor algemene doeleinden" in labels'
      - answer: Nee
        nextQuestionId: "2.6" #uitzondering bijlage III hoog risico

# Uitzondering Bijlage III
  - questionId: "2.6"
    question: "Is er sprake van een uitzondering op de lijst van hoog-risico AI-systemen (uit bijlage III)?"
    explanation: "
      Dit betreft een AI-systeem dat is bedoeld voor een van de volgende doeleinden:<br><br>
      -	Het uitvoeren van een beperkte procedurele taak waarbij er geen significant risico is op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen?<br>
      -	Het verbeteren van het resultaat van een eerder voltooide menselijke activiteit en waarbij er geen significant risico is op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen?<br>
      -	Het opsporen van besluitvormingspatronen of afwijkingen van eerdere besluitvormingspatronen en waarbij het niet bedoeld is om de eerder voltooide menselijke beoordeling zonder behoorlijke menselijke toetsing te vervangen of te beïnvloeden?<br>
      -	Het uitvoeren van een voorbereidende taak voor een beoordeling die relevant is voor de in bijlage III vermelde gebruiksgevallen?"
    category: risicogroep
    subcategory: "Uitzondering Hoog risico bijlage III"
    sources:
      - source: Overweging 53 - Beoordelingscriteria AI-risico's toepassingen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_53
      - source: Bijlage III - Lijst van harmonisatiewetgeving van de Unie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#anx_III
      - source: Artikel 6 (lid 3)- Classificatieregels voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2986-1-1
    answers:
      - answer: Ja
        labels:
            - "geen hoog-risico AI"
        redirects:
         - nextQuestionId: "2.9" #transparantieverplichting
           if: '"aanbieder" in labels || "gebruiksverantwoordelijke" in labels'
         - nextConclusionId: "16.0.3"
           if: '"distributeur" in labels && "AI-systeem" in labels'
         - nextConclusionId: "16.1.3"
           if: '"distributeur" in labels && "AI-systeem voor algemene doeleinden" in labels'
         - nextConclusionId: "15.0.3"
           if: '"importeur" in labels && "AI-systeem" in labels'
         - nextConclusionId: "15.1.3"
           if: '"importeur" in labels && "AI-systeem voor algemene doeleinden" in labels'
      - answer: Nee
        labels:
            - "hoog-risico AI"
        redirects:
            - nextQuestionId: "2.9" #transparantieverplichting
              if: '"aanbieder" in labels || "gebruiksverantwoordelijke" in labels'
            - nextConclusionId: "16.0.1"
              if: '"distributeur" in labels && "AI-systeem" in labels'
            - nextConclusionId: "16.1.1"
              if: '"distributeur" in labels && "AI-systeem voor algemene doeleinden" in labels'
            - nextConclusionId: "15.0.1"
              if: '"importeur" in labels && "AI-systeem" in labels'
            - nextConclusionId: "15.1.1"
              if: '"importeur" in labels && "AI-systeem voor algemene doeleinden" in labels'

## Conformiteitsbeoordeling door derde partij bijlage IA
  - questionId: "2.7.1"
    question: "Is het verplicht om de conformiteitsbeoordeling door een derde partij, zoals een conformiteitsbeoordelingsinstantie, uit te laten voeren?"
    explanation: "Het is verplicht om een conformiteitsbeoordeling door een derde partij uit te laten voeren als de toepassing waarvan het AI-systeem een veiligheidscomponent is, of het AI-systeem zelf onder de harmonisatiewetgeving van de EU valt en een dergelijke beoordeling nodig is om het product in de handel te brengen of te gebruiken."
    category: risicogroep
    subcategory: "Conformiteitsbeoordeling Bijlage 1A"
    sources:
        - source: Artikel 43 - Conformiteitsbeoordeling
          url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5074-1-1
        - source: Artikel 6 - Classificatieregels voor AI-systemen met een hoog risico
          url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#art_6
        - source: Overweging 50 - Conformiteitsbeoordelingsprocedure
          url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_50
        - source: Overwerging 124 - Conformiteitsbeoordeling en harmonisatiewetgeving
          url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_124
        - source: Bijlage 1 - Lijst van harmonisatiewetgeving van de Unie
          url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e38-124-1
        - source: Richtlijn 2006/42/EG - Machines
          url: https://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=OJ:L:2006:157:0024:0086:NL:PDF
        - source: Richtlijn 2009/48/EG - Veiligheid van speelgoed
          url: https://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=OJ:L:2009:170:0001:0037:nl:PDF
        - source: Richtlijn 2013/53/EU - Pleziervaartuigen en waterscooters
          url: https://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=OJ:L:2013:354:0090:0131:NL:PDF
        - source: Richtlijn 2014/33/EU - Harmonisatie van lidstaatwetgeving over liftveiligheid.
          url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32014L0033
        - source: Richtlijn 2014/43/EU - Harmonisatie van lidstaatwetgeving over explosieveilige apparaten
        - source:  Richtlijn 2014/53/EU - Harmonisatie van lidstaatwetgeving over radioapparatuur
          url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32014L0053
        - source: Richtlijn 2014/68/EU - Harmonisatie van wetgeving over drukapparatuur
          url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32014L0068
        - source: Verordening 2016/424 - Kabelbaaninstallaties
          url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32016R0424
        - source: Verordening (EU) 2016/425 - Persoonlijke beschermingsmiddelen
          url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32016R0425
        - source: Verordening (EU) 2016/426 - Gasverbrandingstoestellen
          url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32016R0426&from=DE
        - source: Verordening (EU) 2017/745 - Medische hulpmiddelen
          url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32017R0745
        - source: Verordening (EU) 2017/746 - Medische hulpmiddelen voor in-vitrodiagnostiek
          url: https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=CELEX:32017R0746
    answers:
      - answer: Ja
        labels:
          - "beoordeling door derde partij"
        nextQuestionId: "2.9" #transparantieverplichting
      - answer: Nee
        labels:
          - "niet van toepassing"
        nextQuestionId: "2.9" ##transparantieverplichting

## Conformiteitsbeoordeling door derde partij bijlage III
  - questionId: "2.7.2"
    question: "Is het verplicht om de conformiteitsbeoordeling door een derde partij, zoals een conformiteitsbeoordelingsinstantie, uit te laten voeren?"
    explanation: "Een conformiteitsbeoordeling door een derde partij is verplicht indien het AI-systemen is bedoeld om voor biometrie te worden gebruikt."
    category: risicogroep
    subcategory: "Conformiteitsbeoordeling Bijlage III"
    sources:
      - source: Artikel 43 - Conformiteitsbeoordeling
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5074-1-1
      - source: Overweging 125 - Conformiteitsbeoordeling biometrie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_125
      - source: Bijlage III
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#anx_III
    answers:
      - answer: Ja
        labels:
          - "beoordeling door derde partij"
        nextQuestionId: "2.5" #profilering
      - answer: Nee
        labels:
          - "niet van toepassing"
        nextQuestionId: "2.5" #profilering

## Systeemrisico van het gebruike AI-model voor algemene doeleinden
  - questionId: "2.8"
    question: "Is er sprake van een systeemrisico?"
    explanation: "
      Is er in het gebruikte AI-model sprake van een cumulatieve hoeveelheid rekenkracht van FLOPs groter dan 10^25?<br><br>
      -	FLOPs zijn floating point operations per second.<br>
      -	FLOPs is een eenheid die wordt gebruikt om de rekenkracht van CPU’s aan te duiden.<br>
      -	CPUs zijn Central Processing Units.<br>
      - Dit is de centrale verwerkingseenheid van een computer, smartphone of tablet. De CPU voert het rekenwerk uit waardoor programma’s draaien en hardware wordt aangestuurd."
    category: risicogroep
    subcategory: "Systeemrisico"
    sources:
      - source: Artikel 55 - Systeemrisico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#art_55
    answers:
      - answer: Ja
        labels:
          - "systeemrisico"
        redirects:
          - nextConclusionId: "14.2.1"
            if: '"aanbieder" in labels && "gebruiksverantwoordelijke" in labels'
          - nextConclusionId: "13.2.1"
            if: '"gebruiksverantwoordelijke" in labels'
          - nextConclusionId: "12.2.1"
            if: '"aanbieder" in labels'
      - answer: Nee
        labels:
          - "geen systeemrisico"
        redirects:
          - nextQuestionId: "2.11" # open-source
            if: '"aanbieder" in labels'
          - nextConclusionId: "13.2.1"
            if: '"gebruiksverantwoordelijke" in labels'

## Transparantieverplichting
  - questionId: "2.9"
    question: "Moet het AI-systeem voldoen aan de transparantieverplichtingen?"
    explanation: "
      Dit betreft een AI-systeem dat bedoeld is voor een van de volgende doeleinden:<br><br>
      -	direct communiceert met mensen (zoals chatbots)?<br><br>
      -	synthetische afbeeldingen, audio, video of tekst content genereert en manipuleert? Bijvoorbeeld een deepfake.<br><br>
      -	aan emotieherkenning of biometrische categorisatie doet?"
    category: risicogroep
    subcategory: "Transparantieverplichting"
    sources:
      - source: Artikel 50 - Transparantieverplichting
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5426-1-1
    answers:
      - answer: Ja
        nextQuestionId: "2.10" # uitzondering transparantieverplichting
      - answer: Nee
        labels:
          - "geen transparantieverplichting"
        redirects:
          - nextConclusionId: "14.0.2"
            if: '"aanbieder" in labels && "gebruiksverantwoordelijke" in labels && "AI-systeem" in labels && "hoog-risico AI" in labels'
          - nextConclusionId: "14.0.4"
            if: '"aanbieder" in labels && "gebruiksverantwoordelijke" in labels && "AI-systeem" in labels && "geen hoog-risico AI" in labels'
          - nextConclusionId: "14.1.2"
            if: '"aanbieder" in labels && "gebruiksverantwoordelijke" in labels && "AI-systeem voor algemene doeleinden" in labels && "hoog-risico AI" in labels'
          - nextConclusionId: "14.1.4"
            if: '"aanbieder" in labels && "gebruiksverantwoordelijke" in labels && "AI-systeem voor algemene doeleinden" in labels && "geen hoog-risico AI" in labels'
          - nextConclusionId: "13.0.2"
            if: '"gebruiksverantwoordelijke" in labels && "AI-systeem" in labels && "hoog-risico AI" in labels'
          - nextConclusionId: "13.0.4"
            if: '"gebruiksverantwoordelijke" in labels && "AI-systeem" in labels && "geen hoog-risico AI" in labels'
          - nextConclusionId: "13.1.2"
            if: '"gebruiksverantwoordelijke" in labels && "AI-systeem voor algemene doeleinden" in labels && "hoog-risico AI" in labels'
          - nextConclusionId: "13.1.4"
            if: '"gebruiksverantwoordelijke" in labels && "AI-systeem voor algemene doeleinden" in labels && "geen hoog-risico AI" in labels'
          - nextConclusionId: "12.0.2"
            if: '"aanbieder" in labels && "AI-systeem" in labels && "hoog-risico AI" in labels'
          - nextConclusionId: "12.0.4"
            if: '"aanbieder" in labels && "AI-systeem" in labels && "geen hoog-risico AI" in labels'
          - nextConclusionId: "12.1.2"
            if: '"aanbieder" in labels && "AI-systeem voor algemene doeleinden" in labels && "hoog-risico AI" in labels '
          - nextConclusionId: "12.1.4"
            if: '"aanbieder" in labels && "AI-systeem voor algemene doeleinden" in labels && "geen hoog-risico AI" in labels '


## Uitzondering Transparantieverplichting
  - questionId: "2.10"
    question: "Is er een uitzondering mogelijk op de transparantieverplichtingen?"
    explanation: "Dit betreft AI waarvan het bij wet is toegestaan om te gebruiken voor het opsporen, voorkomen, onderzoeken of vervolgen van strafbare feiten."
    category: risicogroep
    subcategory: "Uitzondering Transparantieverplichting"
    sources:
      - source: Artikel 50 - Transparantieverplichting
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5426-1-1
    answers:
      - answer: Ja
        labels:
          - "geen transparantieverplichting"
        redirects:
          - nextConclusionId: "14.0.2"
            if: '"aanbieder" in labels && "gebruiksverantwoordelijke" in labels && "AI-systeem" in labels && "hoog-risico AI" in labels'
          - nextConclusionId: "14.0.4"
            if: '"aanbieder" in labels && "gebruiksverantwoordelijke" in labels && "AI-systeem" in labels && "geen hoog-risico AI" in labels'
          - nextConclusionId: "14.1.2"
            if: '"aanbieder" in labels && "gebruiksverantwoordelijke" in labels && "AI-systeem voor algemene doeleinden" in labels && "hoog-risico AI" in labels'
          - nextConclusionId: "14.1.4"
            if: '"aanbieder" in labels && "gebruiksverantwoordelijke" in labels && "AI-systeem voor algemene doeleinden" in labels && "geen hoog-risico AI" in labels'
          - nextConclusionId: "13.0.2"
            if: '"gebruiksverantwoordelijke" in labels && "AI-systeem" in labels && "hoog-risico AI" in labels'
          - nextConclusionId: "13.0.4"
            if: '"gebruiksverantwoordelijke" in labels && "AI-systeem" in labels && "geen hoog-risico AI" in labels'
          - nextConclusionId: "13.1.2"
            if: '"gebruiksverantwoordelijke" in labels && "AI-systeem voor algemene doeleinden" in labels && "hoog-risico AI" in labels'
          - nextConclusionId: "13.1.4"
            if: '"gebruiksverantwoordelijke" in labels && "AI-systeem voor algemene doeleinden" in labels && "geen hoog-risico AI" in labels'
          - nextConclusionId: "12.0.2"
            if: '"aanbieder" in labels && "AI-systeem" in labels && "hoog-risico AI" in labels'
          - nextConclusionId: "12.0.4"
            if: '"aanbieder" in labels && "AI-systeem" in labels && "geen hoog-risico AI" in labels'
          - nextConclusionId: "12.1.2"
            if: '"aanbieder" in labels && "AI-systeem voor algemene doeleinden" in labels && "hoog-risico AI" in labels '
          - nextConclusionId: "12.1.4"
            if: '"aanbieder" in labels && "AI-systeem voor algemene doeleinden" in labels && "geen hoog-risico AI" in labels '
      - answer: Nee
        labels:
          - "transparantieverplichting"
        redirects:
          - nextConclusionId: "14.0.1"
            if: '"aanbieder" in labels && "gebruiksverantwoordelijke" in labels && "AI-systeem" in labels && "hoog-risico AI" in labels'
          - nextConclusionId: "14.0.3"
            if: '"aanbieder" in labels && "gebruiksverantwoordelijke" in labels && "AI-systeem" in labels && "geen hoog-risico AI" in labels'
          - nextConclusionId: "14.1.1"
            if: '"aanbieder" in labels && "gebruiksverantwoordelijke" in labels && "AI-systeem voor algemene doeleinden" in labels && "hoog-risico AI" in labels'
          - nextConclusionId: "14.1.3"
            if: '"aanbieder" in labels && "gebruiksverantwoordelijke" in labels && "AI-systeem voor algemene doeleinden" in labels && "geen hoog-risico AI" in labels'
          - nextConclusionId: "13.0.1"
            if: '"gebruiksverantwoordelijke" in labels && "AI-systeem" in labels && "hoog-risico AI" in labels'
          - nextConclusionId: "13.0.3"
            if: '"gebruiksverantwoordelijke" in labels && "AI-systeem" in labels && "geen hoog-risico AI" in labels'
          - nextConclusionId: "13.1.1"
            if: '"gebruiksverantwoordelijke" in labels && "AI-systeem voor algemene doeleinden" in labels && "hoog-risico AI" in labels'
          - nextConclusionId: "13.1.3"
            if: '"gebruiksverantwoordelijke" in labels && "AI-systeem voor algemene doeleinden" in labels && "geen hoog-risico AI" in labels'
          - nextConclusionId: "12.0.1"
            if: '"aanbieder" in labels && "AI-systeem" in labels && "hoog-risico AI" in labels'
          - nextConclusionId: "12.0.3"
            if: '"aanbieder" in labels && "AI-systeem" in labels && "geen hoog-risico AI" in labels'
          - nextConclusionId: "12.1.1"
            if: '"aanbieder" in labels && "AI-systeem voor algemene doeleinden" in labels && "hoog-risico AI" in labels'
          - nextConclusionId: "12.1.3"
            if: '"aanbieder" in labels && "AI-systeem voor algemene doeleinden" in labels && "geen hoog-risico AI" in labels'

## Open-source "Zijn de broncodes en parameters openbaar voor eenieder?"
  - questionId: "2.11"
    question: "Wordt de toepassing onder een open of vrije licentie gedeeld en zijn de broncodes en parameters openbaar voor eenieder?"
    explanation: ""
    category: risicogroep
    subcategory: "Open of vrije licentie"
    sources:
      - source: Overweging 102 - Begrip open-source
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_102
    answers:
      - answer: Ja
        labels:
          - "open-source"
        redirects:
          - nextConclusionId: "14.2.2"
            if: '"aanbieder" in labels && "gebruiksverantwoordelijke" in labels'
          - nextConclusionId: "12.2.2"
            if: '"aanbieder" in labels'
      - answer: Nee
        labels:
          - "geen open-source"
        redirects:
         - nextConclusionId: "14.2.3"
           if: '"aanbieder" in labels && "gebruiksverantwoordelijke" in labels'
         - nextConclusionId: "12.2.3"
           if: '"aanbieder" in labels'

### Conclusies
conclusions:
###Conclusies 12.0.1 tm 12.1.2 voor aanbieders
  - conclusionId: "12.0.0"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent aanbieder van een verboden AI-systeem."
    obligation: "Het AI-systeem moet van de markt worden gehaald. Let op: dit verbod geldt vanaf 1 februari 2025."
    sources:
      - source: Artikel 5 - Verboden AI praktijken
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2816-1-1
  - conclusionId: "12.0.1"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een hoog-risico AI-systeem. Het AI-systeem moet voldoen aan transparantieverplichtingen. "
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
        - AI-geletterdheid (Artikel 4)<br>
        - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking. <br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Verplichtingen voor aanbieder van een hoog risico AI-systeem (Artikel 16):<br>
          - aanbieders zorgen ervoor dat hun AI-systemen met een hoog risico in overeenstemming zijn met de eisen van afdeling 2<br>
          - aanbieders vermelden op het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, naargelang het geval, hun naam, geregistreerde handelsnaam of geregistreerd merk en hun contactadres<br>
          - aanbieders beschikken over een systeem voor kwaliteitsbeheer dat in overeenstemming is met Artikel 17 (systeem voor kwaliteitsbeheer)<br>
          - aanbieders bewaren de in Artikel 18 (bewaring van documentatie) bedoelde documentatie<br>
          - aanbieders bewaren de in Artikel 19 bedoelde logs die automatisch door hun AI-systemen met een hoog risico zijn gegenereerd, wanneer zij hierover de controle hebben<br>
          - aanbieders zorgen ervoor dat voor het AI-systeem met een hoog risico de desbetreffende in Artikel 43 bedoelde conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld<br>
          - aanbieders stellen een EU-conformiteitsverklaring op, in overeenstemming met Artikel 47. In het geval van het label 'beoordeling door derde partij' dient de uitvoering door een conformiteitsbeoordelingsinstantie te worden verzorgd. In het geval dat het AI-systeem gebruikmaakt van biometrie en wordt ingezet door rechtshandhavingsinstanties, immigratie- of asielautoriteiten, of door instellingen, organen of instanties van de Unie, treedt de markttoezichtautoriteit op als conformiteitsbeoordelingsinstantie. <br>
          - aanbieders brengen de CE-markering aan op het Ai-systeem met een hoog risico of, waneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan deze verordening is voldaan, overeenkomstig Artikel 48<br>
          - aanbieders leven de registratieverplichtingen als bedoeld in Artikel 49 lid 1, na<br>
          - aanbieders nemen de noodzakelijke corrigerende maatregelen en verstrekken de uit hoofde van Artikel 20 vereiste informatie<br>
          - aanbieders tonen op een met redenen omkleed verzoek van een nationale bevoegde autoriteit de overeenstemming aan van het AI-systeem met een hoog risico met de eisen van afdeling 2<br>
          - aanbieders zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882.<br><br>
        Verplichtingen voor aanbieders en gebruiksverantwoordelijken van AI-systemen met transparantieverplichtingen (Artikel 50):<br>
          - aanbieders zorgen ervoor dat AI-systemen die voor directe interactie met natuurlijke personen zijn bedoeld, zodanig worden ontworpen en ontwikkeld
            dat de betrokken natuurlijke personen worden geinformeerd dat zij interageren met een AI-systeem, tenzij dit duidelijk is vanuit het oogpunt van een normaal geinformeerde
            en redelijk omzichtige en oplettende natuurlijke persoon, rekening houdend met de omstandigheden en de gebruikscontext.<br>
          - aanbieders van (GP)AI-systemen, die synthetische audio, beeld, video- of tekstinhoud genereren, zorgen ervoor dat de outputs van het AI-systeem worden
            gemarkeerd in een machineleesbaar formaat en detecteerbaar zijn als kunstmatig gegenereerd of gemanipuleerd. Aanbieders zorgen ervoor dat hun technische oplossingen doeltreffend, interoperabel
            robuust en betrouwbaar zijn voor zover dat technisch haalbaar is, rekening houdend met de specifieke kenmerken en beperkingen van de verschillende soorten content, de uitvoeringskosten
            en de algemeen erkende stand van de techniek, zoals tot uiting kan komen in relevante technische normen.<br><br>
        Geldig vanaf (Artikel 111):<br>
         - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
         - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br>"
    sources:
      - source: Afdeling 2 - Eisen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#cpt_III.sct_2
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 16 - Verplichtingen van aanbieders van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3823-1-1
      - source: Artikel 17 - Systeem voor kwaliteitsbeheer
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3906-1-1
      - source: Artikel 18 - Bewaring van documentatie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4013-1-1
      - source: Artikel 19 - Automatisch gegenereerde logs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4066-1-1
      - source: Artikel 20 - Corrigerende maatregelen en mededelingsverplichting
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4082-1-1
      - source: Artikel 43 - Conformiteitsbeoordeling
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5074-1-1
      - source: Artikel 47 - EU-conformiteitsverklaring
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5296-1-1
      - source: Artikel 48 - CE-markering
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5327-1-1
      - source: Artikel 49 - Registratie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5358-1-1
      - source: Artikel 50 - Transparantieverplichtingen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5426-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
  - conclusionId: "12.0.2"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een hoog-risico AI-systeem."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
        - Bevordering van AI-geletterdheid (Artikel 4)<br>
        - Gedragscodes voor de vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Verplichtingen voor aanbieder van een hoog risico AI-systeem (Artikel 16):<br>
          - aanbieders zorgen ervoor dat hun AI-systemen met een hoog risico in overeenstemming zijn met de eisen van afdeling 2<br>
          - aanbieders vermelden op het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, naargelang het geval, hun naam, geregistreerde handelsnaam of geregistreerd merk en hun contactadres<br>
          - aanbieders beschikken over een systeem voor kwaliteitsbeheer dat in overeenstemming is met Artikel 17 (systeem voor kwaliteitsbeheer)<br>
          - aanbieders bewaren de in Artikel 18 (bewaring van documentatie) bedoelde documentatie<br>
          - aanbieders bewaren de in Artikel 19 bedoelde logs die automatisch door hun AI-systemen met een hoog risico zijn gegenereerd, wanneer zij hierover de controle hebben<br>
          - aanbieders zorgen ervoor dat voor het AI-systeem met een hoog risico de desbetreffende in Artikel 43 bedoelde conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld<br>
          - aanbieders stellen een EU-conformiteitsverklaring op, in overeenstemming met Artikel 47. In het geval van het label 'beoordeling door derde partij' dient de uitvoering door een conformiteitsbeoordelingsinstantie te worden verzorgd. In het geval dat het AI-systeem gebruikmaakt van biometrie en wordt ingezet door rechtshandhavingsinstanties, immigratie- of asielautoriteiten, of door instellingen, organen of instanties van de Unie, treedt de markttoezichtautoriteit op als conformiteitsbeoordelingsinstantie. <br>
          - aanbieders brengen de CE-markering aan op het Ai-systeem met een hoog risico of, waneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan deze verordening is voldaan, overeenkomstig Artikel 48<br>
          - aanbieders leven de registratieverplichtingen als bedoeld in Artikel 49 lid 1, na<br>
          - aanbieders nemen de noodzakelijke corrigerende maatregelen en verstrekken de uit hoofde van Artikel 20 vereiste informatie<br>
          - aanbieders tonen op een met redenen omkleed verzoek van een nationale bevoegde autoriteit de overeenstemming aan van het AI-systeem met een hoog risico met de eisen van afdeling 2<br>
          - aanbieders zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882.<br><br>
        Geldig vanaf (Artikel 111):<br>
          - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
          - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br>"
    sources:
      - source: Afdeling 2 - Eisen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#cpt_III.sct_2
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 16 - Verplichtingen van aanbieders van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3823-1-1
      - source: Artikel 17 - Systeem voor kwaliteitsbeheer
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3906-1-1
      - source: Artikel 18 - Bewaring van documentatie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4013-1-1
      - source: Artikel 19 - Automatisch gegenereerde logs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4066-1-1
      - source: Artikel 20 - Corrigerende maatregelen en mededelingsverplichting
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4082-1-1
      - source: Artikel 43 - Conformiteitsbeoordeling
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5074-1-1
      - source: Artikel 47 - EU-conformiteitsverklaring
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5296-1-1
      - source: Artikel 48 - CE-markering
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5327-1-1
      - source: Artikel 49 - Registratie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5358-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
  - conclusionId: "12.0.3"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een niet-hoog-risico AI-systeem. Het AI-systeem moet voldoen aan transparantieverplichtingen."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
        - Bevordering van AI-geletterdheid (Artikel 4)<br>
        - Gedragscodes voor de vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Verplichtingen voor aanbieders en gebruiksverantwoordelijken van AI-systemen met transparantieverplichtingen (Artikel 50):<br>
          - aanbieders zorgen ervoor dat AI-systemen die voor directe interactie met natuurlijke personen zijn bedoeld, zodanig worden ontworpen en ontwikkeld
            dat de betrokken natuurlijke personen worden geinformeerd dat zij interageren met een AI-systeem, tenzij dit duidelijk is vanuit het oogpunt van een normaal geinformeerde
            en redelijk omzichtige en oplettende natuurlijke persoon, rekening houdend met de omstandigheden en de gebruikscontext.<br>
          - aanbieders van (GP)AI-systemen, die synthetische audio, beeld, video- of tekstinhoud genereren, zorgen ervoor dat de outputs van het AI-systeem worden
            gemarkeerd in een machineleesbaar formaat en detecteerbaar zijn als kunstmatig gegenereerd of gemanipuleerd. Aanbieders zorgen ervoor dat hun technische oplossingen doeltreffend, interoperabel
            robuust en betrouwbaar zijn voor zover dat technisch haalbaar is, rekening houdend met de specifieke kenmerken en beperkingen van de verschillende soorten content, de uitvoeringskosten
            en de algemeen erkende stand van de techniek, zoals tot uiting kan komen in relevante technische normen.<br><br>
      Geldig vanaf (Artikel 111):<br>
         - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
         - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br>"
    sources:
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 50 - Transparantieverplichtingen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5426-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
  - conclusionId: "12.0.4"
    conclusion: "Je bent een aanbieder van een niet-hoog-risico AI-systeem."
    obligation: "
     Verplichtingen voor alle AI-systemen:<br>
        - Bevordering van AI-geletterdheid (Artikel 4)<br>
        - Gedragscodes voor de vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Geldig vanaf (Artikel 111):<br>
         - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
         - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br>"
    sources:
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
  - conclusionId: "12.1.1"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een hoog-risico AI-systeem voor algemene doeleinden. Het AI-systeem moet voldoen aan transparantieverplichtingen."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
        - Bevordering van AI-geletterdheid (Artikel 4)<br>
        - Gedragscodes voor de vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Verplichtingen voor aanbieder van een hoog risico AI-systeem (Artikel 16):<br>
          - aanbieders zorgen ervoor dat hun AI-systemen met een hoog risico in overeenstemming zijn met de eisen van afdeling 2<br>
          - aanbieders vermelden op het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, naargelang het geval, hun naam, geregistreerde handelsnaam of geregistreerd merk en hun contactadres<br>
          - aanbieders beschikken over een systeem voor kwaliteitsbeheer dat in overeenstemming is met Artikel 17 (systeem voor kwaliteitsbeheer)<br>
          - aanbieders bewaren de in Artikel 18 (bewaring van documentatie) bedoelde documentatie<br>
          - aanbieders bewaren de in Artikel 19 bedoelde logs die automatisch door hun AI-systemen met een hoog risico zijn gegenereerd, wanneer zij hierover de controle hebben<br>
          - aanbieders zorgen ervoor dat voor het AI-systeem met een hoog risico de desbetreffende in Artikel 43 bedoelde conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld<br>
          - aanbieders stellen een EU-conformiteitsverklaring op, in overeenstemming met Artikel 47. In het geval van het label 'beoordeling door derde partij' dient de uitvoering door een conformiteitsbeoordelingsinstantie te worden verzorgd. In het geval dat het AI-systeem gebruikmaakt van biometrie en wordt ingezet door rechtshandhavingsinstanties, immigratie- of asielautoriteiten, of door instellingen, organen of instanties van de Unie, treedt de markttoezichtautoriteit op als conformiteitsbeoordelingsinstantie. <br>
          - aanbieders brengen de CE-markering aan op het Ai-systeem met een hoog risico of, waneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan deze verordening is voldaan, overeenkomstig Artikel 48<br>
          - aanbieders leven de registratieverplichtingen als bedoeld in Artikel 49 lid 1, na<br>
          - aanbieders nemen de noodzakelijke corrigerende maatregelen en verstrekken de uit hoofde van Artikel 20 vereiste informatie<br>
          - aanbieders tonen op een met redenen omkleed verzoek van een nationale bevoegde autoriteit de overeenstemming aan van het AI-systeem met een hoog risico met de eisen van afdeling 2<br>
          - aanbieders zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882.<br><br>
      Verplichtingen voor aanbieders en gebruiksverantwoordelijken van AI-systemen met transparantieverplichtingen (Artikel 50):<br>
          - aanbieders zorgen ervoor dat AI-systemen die voor directe interactie met natuurlijke personen zijn bedoeld, zodanig worden ontworpen en ontwikkeld
            dat de betrokken natuurlijke personen worden geinformeerd dat zij interageren met een AI-systeem, tenzij dit duidelijk is vanuit het oogpunt van een normaal geinformeerde
            en redelijk omzichtige en oplettende natuurlijke persoon, rekening houdend met de omstandigheden en de gebruikscontext.<br>
          - aanbieders van (GP)AI-systemen, die synthetische audio, beeld, video- of tekstinhoud genereren, zorgen ervoor dat de outputs van het AI-systeem worden
            gemarkeerd in een machineleesbaar formaat en detecteerbaar zijn als kunstmatig gegenereerd of gemanipuleerd. Aanbieders zorgen ervoor dat hun technische oplossingen doeltreffend, interoperabel
            robuust en betrouwbaar zijn voor zover dat technisch haalbaar is, rekening houdend met de specifieke kenmerken en beperkingen van de verschillende soorten content, de uitvoeringskosten
            en de algemeen erkende stand van de techniek, zoals tot uiting kan komen in relevante technische normen.<br><br>
     Geldig vanaf (Artikel 111):<br>
         - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
         - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>
     De volgende verplichtingen gelden voor de aanbieder van het AI-model voor algemene doeleinden, waarop het AI-systeem voor algemene doeleinden is gebaseerd (Artikel 53 en Artikel 54):<br>
      - de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan<br>
      - informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren<br>
      - beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën<br>
      - een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br>
      Geldig vanaf (Artikel 111 en Overweging 179):<br>
      - Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br>
      - Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
    sources:
      - source: Afdeling 2 - Eisen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#cpt_III.sct_2
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 16 - Verplichtingen van aanbieders van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3823-1-1
      - source: Artikel 17 - Systeem voor kwaliteitsbeheer
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3906-1-1
      - source: Artikel 18 - Bewaring van documentatie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4013-1-1
      - source: Artikel 19 - Automatisch gegenereerde logs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4066-1-1
      - source: Artikel 20 - Corrigerende maatregelen en mededelingsverplichting
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4082-1-1
      - source: Artikel 43 - Conformiteitsbeoordeling
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5074-1-1
      - source: Artikel 47 - EU-conformiteitsverklaring
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5296-1-1
      - source: Artikel 48 - CE-markering
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5327-1-1
      - source: Artikel 49 - Registratie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5358-1-1
      - source: Artikel 50 - Transparantieverplichtingen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5426-1-1
      - source: Artikel 53 - Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5576-1-1
      - source: Artikel 54 - Gemachtigden van aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5657-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
      - source: Overweging 179 - Ingangtreding verordening
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_179
  - conclusionId: "12.1.2"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een hoog-risico AI-systeem voor algemene doeleinden."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
        - Bevordering van AI-geletterdheid (Artikel 4)<br>
        - Gedragscodes voor de vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Verplichtingen voor aanbieder van een hoog risico AI-systeem (Artikel 16):<br>
          - aanbieders zorgen ervoor dat hun AI-systemen met een hoog risico in overeenstemming zijn met de eisen van afdeling 2<br>
          - aanbieders vermelden op het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, naargelang het geval, hun naam, geregistreerde handelsnaam of geregistreerd merk en hun contactadres<br>
          - aanbieders beschikken over een systeem voor kwaliteitsbeheer dat in overeenstemming is met Artikel 17 (systeem voor kwaliteitsbeheer)<br>
          - aanbieders bewaren de in Artikel 18 (bewaring van documentatie) bedoelde documentatie<br>
          - aanbieders bewaren de in Artikel 19 bedoelde logs die automatisch door hun AI-systemen met een hoog risico zijn gegenereerd, wanneer zij hierover de controle hebben<br>
          - aanbieders zorgen ervoor dat voor het AI-systeem met een hoog risico de desbetreffende in Artikel 43 bedoelde conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld<br>
          - aanbieders stellen een EU-conformiteitsverklaring op, in overeenstemming met Artikel 47. In het geval van het label 'beoordeling door derde partij' dient de uitvoering door een conformiteitsbeoordelingsinstantie te worden verzorgd. In het geval dat het AI-systeem gebruikmaakt van biometrie en wordt ingezet door rechtshandhavingsinstanties, immigratie- of asielautoriteiten, of door instellingen, organen of instanties van de Unie, treedt de markttoezichtautoriteit op als conformiteitsbeoordelingsinstantie. <br>
          - aanbieders brengen de CE-markering aan op het Ai-systeem met een hoog risico of, waneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan deze verordening is voldaan, overeenkomstig Artikel 48<br>
          - aanbieders leven de registratieverplichtingen als bedoeld in Artikel 49 lid 1, na<br>
          - aanbieders nemen de noodzakelijke corrigerende maatregelen en verstrekken de uit hoofde van Artikel 20 vereiste informatie<br>
          - aanbieders tonen op een met redenen omkleed verzoek van een nationale bevoegde autoriteit de overeenstemming aan van het AI-systeem met een hoog risico met de eisen van afdeling 2<br>
          - aanbieders zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882.<br><br>
     Geldig vanaf (Artikel 111):<br>
         - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
         - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>
     De volgende verplichtingen gelden voor de aanbieder van het AI-model voor algemene doeleinden, waarop het AI-systeem voor algemene doeleinden is gebaseerd (Artikel 53 en Artikel 54):<br>
      - de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan<br>
      - informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren<br>
      - beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën<br>
      - een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br>
      Geldig vanaf (Artikel 111 en Overweging 179):<br>
      - Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br>
      - Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
    sources:
      - source: Afdeling 2 - Eisen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#cpt_III.sct_2
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 16 - Verplichtingen van aanbieders van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3823-1-1
      - source: Artikel 17 - Systeem voor kwaliteitsbeheer
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3906-1-1
      - source: Artikel 18 - Bewaring van documentatie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4013-1-1
      - source: Artikel 19 - Automatisch gegenereerde logs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4066-1-1
      - source: Artikel 20 - Corrigerende maatregelen en mededelingsverplichting
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4082-1-1
      - source: Artikel 43 - Conformiteitsbeoordeling
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5074-1-1
      - source: Artikel 47 - EU-conformiteitsverklaring
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5296-1-1
      - source: Artikel 48 - CE-markering
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5327-1-1
      - source: Artikel 49 - Registratie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5358-1-1
      - source: Artikel 53 - Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5576-1-1
      - source: Artikel 54 - Gemachtigden van aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5657-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
      - source: Overweging 179 - Ingangtreding verordening
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_179
  - conclusionId: "12.1.3"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een niet-hoog-risico AI-systeem voor algemene doeleinden. Het AI-systeem moet voldoen aan transparantieverplichtingen."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
        - Bevordering van AI-geletterdheid (Artikel 4)<br>
        - Gedragscodes voor de vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Verplichtingen voor aanbieders en gebruiksverantwoordelijken van AI-systemen met transparantieverplichtingen (Artikel 50):<br>
          - aanbieders zorgen ervoor dat AI-systemen die voor directe interactie met natuurlijke personen zijn bedoeld, zodanig worden ontworpen en ontwikkeld
            dat de betrokken natuurlijke personen worden geinformeerd dat zij interageren met een AI-systeem, tenzij dit duidelijk is vanuit het oogpunt van een normaal geinformeerde
            en redelijk omzichtige en oplettende natuurlijke persoon, rekening houdend met de omstandigheden en de gebruikscontext.<br>
          - aanbieders van (GP)AI-systemen, die synthetische audio, beeld, video- of tekstinhoud genereren, zorgen ervoor dat de outputs van het AI-systeem worden
            gemarkeerd in een machineleesbaar formaat en detecteerbaar zijn als kunstmatig gegenereerd of gemanipuleerd. Aanbieders zorgen ervoor dat hun technische oplossingen doeltreffend, interoperabel
            robuust en betrouwbaar zijn voor zover dat technisch haalbaar is, rekening houdend met de specifieke kenmerken en beperkingen van de verschillende soorten content, de uitvoeringskosten
            en de algemeen erkende stand van de techniek, zoals tot uiting kan komen in relevante technische normen.<br><br>
     Geldig vanaf (Artikel 111):<br>
         - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
         - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>
     De volgende verplichtingen gelden voor de aanbieder van het AI-model voor algemene doeleinden, waarop het AI-systeem voor algemene doeleinden is gebaseerd (Artikel 53 en Artikel 54):<br>
      - de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan<br>
      - informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren<br>
      - beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën<br>
      - een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br>
      Geldig vanaf (Artikel 111 en Overweging 179):<br>
      - Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br>
      - Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 50 - Transparantieverplichtingen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5426-1-1
      - source: Artikel 53 - Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5576-1-1
      - source: Artikel 54 - Gemachtigden van aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5657-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
      - source: Overweging 179 - Ingangtreding verordening
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_179
  - conclusionId: "12.1.4"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een niet-hoog-risico AI-systeem voor algemene doeleinden."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
        - Bevordering van AI-geletterdheid (Artikel 4)<br>
        - Gedragscodes voor de vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
     De volgende verplichtingen gelden voor de aanbieder van het AI-model voor algemene doeleinden, waarop het AI-systeem voor algemene doeleinden is gebaseerd (Artikel 53 en Artikel 54):<br>
      - de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan<br>
      - informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren<br>
      - beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën<br>
      - een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br>
      Geldig vanaf (Artikel 111 en Overweging 179):<br>
      - Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br>
      - Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 53 - Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5576-1-1
      - source: Artikel 54 - Gemachtigden van aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5657-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
      - source: Overweging 179 - Ingangtreding verordening
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_179
  - conclusionId: "12.2.1"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een AI-model voor algemene doeleinden. Er is sprake van een systeemrisico."
    obligation: "
      Verplichtingen voor alle AI-modellen voor algemene doeleinden:<br>
        - Praktijkcodes (Artikel 56)<br><br>
      Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden (Artikel 53 en Artikel 54):<br>
      - de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan.<br>
      - informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.<br>
      - beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën.<br>
      - een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br>
      Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico (Artikel 55):<br>
      - het uitvoeren van een modelevaluatie overeenkomstig gestandaardiseerde protocollen en instrumenten die de stand van de techniek weerspiegelen, met inbegrip van het uitvoeren en documenteren van tests gericht op het ontdekken van kwetsbaarheden van het model met als doel om systeemrisico’s in kaart te brengen en te beperken.<br>
      - het beoordelen en beperken van mogelijke systeemrisico’s op Unieniveau, met inbegrip van de bronnen daarvan, die kunnen voortvloeien uit de ontwikkeling, het in de handel brengen of het gebruik van AI-modellen voor algemene doeleinden met een systeemrisico.<br>
      - het bijhouden, documenteren en onverwijld rapporteren (aan het AI-bureau (en in voorkomende gevallen aan de nationale bevoegde autoriteiten)) van relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen.<br>
      - het zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden en de fysieke infrastructuur van het model.<br><br>
      Geldig vanaf (Artikel 111 en Overweging 179):<br>
      - Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br>
      - Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 51 - Classificatie van AI-modellen voor algemene doeleinden als AI-modellen voor algemene doeleinden met een systeemrisico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5489-1-1
      - source: Artikel 53 - Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5576-1-1
      - source: Artikel 54 - Gemachtigden van aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5657-1-1
      - source: Artikel 55 - Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5730-1-1
      - source: Artikel 56 - Praktijkcodes
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5788-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
      - source: Overweging 179 - Ingangtreding verordening
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_179
  - conclusionId: "12.2.2"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een open-source AI-model voor algemene doeleinden."
    obligation: "
      Verplichtingen voor alle AI-modellen voor algemene doeleinden:<br>
        - Praktijkcodes (Artikel 56)<br><br>
      Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden (Artikel 53 en Artikel 54):<br>
      - beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën.<br>
      - een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br>
      - Door overweging 104 voor open-source AI-modellen voor algemene doeleinden hoef je niet te voldoen aan: de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan.<br>
      - Door overweging 104 voor open-source AI-modellen voor algemene doeleinden hoef je niet te voldoen aan: informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.<br><br>
      Geldig vanaf (Artikel 111 en Overweging 179):<br>
      - Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br>
      - Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 51 - Classificatie van AI-modellen voor algemene doeleinden als AI-modellen voor algemene doeleinden met een systeemrisico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5489-1-1
      - source: Artikel 53 - Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5576-1-1
      - source: Artikel 54 - Gemachtigden van aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5657-1-1
      - source: Artikel 55 - Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5730-1-1
      - source: Artikel 56 - Praktijkcodes
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5788-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
      - source: Overweging 104 - Transparantie-uitzonderingen open-source AI-modellen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_104
      - source: Overweging 179 - Ingangtreding verordening
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_179
  - conclusionId: "12.2.3"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder van een AI-model voor algemene doeleinden."
    obligation: "
      Verplichtingen voor alle AI-modellen voor algemene doeleinden:<br>
        - Praktijkcodes (Artikel 56)<br><br>
      Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden (Artikel 53 en Artikel 54):<br>
      - de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan. <br>
      - informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren. <br>
      - beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën.<br>
      - een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br>
      Aangezien het geen open-source toepassing is, gelden er geen uitzonderingen. <br><br>
      Geldig vanaf (Artikel 111 en Overweging 179 ):<br>
      - Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br>
      - Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 51 - Classificatie van AI-modellen voor algemene doeleinden als AI-modellen voor algemene doeleinden met een systeemrisico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5489-1-1
      - source: Artikel 53 - Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5576-1-1
      - source: Artikel 54 - Gemachtigden van aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5657-1-1
      - source: Artikel 55 - Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5730-1-1
      - source: Artikel 56 - Praktijkcodes
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5788-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
      - source: Overweging 179 - Ingangtreding verordening
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_179
# Conclusies 13.0.1 tm 13.2.1 voor gebruiksverantwoordelijken
  - conclusionId: "13.0.0"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent gebruiksverantwoordelijke van een verboden AI-systeem."
    obligation: "Het gebruik van het AI-systeem moet worden stop gezet. Let op: dit geldt vanaf 1 februari 2025."
    sources:
      - source: Artikel 5 - Verboden AI praktijken
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2816-1-1
  - conclusionId: "13.0.1"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke van een hoog-risico AI-systeem. Het AI-systeem moet voldoen aan transparantieverplichtingen. "
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
          - AI-geletterdheid (Artikel 4)<br>
          - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico (Artikel 26 en Artikel 27):<br>
        - het nemen van passende technische en organisatorische maatregelen om te waarborgen dat dergelijke systemen in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd worden gebruikt<br>
        - het opdragen van menselijk toezicht aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen<br>
        - het ervoor zorgen dat, voor zover de gebruikersverantwoordelijke controle heeft over de inputdata, de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico<br>
        - het monitoren van de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en in voorkomend geval het in kennis stellen van de aanbieders overeenkomstig Artikel 72.<br>
        - het bewaren van de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder controle van de gebruiksverantwoordelijke vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden<br>
        - voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico<br>
        - gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in Artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in Artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis<br>
        - indien van toepassing, gebruiken gebruiksverantwoordelijken van AI-systemen met een hoog risico de informatie die op grond van Artikel 13 van deze verordening wordt verstrekt om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren<br>
        - de gebruiksverantwoordelijke van een AI-systeem met een hoog risico voor biometrische identificatie op afstand verzoekt achteraf in het kader van een onderzoek waarbij gericht wordt gezocht naar een persoon die wordt verdacht van of veroordeeld is voor het plegen van een strafbaar feit, vooraf of zonder onnodige vertraging en uiterlijk 48 uur na het feit, om toestemming van een gerechtelijke instantie of administratieve instantie, van wie de beslissing bindend is en onderworpen is aan rechterlijke toetsing, voor het gebruik van dat systeem, behalve wanneer het wordt gebruikt voor de initiële identificatie van een potentiële verdachte op basis van objectieve en verifieerbare feiten die rechtstreeks verband houden met het strafbare feit. Elk gebruik wordt beperkt tot hetgeen strikt noodzakelijk is voor het onderzoek naar een specifiek strafbaar feit<br>
        - gebruiksverantwoordelijken van in bijlage III bedoelde AI-systemen met een hoog risico die beslissingen met betrekking tot natuurlijke personen nemen of helpen nemen, informeren de natuurlijke personen dat het AI-systeem met een hoog risico op hen wordt toegepast.<br>
        - gebruiksverantwoordelijken werken samen met de relevante bevoegde autoriteiten bij alle door deze autoriteiten genomen maatregelen met betrekking tot een AI-systeem met een hoog risico met het oog op de uitvoering van deze verordening.<br>
        - gebruiksverantwoordelijken die publiekrechtelijke organen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruikt in krediet/verzekering (bijlage III, 5, c en d) een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren (Artikel 27).<br><br>
      Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systemen (Artikel 50):<br>
          - gebruiksverantwoordelijken van een systeem voor het herkennen van emoties of een systeem voor biometrische categorisering informeren de daaraan blootgestelde natuurlijke personen over de werking van het systeem en verwerken de persoonsgegevens in overeenstemming met Verordening (EU) 2016/679, Verordening (EU) 2018/1725 en Richtlijn (EU) 2016/680, indien van toepassing<br>
          - gebruiksverantwoordelijken van een AI-systeem dat beeld-, audio- of videocontent genereert of bewerkt die een deepfake vormt, maken bekend dat de content kunstmatig is gegenereerd of gemanipuleerd. Wanneer de content deel uitmaakt van een kennelijk artistiek, creatief, satirisch, fictief of analoog werk of programma, zijn de transparantieverplichtingen beperkt tot de openbaarmaking van het bestaan van dergelijke gegenereerde of bewerkte content op een passende wijze die de weergave of het genot van het werk niet belemmert.<br><br>
      Geldig vanaf (Artikel 111):<br>
          - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
          - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 26 - Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4350-1-1
      - source: Artikel 27 - Beoordeling van de gevolgen voor de grondrechten van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4433-1-1
      - source: Artikel 50 - Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5426-1-1
      - source: Artikel 72 - Monitoring door aanbieders na het in de handel brengen en plan voor monitoring na het in de handel brengen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7075-1-1
      - source: Artikel 73 - Melding van ernstige incidenten
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7117-1-1
      - source: Artikel 79 - Procedure op nationaal niveau voor de omgang met AI-systemen die een risico vormen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7480-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
  - conclusionId: "13.0.2"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke van een hoog-risico AI-systeem."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
          - AI-geletterdheid (Artikel 4)<br>
          - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico (Artikel 26 en Artikel 27):<br>
        - het nemen van passende technische en organisatorische maatregelen om te waarborgen dat dergelijke systemen in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd worden gebruikt<br>
        - het opdragen van menselijk toezicht aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen<br>
        - het ervoor zorgen dat, voor zover de gebruikersverantwoordelijke controle heeft over de inputdata, de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico<br>
        - het monitoren van de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en in voorkomend geval het in kennis stellen van de aanbieders overeenkomstig Artikel 72.<br>
        - het bewaren van de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder controle van de gebruiksverantwoordelijke vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden<br>
        - voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico<br>
        - gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in Artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in Artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis<br>
        - indien van toepassing, gebruiken gebruiksverantwoordelijken van AI-systemen met een hoog risico de informatie die op grond van Artikel 13 van deze verordening wordt verstrekt om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren<br>
        - de gebruiksverantwoordelijke van een AI-systeem met een hoog risico voor biometrische identificatie op afstand verzoekt achteraf in het kader van een onderzoek waarbij gericht wordt gezocht naar een persoon die wordt verdacht van of veroordeeld is voor het plegen van een strafbaar feit, vooraf of zonder onnodige vertraging en uiterlijk 48 uur na het feit, om toestemming van een gerechtelijke instantie of administratieve instantie, van wie de beslissing bindend is en onderworpen is aan rechterlijke toetsing, voor het gebruik van dat systeem, behalve wanneer het wordt gebruikt voor de initiële identificatie van een potentiële verdachte op basis van objectieve en verifieerbare feiten die rechtstreeks verband houden met het strafbare feit. Elk gebruik wordt beperkt tot hetgeen strikt noodzakelijk is voor het onderzoek naar een specifiek strafbaar feit<br>
        - gebruiksverantwoordelijken van in bijlage III bedoelde AI-systemen met een hoog risico die beslissingen met betrekking tot natuurlijke personen nemen of helpen nemen, informeren de natuurlijke personen dat het AI-systeem met een hoog risico op hen wordt toegepast.<br>
        - gebruiksverantwoordelijken werken samen met de relevante bevoegde autoriteiten bij alle door deze autoriteiten genomen maatregelen met betrekking tot een AI-systeem met een hoog risico met het oog op de uitvoering van deze verordening.<br>
        - gebruiksverantwoordelijken die publiekrechtelijke organen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruikt in krediet/verzekering (bijlage III, 5, c en d) een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren (Artikel 27).<br><br>
      Geldig vanaf (Artikel 111):<br>
          - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
          - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 26 - Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4350-1-1
      - source: Artikel 27 - Beoordeling van de gevolgen voor de grondrechten van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4433-1-1
      - source: Artikel 72 - Monitoring door aanbieders na het in de handel brengen en plan voor monitoring na het in de handel brengen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7075-1-1
      - source: Artikel 73 - Melding van ernstige incidenten
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7117-1-1
      - source: Artikel 79 - Procedure op nationaal niveau voor de omgang met AI-systemen die een risico vormen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7480-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
  - conclusionId: "13.0.3"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke van een niet-hoog-risico AI-systeem. Het AI-systeem moet voldoen aan transparantieverplichtingen."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
          - AI-geletterdheid (Artikel 4)<br>
          - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systemen (Artikel 50):<br>
          - gebruiksverantwoordelijken van een systeem voor het herkennen van emoties of een systeem voor biometrische categorisering informeren de daaraan blootgestelde natuurlijke personen over de werking van het systeem en verwerken de persoonsgegevens in overeenstemming met Verordening (EU) 2016/679, Verordening (EU) 2018/1725 en Richtlijn (EU) 2016/680, indien van toepassing<br>
          - gebruiksverantwoordelijken van een AI-systeem dat beeld-, audio- of videocontent genereert of bewerkt die een deepfake vormt, maken bekend dat de content kunstmatig is gegenereerd of gemanipuleerd. Wanneer de content deel uitmaakt van een kennelijk artistiek, creatief, satirisch, fictief of analoog werk of programma, zijn de transparantieverplichtingen beperkt tot de openbaarmaking van het bestaan van dergelijke gegenereerde of bewerkte content op een passende wijze die de weergave of het genot van het werk niet belemmert.<br><br>
      Geldig vanaf (Artikel 111):<br>
          - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
          - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 50 - Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5426-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
  - conclusionId: "13.0.4"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke van een niet-hoog-risico AI-systeem."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
          - AI-geletterdheid (Artikel 4)<br>
          - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Geldig vanaf (Artikel 111):<br>
          - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
          - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
  - conclusionId: "13.1.1"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke van een hoog-risico AI-systeem voor algemene doeleinden. Het AI-systeem moet voldoen aan transparantieverplichtingen."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
          - AI-geletterdheid (Artikel 4)<br>
          - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico (Artikel 26 en Artikel 27):<br>
        - het nemen van passende technische en organisatorische maatregelen om te waarborgen dat dergelijke systemen in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd worden gebruikt<br>
        - het opdragen van menselijk toezicht aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen<br>
        - het ervoor zorgen dat, voor zover de gebruikersverantwoordelijke controle heeft over de inputdata, de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico<br>
        - het monitoren van de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en in voorkomend geval het in kennis stellen van de aanbieders overeenkomstig Artikel 72.<br>
        - het bewaren van de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder controle van de gebruiksverantwoordelijke vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden<br>
        - voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico<br>
        - gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in Artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in Artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis<br>
        - indien van toepassing, gebruiken gebruiksverantwoordelijken van AI-systemen met een hoog risico de informatie die op grond van Artikel 13 van deze verordening wordt verstrekt om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren<br>
        - de gebruiksverantwoordelijke van een AI-systeem met een hoog risico voor biometrische identificatie op afstand verzoekt achteraf in het kader van een onderzoek waarbij gericht wordt gezocht naar een persoon die wordt verdacht van of veroordeeld is voor het plegen van een strafbaar feit, vooraf of zonder onnodige vertraging en uiterlijk 48 uur na het feit, om toestemming van een gerechtelijke instantie of administratieve instantie, van wie de beslissing bindend is en onderworpen is aan rechterlijke toetsing, voor het gebruik van dat systeem, behalve wanneer het wordt gebruikt voor de initiële identificatie van een potentiële verdachte op basis van objectieve en verifieerbare feiten die rechtstreeks verband houden met het strafbare feit. Elk gebruik wordt beperkt tot hetgeen strikt noodzakelijk is voor het onderzoek naar een specifiek strafbaar feit<br>
        - gebruiksverantwoordelijken van in bijlage III bedoelde AI-systemen met een hoog risico die beslissingen met betrekking tot natuurlijke personen nemen of helpen nemen, informeren de natuurlijke personen dat het AI-systeem met een hoog risico op hen wordt toegepast.<br>
        - gebruiksverantwoordelijken werken samen met de relevante bevoegde autoriteiten bij alle door deze autoriteiten genomen maatregelen met betrekking tot een AI-systeem met een hoog risico met het oog op de uitvoering van deze verordening.<br>
        - gebruiksverantwoordelijken die publiekrechtelijke organen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruikt in krediet/verzekering (bijlage III, 5, c en d) een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren (Artikel 27).<br><br>
      Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systemen (Artikel 50):<br>
          - gebruiksverantwoordelijken van een systeem voor het herkennen van emoties of een systeem voor biometrische categorisering informeren de daaraan blootgestelde natuurlijke personen over de werking van het systeem en verwerken de persoonsgegevens in overeenstemming met Verordening (EU) 2016/679, Verordening (EU) 2018/1725 en Richtlijn (EU) 2016/680, indien van toepassing<br>
          - gebruiksverantwoordelijken van een AI-systeem dat beeld-, audio- of videocontent genereert of bewerkt die een deepfake vormt, maken bekend dat de content kunstmatig is gegenereerd of gemanipuleerd. Wanneer de content deel uitmaakt van een kennelijk artistiek, creatief, satirisch, fictief of analoog werk of programma, zijn de transparantieverplichtingen beperkt tot de openbaarmaking van het bestaan van dergelijke gegenereerde of bewerkte content op een passende wijze die de weergave of het genot van het werk niet belemmert.<br><br>
      Geldig vanaf (Artikel 111):<br>
          - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
          - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 26 - Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4350-1-1
      - source: Artikel 27 - Beoordeling van de gevolgen voor de grondrechten van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4433-1-1
      - source: Artikel 50 - Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5426-1-1
      - source: Artikel 72 - Monitoring door aanbieders na het in de handel brengen en plan voor monitoring na het in de handel brengen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7075-1-1
      - source: Artikel 73 - Melding van ernstige incidenten
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7117-1-1
      - source: Artikel 79 - Procedure op nationaal niveau voor de omgang met AI-systemen die een risico vormen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7480-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
  - conclusionId: "13.1.2"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke van een hoog-risico AI-systeem voor algemene doeleinden."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
          - AI-geletterdheid (Artikel 4)<br>
          - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico (Artikel 26 en Artikel 27):<br>
        - het nemen van passende technische en organisatorische maatregelen om te waarborgen dat dergelijke systemen in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd worden gebruikt<br>
        - het opdragen van menselijk toezicht aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen<br>
        - het ervoor zorgen dat, voor zover de gebruikersverantwoordelijke controle heeft over de inputdata, de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico<br>
        - het monitoren van de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en in voorkomend geval het in kennis stellen van de aanbieders overeenkomstig Artikel 72.<br>
        - het bewaren van de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder controle van de gebruiksverantwoordelijke vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden<br>
        - voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico<br>
        - gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in Artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in Artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis<br>
        - indien van toepassing, gebruiken gebruiksverantwoordelijken van AI-systemen met een hoog risico de informatie die op grond van Artikel 13 van deze verordening wordt verstrekt om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren<br>
        - de gebruiksverantwoordelijke van een AI-systeem met een hoog risico voor biometrische identificatie op afstand verzoekt achteraf in het kader van een onderzoek waarbij gericht wordt gezocht naar een persoon die wordt verdacht van of veroordeeld is voor het plegen van een strafbaar feit, vooraf of zonder onnodige vertraging en uiterlijk 48 uur na het feit, om toestemming van een gerechtelijke instantie of administratieve instantie, van wie de beslissing bindend is en onderworpen is aan rechterlijke toetsing, voor het gebruik van dat systeem, behalve wanneer het wordt gebruikt voor de initiële identificatie van een potentiële verdachte op basis van objectieve en verifieerbare feiten die rechtstreeks verband houden met het strafbare feit. Elk gebruik wordt beperkt tot hetgeen strikt noodzakelijk is voor het onderzoek naar een specifiek strafbaar feit<br>
        - gebruiksverantwoordelijken van in bijlage III bedoelde AI-systemen met een hoog risico die beslissingen met betrekking tot natuurlijke personen nemen of helpen nemen, informeren de natuurlijke personen dat het AI-systeem met een hoog risico op hen wordt toegepast.<br>
        - gebruiksverantwoordelijken werken samen met de relevante bevoegde autoriteiten bij alle door deze autoriteiten genomen maatregelen met betrekking tot een AI-systeem met een hoog risico met het oog op de uitvoering van deze verordening.<br>
        - gebruiksverantwoordelijken die publiekrechtelijke organen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruikt in krediet/verzekering (bijlage III, 5, c en d) een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren (Artikel 27).<br><br>
      Geldig vanaf (Artikel 111):<br>
          - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
          - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 26 - Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4350-1-1
      - source: Artikel 27 - Beoordeling van de gevolgen voor de grondrechten van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4433-1-1
      - source: Artikel 72 - Monitoring door aanbieders na het in de handel brengen en plan voor monitoring na het in de handel brengen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7075-1-1
      - source: Artikel 73 - Melding van ernstige incidenten
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7117-1-1
      - source: Artikel 79 - Procedure op nationaal niveau voor de omgang met AI-systemen die een risico vormen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7480-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
  - conclusionId: "13.1.3"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke van een niet-hoog-risico AI-systeem voor algemene doeleinden. Het AI-systeem moet voldoen aan transparantieverplichtingen."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
          - AI-geletterdheid (Artikel 4)<br>
          - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systemen (Artikel 50):<br>
          - gebruiksverantwoordelijken van een systeem voor het herkennen van emoties of een systeem voor biometrische categorisering informeren de daaraan blootgestelde natuurlijke personen over de werking van het systeem en verwerken de persoonsgegevens in overeenstemming met Verordening (EU) 2016/679, Verordening (EU) 2018/1725 en Richtlijn (EU) 2016/680, indien van toepassing<br>
          - gebruiksverantwoordelijken van een AI-systeem dat beeld-, audio- of videocontent genereert of bewerkt die een deepfake vormt, maken bekend dat de content kunstmatig is gegenereerd of gemanipuleerd. Wanneer de content deel uitmaakt van een kennelijk artistiek, creatief, satirisch, fictief of analoog werk of programma, zijn de transparantieverplichtingen beperkt tot de openbaarmaking van het bestaan van dergelijke gegenereerde of bewerkte content op een passende wijze die de weergave of het genot van het werk niet belemmert.<br><br>
      Geldig vanaf (Artikel 111):<br>
          - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
          - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 50 - Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5426-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
  - conclusionId: "13.1.4"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke van een niet-hoog-risico AI-systeem voor algemene doeleinden."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
          - AI-geletterdheid (Artikel 4)<br>
          - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Geldig vanaf (Artikel 111 en Overweging 179):<br>
          - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
          - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
      - source: Overweging 179 - Ingangtreding verordening
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_179
  - conclusionId: "13.2.1"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke van een AI-model voor algemene doeleinden."
    obligation: "
      Verplichtingen voor alle AI-modellen voor algemene doeleinden:<br>
        - Praktijkcodes (Artikel 56)<br><br>
      Geldig vanaf (Artikel 111 en Overweging 179):<br>
      - Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br>
      - Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>
      Als gebruiksverantwoordelijke van een AI-model voor algemene doeleinden gelden er geen verplichtingen vanuit een mogelijk systeemrisico.
      Het is echter belangrijk om te realiseren dat als een AI-model voor algemene doeleinden verder wordt ontwikkeld het in een AI-systeem voor algemene doeleinden kan veranderen en er mogelijk minimale transparantieverplichtingen van toepassing zijn.
      Daarnaast kan het systeem, afhankelijk van de specifieke toepassing, als een hoog-risico AI-systeem worden geclassificeerd."
    sources:
      - source: Artikel 51 - Classificatie van AI-modellen voor algemene doeleinden als AI-modellen voor algemene doeleinden met een systeemrisico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5489-1-1
      - source: Artikel 56 - Praktijkcodes
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5788-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
      - source: Overweging 179 - Ingangtreding verordening
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_179


# Conclusies 14.0.1 tm 14.1.2 voor gebruiksverantwoordelijken && aanbieders
  - conclusionId: "14.0.0"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent aanbieder en gebruiksverantwoordelijke van een verboden AI-systeem."
    obligation: "Het AI-systeem moet van de markt worden gehaald en het gebruik ervan stop gezet. Let op: dit geldt vanaf 1 februari 2025."
    sources:
      - source: Artikel 5 - Verboden AI praktijken
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2816-1-1
  - conclusionId: "14.0.1"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke en aanbieder van een hoog-risico AI-systeem. Het AI-systeem moet voldoen aan transparantieverplichtingen."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
          - AI-geletterdheid (Artikel 4)<br>
          - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Verplichtingen voor aanbieder van een hoog risico AI-systeem (Artikel 16):<br>
          - aanbieders zorgen ervoor dat hun AI-systemen met een hoog risico in overeenstemming zijn met de eisen van afdeling 2<br>
          - aanbieders vermelden op het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, naargelang het geval, hun naam, geregistreerde handelsnaam of geregistreerd merk en hun contactadres<br>
          - aanbieders beschikken over een systeem voor kwaliteitsbeheer dat in overeenstemming is met Artikel 17 (systeem voor kwaliteitsbeheer)<br>
          - aanbieders bewaren de in Artikel 18 (bewaring van documentatie) bedoelde documentatie<br>
          - aanbieders bewaren de in Artikel 19 bedoelde logs die automatisch door hun AI-systemen met een hoog risico zijn gegenereerd, wanneer zij hierover de controle hebben<br>
          - aanbieders zorgen ervoor dat voor het AI-systeem met een hoog risico de desbetreffende in Artikel 43 bedoelde conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld<br>
          - aanbieders stellen een EU-conformiteitsverklaring op, in overeenstemming met Artikel 47. In het geval van het label 'beoordeling door derde partij' dient de uitvoering door een conformiteitsbeoordelingsinstantie te worden verzorgd. In het geval dat het AI-systeem gebruikmaakt van biometrie en wordt ingezet door rechtshandhavingsinstanties, immigratie- of asielautoriteiten, of door instellingen, organen of instanties van de Unie, treedt de markttoezichtautoriteit op als conformiteitsbeoordelingsinstantie. <br>
          - aanbieders brengen de CE-markering aan op het Ai-systeem met een hoog risico of, waneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan deze verordening is voldaan, overeenkomstig Artikel 48<br>
          - aanbieders leven de registratieverplichtingen als bedoeld in Artikel 49 lid 1, na<br>
          - aanbieders nemen de noodzakelijke corrigerende maatregelen en verstrekken de uit hoofde van Artikel 20 vereiste informatie<br>
          - aanbieders tonen op een met redenen omkleed verzoek van een nationale bevoegde autoriteit de overeenstemming aan van het AI-systeem met een hoog risico met de eisen van afdeling 2<br>
          - aanbieders zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882.<br><br>
      Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico (Artikel 26 en Artikel 27):<br>
        - het nemen van passende technische en organisatorische maatregelen om te waarborgen dat dergelijke systemen in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd worden gebruikt<br>
        - het opdragen van menselijk toezicht aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen<br>
        - het ervoor zorgen dat, voor zover de gebruikersverantwoordelijke controle heeft over de inputdata, de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico<br>
        - het monitoren van de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en in voorkomend geval het in kennis stellen van de aanbieders overeenkomstig Artikel 72.<br>
        - het bewaren van de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder controle van de gebruiksverantwoordelijke vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden<br>
        - voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico<br>
        - gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in Artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in Artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis<br>
        - indien van toepassing, gebruiken gebruiksverantwoordelijken van AI-systemen met een hoog risico de informatie die op grond van Artikel 13 van deze verordening wordt verstrekt om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren<br>
        - de gebruiksverantwoordelijke van een AI-systeem met een hoog risico voor biometrische identificatie op afstand verzoekt achteraf in het kader van een onderzoek waarbij gericht wordt gezocht naar een persoon die wordt verdacht van of veroordeeld is voor het plegen van een strafbaar feit, vooraf of zonder onnodige vertraging en uiterlijk 48 uur na het feit, om toestemming van een gerechtelijke instantie of administratieve instantie, van wie de beslissing bindend is en onderworpen is aan rechterlijke toetsing, voor het gebruik van dat systeem, behalve wanneer het wordt gebruikt voor de initiële identificatie van een potentiële verdachte op basis van objectieve en verifieerbare feiten die rechtstreeks verband houden met het strafbare feit. Elk gebruik wordt beperkt tot hetgeen strikt noodzakelijk is voor het onderzoek naar een specifiek strafbaar feit<br>
        - gebruiksverantwoordelijken van in bijlage III bedoelde AI-systemen met een hoog risico die beslissingen met betrekking tot natuurlijke personen nemen of helpen nemen, informeren de natuurlijke personen dat het AI-systeem met een hoog risico op hen wordt toegepast.<br>
        - gebruiksverantwoordelijken werken samen met de relevante bevoegde autoriteiten bij alle door deze autoriteiten genomen maatregelen met betrekking tot een AI-systeem met een hoog risico met het oog op de uitvoering van deze verordening.<br>
        - gebruiksverantwoordelijken die publiekrechtelijke organen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruikt in krediet/verzekering (bijlage III, 5, c en d) een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren (Artikel 27).<br><br>
      Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systemen (Artikel 50):<br>
          - gebruiksverantwoordelijken van een systeem voor het herkennen van emoties of een systeem voor biometrische categorisering informeren de daaraan blootgestelde natuurlijke personen over de werking van het systeem en verwerken de persoonsgegevens in overeenstemming met Verordening (EU) 2016/679, Verordening (EU) 2018/1725 en Richtlijn (EU) 2016/680, indien van toepassing<br>
          - gebruiksverantwoordelijken van een AI-systeem dat beeld-, audio- of videocontent genereert of bewerkt die een deepfake vormt, maken bekend dat de content kunstmatig is gegenereerd of gemanipuleerd. Wanneer de content deel uitmaakt van een kennelijk artistiek, creatief, satirisch, fictief of analoog werk of programma, zijn de transparantieverplichtingen beperkt tot de openbaarmaking van het bestaan van dergelijke gegenereerde of bewerkte content op een passende wijze die de weergave of het genot van het werk niet belemmert.<br><br>
      Geldig vanaf (Artikel 111):<br>
          - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
          - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
    sources:
      - source: Afdeling 2 - Eisen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#cpt_III.sct_2
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 16 - Verplichtingen van aanbieders van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3823-1-1
      - source: Artikel 17 - Systeem voor kwaliteitsbeheer
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3906-1-1
      - source: Artikel 18 - Bewaring van documentatie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4013-1-1
      - source: Artikel 19 - Automatisch gegenereerde logs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4066-1-1
      - source: Artikel 20 - Corrigerende maatregelen en mededelingsverplichting
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4082-1-1
      - source: Artikel 26 - Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4350-1-1
      - source: Artikel 27 - Beoordeling van de gevolgen voor de grondrechten van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4433-1-1
      - source: Artikel 43 - Conformiteitsbeoordeling
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5074-1-1
      - source: Artikel 47 - EU-conformiteitsverklaring
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5296-1-1
      - source: Artikel 48 - CE-markering
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5327-1-1
      - source: Artikel 49 - Registratie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5358-1-1
      - source: Artikel 50 - Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5426-1-1
      - source: Artikel 72 - Monitoring door aanbieders na het in de handel brengen en plan voor monitoring na het in de handel brengen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7075-1-1
      - source: Artikel 73 - Melding van ernstige incidenten
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7117-1-1
      - source: Artikel 79 - Procedure op nationaal niveau voor de omgang met AI-systemen die een risico vormen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7480-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
  - conclusionId: "14.0.2"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke en aanbieder van een hoog-risico AI-systeem."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
          - AI-geletterdheid (Artikel 4)<br>
          - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Verplichtingen voor aanbieder van een hoog risico AI-systeem (Artikel 16):<br>
          - aanbieders zorgen ervoor dat hun AI-systemen met een hoog risico in overeenstemming zijn met de eisen van afdeling 2<br>
          - aanbieders vermelden op het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, naargelang het geval, hun naam, geregistreerde handelsnaam of geregistreerd merk en hun contactadres<br>
          - aanbieders beschikken over een systeem voor kwaliteitsbeheer dat in overeenstemming is met Artikel 17 (systeem voor kwaliteitsbeheer)<br>
          - aanbieders bewaren de in Artikel 18 (bewaring van documentatie) bedoelde documentatie<br>
          - aanbieders bewaren de in Artikel 19 bedoelde logs die automatisch door hun AI-systemen met een hoog risico zijn gegenereerd, wanneer zij hierover de controle hebben<br>
          - aanbieders zorgen ervoor dat voor het AI-systeem met een hoog risico de desbetreffende in Artikel 43 bedoelde conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld<br>
          - aanbieders stellen een EU-conformiteitsverklaring op, in overeenstemming met Artikel 47. In het geval van het label 'beoordeling door derde partij' dient de uitvoering door een conformiteitsbeoordelingsinstantie te worden verzorgd. In het geval dat het AI-systeem gebruikmaakt van biometrie en wordt ingezet door rechtshandhavingsinstanties, immigratie- of asielautoriteiten, of door instellingen, organen of instanties van de Unie, treedt de markttoezichtautoriteit op als conformiteitsbeoordelingsinstantie. <br>
          - aanbieders brengen de CE-markering aan op het Ai-systeem met een hoog risico of, waneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan deze verordening is voldaan, overeenkomstig Artikel 48<br>
          - aanbieders leven de registratieverplichtingen als bedoeld in Artikel 49 lid 1, na<br>
          - aanbieders nemen de noodzakelijke corrigerende maatregelen en verstrekken de uit hoofde van Artikel 20 vereiste informatie<br>
          - aanbieders tonen op een met redenen omkleed verzoek van een nationale bevoegde autoriteit de overeenstemming aan van het AI-systeem met een hoog risico met de eisen van afdeling 2<br>
          - aanbieders zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882.<br><br>
      Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico (Artikel 26 en Artikel 27):<br>
        - het nemen van passende technische en organisatorische maatregelen om te waarborgen dat dergelijke systemen in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd worden gebruikt<br>
        - het opdragen van menselijk toezicht aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen<br>
        - het ervoor zorgen dat, voor zover de gebruikersverantwoordelijke controle heeft over de inputdata, de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico<br>
        - het monitoren van de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en in voorkomend geval het in kennis stellen van de aanbieders overeenkomstig Artikel 72.<br>
        - het bewaren van de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder controle van de gebruiksverantwoordelijke vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden<br>
        - voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico<br>
        - gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in Artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in Artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis<br>
        - indien van toepassing, gebruiken gebruiksverantwoordelijken van AI-systemen met een hoog risico de informatie die op grond van Artikel 13 van deze verordening wordt verstrekt om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren<br>
        - de gebruiksverantwoordelijke van een AI-systeem met een hoog risico voor biometrische identificatie op afstand verzoekt achteraf in het kader van een onderzoek waarbij gericht wordt gezocht naar een persoon die wordt verdacht van of veroordeeld is voor het plegen van een strafbaar feit, vooraf of zonder onnodige vertraging en uiterlijk 48 uur na het feit, om toestemming van een gerechtelijke instantie of administratieve instantie, van wie de beslissing bindend is en onderworpen is aan rechterlijke toetsing, voor het gebruik van dat systeem, behalve wanneer het wordt gebruikt voor de initiële identificatie van een potentiële verdachte op basis van objectieve en verifieerbare feiten die rechtstreeks verband houden met het strafbare feit. Elk gebruik wordt beperkt tot hetgeen strikt noodzakelijk is voor het onderzoek naar een specifiek strafbaar feit<br>
        - gebruiksverantwoordelijken van in bijlage III bedoelde AI-systemen met een hoog risico die beslissingen met betrekking tot natuurlijke personen nemen of helpen nemen, informeren de natuurlijke personen dat het AI-systeem met een hoog risico op hen wordt toegepast.<br>
        - gebruiksverantwoordelijken werken samen met de relevante bevoegde autoriteiten bij alle door deze autoriteiten genomen maatregelen met betrekking tot een AI-systeem met een hoog risico met het oog op de uitvoering van deze verordening.<br>
        - gebruiksverantwoordelijken die publiekrechtelijke organen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruikt in krediet/verzekering (bijlage III, 5, c en d) een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren (Artikel 27).<br><br>
      Geldig vanaf (Artikel 111):<br>
          - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
          - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
    sources:
      - source: Afdeling 2 - Eisen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#cpt_III.sct_2
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 16 - Verplichtingen van aanbieders van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3823-1-1
      - source: Artikel 17 - Systeem voor kwaliteitsbeheer
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3906-1-1
      - source: Artikel 18 - Bewaring van documentatie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4013-1-1
      - source: Artikel 19 - Automatisch gegenereerde logs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4066-1-1
      - source: Artikel 20 - Corrigerende maatregelen en mededelingsverplichting
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4082-1-1
      - source: Artikel 26 - Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4350-1-1
      - source: Artikel 27 - Beoordeling van de gevolgen voor de grondrechten van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4433-1-1
      - source: Artikel 43 - Conformiteitsbeoordeling
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5074-1-1
      - source: Artikel 47 - EU-conformiteitsverklaring
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5296-1-1
      - source: Artikel 48 - CE-markering
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5327-1-1
      - source: Artikel 49 - Registratie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5358-1-1
      - source: Artikel 72 - Monitoring door aanbieders na het in de handel brengen en plan voor monitoring na het in de handel brengen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7075-1-1
      - source: Artikel 73 - Melding van ernstige incidenten
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7117-1-1
      - source: Artikel 79 - Procedure op nationaal niveau voor de omgang met AI-systemen die een risico vormen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7480-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
  - conclusionId: "14.0.3"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke en aanbieder van een niet-hoog-risico AI-systeem. Het AI-systeem moet voldoen aan transparantieverplichtingen."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
          - AI-geletterdheid (Artikel 4)<br>
          - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systemen (Artikel 50):<br>
          - gebruiksverantwoordelijken van een systeem voor het herkennen van emoties of een systeem voor biometrische categorisering informeren de daaraan blootgestelde natuurlijke personen over de werking van het systeem en verwerken de persoonsgegevens in overeenstemming met Verordening (EU) 2016/679, Verordening (EU) 2018/1725 en Richtlijn (EU) 2016/680, indien van toepassing<br>
          - gebruiksverantwoordelijken van een AI-systeem dat beeld-, audio- of videocontent genereert of bewerkt die een deepfake vormt, maken bekend dat de content kunstmatig is gegenereerd of gemanipuleerd. Wanneer de content deel uitmaakt van een kennelijk artistiek, creatief, satirisch, fictief of analoog werk of programma, zijn de transparantieverplichtingen beperkt tot de openbaarmaking van het bestaan van dergelijke gegenereerde of bewerkte content op een passende wijze die de weergave of het genot van het werk niet belemmert.<br><br>
      Geldig vanaf (Artikel 111):<br>
          - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
          - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 50 - Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5426-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
  - conclusionId: "14.0.4"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke en aanbieder van een niet-hoog-risico AI-systeem."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
          - AI-geletterdheid (Artikel 4)<br>
          - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Geldig vanaf (Artikel 111):<br>
          - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
          - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
  - conclusionId: "14.1.1"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke en aanbieder van een hoog-risico AI-systeem voor algemene doeleinden. Het AI-systeem moet voldoen aan transparantieverplichtingen."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
          - AI-geletterdheid (Artikel 4)<br>
          - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Verplichtingen voor aanbieder van een hoog risico AI-systeem (Artikel 16):<br>
          - aanbieders zorgen ervoor dat hun AI-systemen met een hoog risico in overeenstemming zijn met de eisen van afdeling 2<br>
          - aanbieders vermelden op het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, naargelang het geval, hun naam, geregistreerde handelsnaam of geregistreerd merk en hun contactadres<br>
          - aanbieders beschikken over een systeem voor kwaliteitsbeheer dat in overeenstemming is met Artikel 17 (systeem voor kwaliteitsbeheer)<br>
          - aanbieders bewaren de in Artikel 18 (bewaring van documentatie) bedoelde documentatie<br>
          - aanbieders bewaren de in Artikel 19 bedoelde logs die automatisch door hun AI-systemen met een hoog risico zijn gegenereerd, wanneer zij hierover de controle hebben<br>
          - aanbieders zorgen ervoor dat voor het AI-systeem met een hoog risico de desbetreffende in Artikel 43 bedoelde conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld<br>
          - aanbieders stellen een EU-conformiteitsverklaring op, in overeenstemming met Artikel 47. In het geval van het label 'beoordeling door derde partij' dient de uitvoering door een conformiteitsbeoordelingsinstantie te worden verzorgd. In het geval dat het AI-systeem gebruikmaakt van biometrie en wordt ingezet door rechtshandhavingsinstanties, immigratie- of asielautoriteiten, of door instellingen, organen of instanties van de Unie, treedt de markttoezichtautoriteit op als conformiteitsbeoordelingsinstantie. <br>
          - aanbieders brengen de CE-markering aan op het Ai-systeem met een hoog risico of, waneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan deze verordening is voldaan, overeenkomstig Artikel 48<br>
          - aanbieders leven de registratieverplichtingen als bedoeld in Artikel 49 lid 1, na<br>
          - aanbieders nemen de noodzakelijke corrigerende maatregelen en verstrekken de uit hoofde van Artikel 20 vereiste informatie<br>
          - aanbieders tonen op een met redenen omkleed verzoek van een nationale bevoegde autoriteit de overeenstemming aan van het AI-systeem met een hoog risico met de eisen van afdeling 2<br>
          - aanbieders zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882.<br><br>
      Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico (Artikel 26 en Artikel 27):<br>
        - het nemen van passende technische en organisatorische maatregelen om te waarborgen dat dergelijke systemen in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd worden gebruikt<br>
        - het opdragen van menselijk toezicht aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen<br>
        - het ervoor zorgen dat, voor zover de gebruikersverantwoordelijke controle heeft over de inputdata, de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico<br>
        - het monitoren van de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en in voorkomend geval het in kennis stellen van de aanbieders overeenkomstig Artikel 72.<br>
        - het bewaren van de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder controle van de gebruiksverantwoordelijke vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden<br>
        - voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico<br>
        - gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in Artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in Artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis<br>
        - indien van toepassing, gebruiken gebruiksverantwoordelijken van AI-systemen met een hoog risico de informatie die op grond van Artikel 13 van deze verordening wordt verstrekt om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren<br>
        - de gebruiksverantwoordelijke van een AI-systeem met een hoog risico voor biometrische identificatie op afstand verzoekt achteraf in het kader van een onderzoek waarbij gericht wordt gezocht naar een persoon die wordt verdacht van of veroordeeld is voor het plegen van een strafbaar feit, vooraf of zonder onnodige vertraging en uiterlijk 48 uur na het feit, om toestemming van een gerechtelijke instantie of administratieve instantie, van wie de beslissing bindend is en onderworpen is aan rechterlijke toetsing, voor het gebruik van dat systeem, behalve wanneer het wordt gebruikt voor de initiële identificatie van een potentiële verdachte op basis van objectieve en verifieerbare feiten die rechtstreeks verband houden met het strafbare feit. Elk gebruik wordt beperkt tot hetgeen strikt noodzakelijk is voor het onderzoek naar een specifiek strafbaar feit<br>
        - gebruiksverantwoordelijken van in bijlage III bedoelde AI-systemen met een hoog risico die beslissingen met betrekking tot natuurlijke personen nemen of helpen nemen, informeren de natuurlijke personen dat het AI-systeem met een hoog risico op hen wordt toegepast.<br>
        - gebruiksverantwoordelijken werken samen met de relevante bevoegde autoriteiten bij alle door deze autoriteiten genomen maatregelen met betrekking tot een AI-systeem met een hoog risico met het oog op de uitvoering van deze verordening.<br>
        - gebruiksverantwoordelijken die publiekrechtelijke organen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruikt in krediet/verzekering (bijlage III, 5, c en d) een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren (Artikel 27).<br><br>
      Verplichtingen voor aanbieders en gebruiksverantwoordelijken van AI-systemen met transparantieverplichtingen (Artikel 50):<br>
          - aanbieders zorgen ervoor dat AI-systemen die voor directe interactie met natuurlijke personen zijn bedoeld, zodanig worden ontworpen en ontwikkeld
            dat de betrokken natuurlijke personen worden geinformeerd dat zij interageren met een AI-systeem, tenzij dit duidelijk is vanuit het oogpunt van een normaal geinformeerde
            en redelijk omzichtige en oplettende natuurlijke persoon, rekening houdend met de omstandigheden en de gebruikscontext.<br>
          - aanbieders van (GP)AI-systemen, die synthetische audio, beeld, video- of tekstinhoud genereren, zorgen ervoor dat de outputs van het AI-systeem worden
            gemarkeerd in een machineleesbaar formaat en detecteerbaar zijn als kunstmatig gegenereerd of gemanipuleerd. Aanbieders zorgen ervoor dat hun technische oplossingen doeltreffend, interoperabel
            robuust en betrouwbaar zijn voor zover dat technisch haalbaar is, rekening houdend met de specifieke kenmerken en beperkingen van de verschillende soorten content, de uitvoeringskosten
            en de algemeen erkende stand van de techniek, zoals tot uiting kan komen in relevante technische normen.<br><br>
      Geldig vanaf (Artikel 111):<br>
          - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
          - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>
      De volgende verplichtingen gelden voor de aanbieder van het AI-model voor algemene doeleinden, waarop het AI-systeem voor algemene doeleinden is gebaseerd (Artikel 53 en Artikel 54):<br>
      - de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan<br>
      - informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren<br>
      - beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën<br>
      - een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br>
      Geldig vanaf (Artikel 111 en Overweging 179):<br>
      - Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br>
      - Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
    sources:
      - source: Afdeling 2 - Eisen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#cpt_III.sct_2
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 16 - Verplichtingen van aanbieders van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3823-1-1
      - source: Artikel 17 - Systeem voor kwaliteitsbeheer
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3906-1-1
      - source: Artikel 18 - Bewaring van documentatie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4013-1-1
      - source: Artikel 19 - Automatisch gegenereerde logs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4066-1-1
      - source: Artikel 20 - Corrigerende maatregelen en mededelingsverplichting
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4082-1-1
      - source: Artikel 26 - Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4350-1-1
      - source: Artikel 27 - Beoordeling van de gevolgen voor de grondrechten van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4433-1-1
      - source: Artikel 43 - Conformiteitsbeoordeling
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5074-1-1
      - source: Artikel 47 - EU-conformiteitsverklaring
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5296-1-1
      - source: Artikel 48 - CE-markering
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5327-1-1
      - source: Artikel 49 - Registratie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5358-1-1
      - source: Artikel 50 - Transparantieverplichting
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5426-1-1
      - source: Artikel 53 - Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5576-1-1
      - source: Artikel 54 - Gemachtigden van aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5657-1-1
      - source: Artikel 72 - Monitoring door aanbieders na het in de handel brengen en plan voor monitoring na het in de handel brengen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7075-1-1
      - source: Artikel 73 - Melding van ernstige incidenten
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7117-1-1
      - source: Artikel 79 - Procedure op nationaal niveau voor de omgang met AI-systemen die een risico vormen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7480-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
      - source: Overweging 179 - Ingangtreding verordening
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_179
  - conclusionId: "14.1.2"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke en aanbieder van een hoog-risico AI-systeem voor algemene doeleinden."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
          - AI-geletterdheid (Artikel 4)<br>
          - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Verplichtingen voor aanbieder van een hoog risico AI-systeem (Artikel 16):<br>
          - aanbieders zorgen ervoor dat hun AI-systemen met een hoog risico in overeenstemming zijn met de eisen van afdeling 2<br>
          - aanbieders vermelden op het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, naargelang het geval, hun naam, geregistreerde handelsnaam of geregistreerd merk en hun contactadres<br>
          - aanbieders beschikken over een systeem voor kwaliteitsbeheer dat in overeenstemming is met Artikel 17 (systeem voor kwaliteitsbeheer)<br>
          - aanbieders bewaren de in Artikel 18 (bewaring van documentatie) bedoelde documentatie<br>
          - aanbieders bewaren de in Artikel 19 bedoelde logs die automatisch door hun AI-systemen met een hoog risico zijn gegenereerd, wanneer zij hierover de controle hebben<br>
          - aanbieders zorgen ervoor dat voor het AI-systeem met een hoog risico de desbetreffende in Artikel 43 bedoelde conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld<br>
          - aanbieders stellen een EU-conformiteitsverklaring op, in overeenstemming met Artikel 47. In het geval van het label 'beoordeling door derde partij' dient de uitvoering door een conformiteitsbeoordelingsinstantie te worden verzorgd. In het geval dat het AI-systeem gebruikmaakt van biometrie en wordt ingezet door rechtshandhavingsinstanties, immigratie- of asielautoriteiten, of door instellingen, organen of instanties van de Unie, treedt de markttoezichtautoriteit op als conformiteitsbeoordelingsinstantie. <br>
          - aanbieders brengen de CE-markering aan op het Ai-systeem met een hoog risico of, waneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan deze verordening is voldaan, overeenkomstig Artikel 48<br>
          - aanbieders leven de registratieverplichtingen als bedoeld in Artikel 49 lid 1, na<br>
          - aanbieders nemen de noodzakelijke corrigerende maatregelen en verstrekken de uit hoofde van Artikel 20 vereiste informatie<br>
          - aanbieders tonen op een met redenen omkleed verzoek van een nationale bevoegde autoriteit de overeenstemming aan van het AI-systeem met een hoog risico met de eisen van afdeling 2<br>
          - aanbieders zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882.<br><br>
      Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico (Artikel 26 en Artikel 27):<br>
        - het nemen van passende technische en organisatorische maatregelen om te waarborgen dat dergelijke systemen in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd worden gebruikt<br>
        - het opdragen van menselijk toezicht aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen<br>
        - het ervoor zorgen dat, voor zover de gebruikersverantwoordelijke controle heeft over de inputdata, de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico<br>
        - het monitoren van de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en in voorkomend geval het in kennis stellen van de aanbieders overeenkomstig Artikel 72.<br>
        - het bewaren van de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder controle van de gebruiksverantwoordelijke vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden<br>
        - voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico<br>
        - gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in Artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in Artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis<br>
        - indien van toepassing, gebruiken gebruiksverantwoordelijken van AI-systemen met een hoog risico de informatie die op grond van Artikel 13 van deze verordening wordt verstrekt om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren<br>
        - de gebruiksverantwoordelijke van een AI-systeem met een hoog risico voor biometrische identificatie op afstand verzoekt achteraf in het kader van een onderzoek waarbij gericht wordt gezocht naar een persoon die wordt verdacht van of veroordeeld is voor het plegen van een strafbaar feit, vooraf of zonder onnodige vertraging en uiterlijk 48 uur na het feit, om toestemming van een gerechtelijke instantie of administratieve instantie, van wie de beslissing bindend is en onderworpen is aan rechterlijke toetsing, voor het gebruik van dat systeem, behalve wanneer het wordt gebruikt voor de initiële identificatie van een potentiële verdachte op basis van objectieve en verifieerbare feiten die rechtstreeks verband houden met het strafbare feit. Elk gebruik wordt beperkt tot hetgeen strikt noodzakelijk is voor het onderzoek naar een specifiek strafbaar feit<br>
        - gebruiksverantwoordelijken van in bijlage III bedoelde AI-systemen met een hoog risico die beslissingen met betrekking tot natuurlijke personen nemen of helpen nemen, informeren de natuurlijke personen dat het AI-systeem met een hoog risico op hen wordt toegepast.<br>
        - gebruiksverantwoordelijken werken samen met de relevante bevoegde autoriteiten bij alle door deze autoriteiten genomen maatregelen met betrekking tot een AI-systeem met een hoog risico met het oog op de uitvoering van deze verordening.<br>
        - gebruiksverantwoordelijken die publiekrechtelijke organen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruikt in krediet/verzekering (bijlage III, 5, c en d) een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren (Artikel 27).<br><br>
      Geldig vanaf (Artikel 111):<br>
          - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
          - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>
      De volgende verplichtingen gelden voor de aanbieder van het AI-model voor algemene doeleinden, waarop het AI-systeem voor algemene doeleinden is gebaseerd (Artikel 53 en Artikel 54):<br>
      - de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan<br>
      - informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren<br>
      - beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën<br>
      - een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br>
      Geldig vanaf (Artikel 111 en Overweging 179):<br>
      - Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br>
      - Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
    sources:
      - source: Afdeling 2 - Eisen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#cpt_III.sct_2
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 16 - Verplichtingen van aanbieders van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3823-1-1
      - source: Artikel 17 - Systeem voor kwaliteitsbeheer
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3906-1-1
      - source: Artikel 18 - Bewaring van documentatie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4013-1-1
      - source: Artikel 19 - Automatisch gegenereerde logs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4066-1-1
      - source: Artikel 20 - Corrigerende maatregelen en mededelingsverplichting
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4082-1-1
      - source: Artikel 26 - Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4350-1-1
      - source: Artikel 27 - Beoordeling van de gevolgen voor de grondrechten van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4433-1-1
      - source: Artikel 43 - Conformiteitsbeoordeling
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5074-1-1
      - source: Artikel 47 - EU-conformiteitsverklaring
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5296-1-1
      - source: Artikel 48 - CE-markering
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5327-1-1
      - source: Artikel 49 - Registratie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5358-1-1
      - source: Artikel 53 - Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5576-1-1
      - source: Artikel 54 - Gemachtigden van aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5657-1-1
      - source: Artikel 72 - Monitoring door aanbieders na het in de handel brengen en plan voor monitoring na het in de handel brengen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7075-1-1
      - source: Artikel 73 - Melding van ernstige incidenten
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7117-1-1
      - source: Artikel 79 - Procedure op nationaal niveau voor de omgang met AI-systemen die een risico vormen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7480-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
      - source: Overweging 179 - Ingangtreding verordening
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_179
  - conclusionId: "14.1.3"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke en aanbieder van een niet-hoog-risico AI-systeem voor algemene doeleinden.  Het AI-systeem moet voldoen aan transparantieverplichtingen."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
          - AI-geletterdheid (Artikel 4)<br>
          - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Verplichtingen voor aanbieders en gebruiksverantwoordelijken van AI-systemen met transparantieverplichtingen (Artikel 50):<br>
          - aanbieders zorgen ervoor dat AI-systemen die voor directe interactie met natuurlijke personen zijn bedoeld, zodanig worden ontworpen en ontwikkeld
            dat de betrokken natuurlijke personen worden geinformeerd dat zij interageren met een AI-systeem, tenzij dit duidelijk is vanuit het oogpunt van een normaal geinformeerde
            en redelijk omzichtige en oplettende natuurlijke persoon, rekening houdend met de omstandigheden en de gebruikscontext.<br>
          - aanbieders van (GP)AI-systemen, die synthetische audio, beeld, video- of tekstinhoud genereren, zorgen ervoor dat de outputs van het AI-systeem worden
            gemarkeerd in een machineleesbaar formaat en detecteerbaar zijn als kunstmatig gegenereerd of gemanipuleerd. Aanbieders zorgen ervoor dat hun technische oplossingen doeltreffend, interoperabel
            robuust en betrouwbaar zijn voor zover dat technisch haalbaar is, rekening houdend met de specifieke kenmerken en beperkingen van de verschillende soorten content, de uitvoeringskosten
            en de algemeen erkende stand van de techniek, zoals tot uiting kan komen in relevante technische normen.<br><br>
      Geldig vanaf (Artikel 111):<br>
          - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
          - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>
      De volgende verplichtingen gelden voor de aanbieder van het AI-model voor algemene doeleinden, waarop het AI-systeem voor algemene doeleinden is gebaseerd (Artikel 53 en Artikel 54):<br>
      - de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan<br>
      - informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren<br>
      - beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën<br>
      - een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br>
      Geldig vanaf (Artikel 111 en Overweging 179):<br>
      - Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br>
      - Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 50 - Transparantieverplichting
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5426-1-1
      - source: Artikel 53 - Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5576-1-1
      - source: Artikel 54 - Gemachtigden van aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5657-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
      - source: Overweging 179 - Ingangtreding verordening
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_179
  - conclusionId: "14.1.4"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een gebruiksverantwoordelijke en aanbieder van een niet-hoog-risico AI-systeem voor algemene doeleinden."
    obligation: "
      Verplichtingen voor alle AI-systemen:<br>
          - AI-geletterdheid (Artikel 4)<br>
          - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften (Artikel 95)<br>
      Geldig vanaf:<br>
          - AI-geletterdheid (Artikel 4) gaat vanaf februari 2025 in werking.<br>
          - Gedragscodes (Artikel 95) zijn vrijwillig en kunnen op elk moment na de inwerkingtreding van de AI-verordening worden opgesteld en toegepast.<br><br>
      Geldig vanaf (Artikel 111):<br>
          - Voor AI-systemen in ontwikkeling geldt dat de verordening volledig in werking treedt op 2 augustus 2026, wat betekent dat deze systemen vanaf die datum aan de voorschriften moeten voldoen.<br>
          - Voor AI-systemen in gebruik die vóór 2 augustus 2026 zijn geïntroduceerd, geldt dat de verordening alleen van toepassing is als ze significante wijzigingen ondergaan, maar voor AI-systemen met een hoog risico, met name die bedoeld voor overheidsgebruik, moeten aanbieders uiterlijk op 2 augustus 2030 aan alle vereisten voldoen, ongeacht ontwerpwijzigingen.<br><br>
      De volgende verplichtingen gelden voor de aanbieder van het AI-model voor algemene doeleinden, waarop het AI-systeem voor algemene doeleinden is gebaseerd (Artikel 53 en Artikel 54):<br>
      - de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan<br>
      - informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren<br>
      - beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën<br>
      - een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br>
      Geldig vanaf (Artikel 111 en Overweging 179):<br>
      - Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br>
      - Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 4 - AI-geletterdheid
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1
      - source: Artikel 53 - Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5576-1-1
      - source: Artikel 54 - Gemachtigden van aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5657-1-1
      - source: Artikel 95 - Gedragscodes voor vrijwillige toepassing van specifieke voorschriften
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8052-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
      - source: Overweging 179 - Ingangtreding verordening
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_179
  - conclusionId: "14.2.1"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder en gebruiksverantwoordelijke van een AI-model voor algemene doeleinden. Er is sprake van een systeemrisico."
    obligation: "
      Verplichtingen voor alle AI-modellen voor algemene doeleinden:<br>
        - Praktijkcodes (Artikel 56)<br><br>
      Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden (Artikel 53 en Artikel 54):<br>
      - de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan.<br>
      - informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.<br>
      - beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën.<br>
      - een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br><br>
      Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico (Artikel 55):<br>
      - het uitvoeren van een modelevaluatie overeenkomstig gestandaardiseerde protocollen en instrumenten die de stand van de techniek weerspiegelen, met inbegrip van het uitvoeren en documenteren van tests gericht op het ontdekken van kwetsbaarheden van het model met als doel om systeemrisico’s in kaart te brengen en te beperken.<br>
      - het beoordelen en beperken van mogelijke systeemrisico’s op Unieniveau, met inbegrip van de bronnen daarvan, die kunnen voortvloeien uit de ontwikkeling, het in de handel brengen of het gebruik van AI-modellen voor algemene doeleinden met een systeemrisico.<br>
      - het bijhouden, documenteren en onverwijld rapporteren (aan het AI-bureau (en in voorkomende gevallen aan de nationale bevoegde autoriteiten)) van relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen.<br>
      - het zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden en de fysieke infrastructuur van het model.<br><br>
      Geldig vanaf (Artikel 111 en Overweging 179):<br>
      - Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br>
      - Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 51 - Classificatie van AI-modellen voor algemene doeleinden als AI-modellen voor algemene doeleinden met een systeemrisico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5489-1-1
      - source: Artikel 53 - Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5576-1-1
      - source: Artikel 54 - Gemachtigden van aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5657-1-1
      - source: Artikel 55 - Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5730-1-1
      - source: Artikel 56 - Praktijkcodes
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5788-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
      - source: Overweging 179 - Ingangtreding verordening
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_179
  - conclusionId: "14.2.2"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder en gebruiksverantwoordelijke van een AI-model voor algemene doeleinden."
    obligation: "
      Verplichtingen voor alle AI-modellen voor algemene doeleinden:<br>
        - Praktijkcodes (Artikel 56)<br><br>
      Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden (Artikel 53 en Artikel 54):<br>
      - de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan.<br>
      - informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.<br>
      - Door overweging 104 voor open-source AI-modellen voor algemene doeleinden hoef je niet te voldoen aan: de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan.<br>
      - Door overweging 104 voor open-source AI-modellen voor algemene doeleinden hoef je niet te voldoen aan: informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.<br><br>
      Geldig vanaf (Artikel 111 en Overweging 179):<br>
      - Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br>
      - Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 51 - Classificatie van AI-modellen voor algemene doeleinden als AI-modellen voor algemene doeleinden met een systeemrisico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5489-1-1
      - source: Artikel 53 - Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5576-1-1
      - source: Artikel 54 - Gemachtigden van aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5657-1-1
      - source: Artikel 56 - Praktijkcodes
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5788-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
      - source: Overweging 179 - Ingangtreding verordening
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_179
  - conclusionId: "14.2.3"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een aanbieder en gebruiksverantwoordelijke van een AI-model voor algemene doeleinden."
    obligation: "
      Verplichtingen voor alle AI-modellen voor algemene doeleinden:<br>
        - Praktijkcodes (Artikel 56)<br><br>
      Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden (Artikel 53 en Artikel 54):<br>
      - de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan. <br>
      - informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren. <br>
      - beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën.<br>
      - een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.<br>
      Aangezien het geen open-source toepassing is, gelden er geen uitzonderingen. <br><br>
      Geldig vanaf (Artikel 111 en Overweging 179):<br>
      - Voor AI-modellen in ontwikkeling gelden de verplichtingen voor aanbieders van algemene AI-modellen, zoals taal- of beeldherkenningsmodellen, vanaf 2 augustus 2025.<br>
      - Voor AI-modellen in gebruik die vóór 2 augustus 2025 in de handel zijn gebracht, geldt dat zij uiterlijk op 2 augustus 2027 aan de verordening moeten voldoen, ook zonder significante ontwerpwijzigingen.<br><br>"
    sources:
      - source: Artikel 51 - Classificatie van AI-modellen voor algemene doeleinden als AI-modellen voor algemene doeleinden met een systeemrisico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5489-1-1
      - source: Artikel 53 - Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5576-1-1
      - source: Artikel 54 - Gemachtigden van aanbieders van AI-modellen voor algemene doeleinden
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5657-1-1
      - source: Artikel 56 - Praktijkcodes
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5788-1-1
      - source: Artikel 111 - Reeds in de handel gebrachte of in gebruik gestelde AI-systemen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e8928-1-1
      - source: Overweging 179 - Ingangtreding verordening
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#rct_179

## Conclusies voor importeur (13)
  - conclusionId: "15.0.0"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent importeur van een verboden AI-systeem."
    obligation: "Het AI-systeem moet van de markt worden gehaald en het gebruik ervan stop gezet. Let op: dit geldt vanaf 1 februari 2025."
    sources:
      - source: Artikel 5 - Verboden AI praktijken
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2816-1-1
  - conclusionId: "15.0.1"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een importeur van een AI-systeem een hoog risico."
    obligation: "
      Verplichtingen voor importeur van een hoog risico AI-systeem (Artikel 23):<br>
      - Importeurs zorgen ervoor dat een AI-systeem met een hoog risico in overeenstemming is met de verordening voordat het in de handel wordt gebracht door na te gaan of de relevante conformiteitsbeoordelingsprocedure is uitgevoerd (Artikel 43), de technische documentatie is opgesteld (Artikel 11 en bijlage IV), de CE-markering is aangebracht en de EU-conformiteitsverklaring en gebruiksaanwijzingen aanwezig zijn (Artikel 47), en of de aanbieder een gemachtigde heeft aangewezen (Artikel 22, lid 1).<br>
      - Indien een importeur vermoedt dat het AI-systeem met een hoog risico niet in overeenstemming is met de verordening, vervalst is of vergezeld gaat van vervalste documenten, mag het systeem niet in de handel worden gebracht totdat het aan de eisen voldoet. Als het systeem een risico vormt (Artikel 79, lid 1), moet de importeur de aanbieder, gemachtigden en markttoezichtautoriteiten informeren.<br>
      - Importeurs moeten hun naam, geregistreerde handelsnaam of merk en contactadres vermelden op de verpakking of in de bijgevoegde documentatie van het AI-systeem met een hoog risico.<br>
      - Importeurs zorgen ervoor dat de opslag- en vervoersomstandigheden van het AI-systeem met een hoog risico de naleving van de eisen van afdeling 2 niet in gevaar brengen.<br>
      - Importeurs moeten gedurende tien jaar een kopie bewaren van het door de aangemelde instantie afgegeven certificaat en, indien van toepassing, de gebruiksaanwijzing en de EU-conformiteitsverklaring (Artikel 47).<br>
      - Bij verzoek van bevoegde autoriteiten moeten importeurs alle benodigde informatie en documentatie verstrekken ter staving van de naleving van de eisen van afdeling 2, in een voor de autoriteit begrijpelijke taal.<br>
      - Importeurs werken samen met bevoegde autoriteiten bij het nemen van maatregelen om de risico’s van het AI-systeem te verminderen en te beperken.<br>"
    sources:
      - source: Afdeling 2 - Eisen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#cpt_III.sct_2
      - source: Artikel 11 - Technische documentatie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3472-1-1
      - source: Artikel 22 - Gemachtigden van aanbieders van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4119-1-1
      - source: Artikel 23 - Verplichtingen van importeurs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3823-1-1
      - source: Artikel 43 - Conformiteitsbeoordeling
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5074-1-1
      - source: Artikel 47 - EU-conformiteitsverklaring
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5296-1-1
      - source: Artikel 79 - Procedure op nationaal niveau voor de omgang met AI-systemen die een risico vormen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7480-1-1
  - conclusionId: "15.0.3"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een importeur van een niet-hoog-risico AI-systeem."
    obligation: "Er zijn geen verplichtingen voor importeurs van niet-hoog-risico AI-systemen, alleen voor hoog-risico. In de bronnen is Artikel 23 opgenomen, deze bevat de verplichtingen voor importeurs van hoog-risico AI-systemen ter informatie ter informatie."
    sources:
      - source: Artikel 23 - Verplichtingen van importeurs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3823-1-1
  - conclusionId: "15.1.1"
    conclusion: "Je bent een importeur van een hoog risico AI-systeem voor algemene doeleinden."
    obligation: "
      Verplichtingen voor importeur van een hoog risico AI-systeem (Artikel 23):<br>
      - Importeurs zorgen ervoor dat een AI-systeem met een hoog risico in overeenstemming is met de verordening voordat het in de handel wordt gebracht door na te gaan of de relevante conformiteitsbeoordelingsprocedure is uitgevoerd (Artikel 43), de technische documentatie is opgesteld (Artikel 11 en bijlage IV), de CE-markering is aangebracht en de EU-conformiteitsverklaring en gebruiksaanwijzingen aanwezig zijn (Artikel 47), en of de aanbieder een gemachtigde heeft aangewezen (Artikel 22, lid 1).<br>
      - Indien een importeur vermoedt dat het AI-systeem met een hoog risico niet in overeenstemming is met de verordening, vervalst is of vergezeld gaat van vervalste documenten, mag het systeem niet in de handel worden gebracht totdat het aan de eisen voldoet. Als het systeem een risico vormt (Artikel 79, lid 1), moet de importeur de aanbieder, gemachtigden en markttoezichtautoriteiten informeren.<br>
      - Importeurs moeten hun naam, geregistreerde handelsnaam of merk en contactadres vermelden op de verpakking of in de bijgevoegde documentatie van het AI-systeem met een hoog risico.<br>
      - Importeurs zorgen ervoor dat de opslag- en vervoersomstandigheden van het AI-systeem met een hoog risico de naleving van de eisen van afdeling 2 niet in gevaar brengen.<br>
      - Importeurs moeten gedurende tien jaar een kopie bewaren van het door de aangemelde instantie afgegeven certificaat en, indien van toepassing, de gebruiksaanwijzing en de EU-conformiteitsverklaring (Artikel 47).<br>
      - Bij verzoek van bevoegde autoriteiten moeten importeurs alle benodigde informatie en documentatie verstrekken ter staving van de naleving van de eisen van afdeling 2, in een voor de autoriteit begrijpelijke taal.<br>
      - Importeurs werken samen met bevoegde autoriteiten bij het nemen van maatregelen om de risico’s van het AI-systeem te verminderen en te beperken.<br>"
    sources:
      - source: Afdeling 2 - Eisen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#cpt_III.sct_2
      - source: Artikel 11 - Technische documentatie
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3472-1-1
      - source: Artikel 22 - Gemachtigden van aanbieders van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4119-1-1
      - source: Artikel 23 - Verplichtingen van importeurs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3823-1-1
      - source: Artikel 43 - Conformiteitsbeoordeling
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5074-1-1
      - source: Artikel 47 - EU-conformiteitsverklaring
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5296-1-1
      - source: Artikel 79 - Procedure op nationaal niveau voor de omgang met AI-systemen die een risico vormen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7480-1-1
  - conclusionId: "15.1.3"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een importeur van een niet-hoog-risico AI-systeem voor algemene doeleinden."
    obligation: "Er zijn geen verplichtingen voor importeurs van niet-hoog-risico AI-systemen voor algemene doeleinden, alleen voor hoog-risico. In de bronnen is Artikel 23 opgenomen, deze bevat de verplichtingen voor importeurs van hoog-risico AI-systemen ter informatie."
    sources:
      - source: Artikel 23 - Verplichtingen van importeurs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3823-1-1
  - conclusionId: "15.2.1"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een importeur van een AI-model voor algemene doeleinden."
    obligation: "Er zijn geen verplichtingen voor importeurs van AI-modellen voor algemene doeleinden, alleen voor hoog-risico AI-systemen. In de bronnen is Artikel 23 opgenomen, deze bevat de verplichtingen voor importeurs van hoog-risico AI-systemen ter informatie."
    sources:
      - source: Artikel 23 - Verplichtingen van importeurs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3823-1-1


## Conclusies voor distributeur (14)
  - conclusionId: "16.0.0"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent distributeur van een verboden AI-systeem."
    obligation: "Het AI-systeem moet van de markt worden gehaald en het gebruik ervan stop gezet. Let op: dit geldt vanaf 1 februari 2025."
    sources:
      - source: Artikel 5 - Verboden AI praktijken
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2816-1-1
  - conclusionId: "16.0.1"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een distributeur van een hoog-risico AI-systeem."
    obligation: "
      Verplichtingen voor distributeur van een hoog risico AI-systeem (Artikel 24):<br>
      - Distributeurs controleren of het AI-systeem met een hoog risico de vereiste CE-markering heeft, vergezeld gaat van de EU-conformiteitsverklaring en gebruiksinstructies, en of de aanbieder en importeur hun verplichtingen uit Artikel 16 (b en c) en Artikel 23 (3) hebben nageleefd.<br>
      - Wanneer een distributeur vermoedt dat een AI-systeem met een hoog risico niet voldoet aan de eisen, mag het systeem niet op de markt worden gebracht totdat het in overeenstemming is gebracht met de vereisten en de aanbieder of importeur moet worden geïnformeerd als het systeem een risico vormt (Artikel 79 (1)).<br>
      - Distributeurs zorgen ervoor dat de opslag- en vervoersomstandigheden van het AI-systeem met een hoog risico geen invloed hebben op de naleving van de eisen van afdeling 2.<br>
      - Wanneer een distributeur vermoedt dat een AI-systeem met een hoog risico niet voldoet aan de eisen na het op de markt te hebben gebracht, moet de distributeur corrigerende maatregelen nemen of zorgen dat de aanbieder/importeur dit doet, zoals het systeem uit de handel nemen of terugroepen, en de bevoegde autoriteiten informeren.<br>
      - Distributeurs moeten op verzoek van bevoegde autoriteiten de nodige informatie en documentatie verstrekken om aan te tonen dat het AI-systeem voldoet aan de eisen van afdeling 2.<br>
      - Distributeurs werken samen met de bevoegde autoriteiten met betrekking tot maatregelen die genomen worden om de risico's van het AI-systeem dat zij op de markt hebben aangeboden te verminderen of te beperken."
    sources:
      - source: Afdeling 2 - Eisen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#cpt_III.sct_2
      - source: Artikel 16 - Verplichtingen van aanbieders van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3823-1-1
      - source: Artikel 24 - Verplichtingen van distributeurs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4246-1-1
      - source: Artikel 23 - Verplichtingen van importeurs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3823-1-1
      - source: Artikel 79 - Procedure op nationaal niveau voor de omgang met AI-systemen die een risico vormen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7480-1-1
  - conclusionId: "16.0.3"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een distributeur van een niet-hoog-risico AI-systeem."
    obligation: "Er zijn geen verplichtingen voor distributeurs van niet-hoog-risico AI-systemen, alleen voor hoog-risico. In de bronnen is Artikel 24 opgenomen, deze bevat de verplichtingen voor distributeurs van hoog-risico AI-systemen ter informatie."
    sources:
      - source: Artikel 24 - Verplichtingen van distributeurs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4246-1-1
  - conclusionId: "16.1.1"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een distributeur van een hoog-risico AI-systeem voor algemene doeleinden."
    obligation: "
      Verplichtingen voor distributeur van een hoog risico AI-systeem (Artikel 24):<br>
      - Distributeurs controleren of het AI-systeem met een hoog risico de vereiste CE-markering heeft, vergezeld gaat van de EU-conformiteitsverklaring en gebruiksinstructies, en of de aanbieder en importeur hun verplichtingen uit Artikel 16 (b en c) en Artikel 23 (3) hebben nageleefd.<br>
      - Wanneer een distributeur vermoedt dat een AI-systeem met een hoog risico niet voldoet aan de eisen, mag het systeem niet op de markt worden gebracht totdat het in overeenstemming is gebracht met de vereisten en de aanbieder of importeur moet worden geïnformeerd als het systeem een risico vormt (Artikel 79 (1)).<br>
      - Distributeurs zorgen ervoor dat de opslag- en vervoersomstandigheden van het AI-systeem met een hoog risico geen invloed hebben op de naleving van de eisen van afdeling 2.<br>
      - Wanneer een distributeur vermoedt dat een AI-systeem met een hoog risico niet voldoet aan de eisen na het op de markt te hebben gebracht, moet de distributeur corrigerende maatregelen nemen of zorgen dat de aanbieder/importeur dit doet, zoals het systeem uit de handel nemen of terugroepen, en de bevoegde autoriteiten informeren.<br>
      - Distributeurs moeten op verzoek van bevoegde autoriteiten de nodige informatie en documentatie verstrekken om aan te tonen dat het AI-systeem voldoet aan de eisen van afdeling 2.<br>
      - Distributeurs werken samen met de bevoegde autoriteiten met betrekking tot maatregelen die genomen worden om de risico's van het AI-systeem dat zij op de markt hebben aangeboden te verminderen of te beperken."
    sources:
      - source: Afdeling 2 - Eisen voor AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#cpt_III.sct_2
      - source: Artikel 16 - Verplichtingen van aanbieders van AI-systemen met een hoog risico
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3823-1-1
      - source: Artikel 24 - Verplichtingen van distributeurs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4246-1-1
      - source: Artikel 23 - Verplichtingen van importeurs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3823-1-1
      - source: Artikel 79 - Procedure op nationaal niveau voor de omgang met AI-systemen die een risico vormen
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7480-1-1
  - conclusionId: "16.1.3"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een distributeur van een niet-hoog-risico AI-systeem voor algemene doeleinden."
    obligation: "Er zijn geen verplichtingen voor distributeurs van niet-hoog-risico AI-systemen, alleen voor hoog-risico. In de bronnen is Artikel 24 opgenomen, deze bevat de verplichtingen voor distributeurs van hoog-risico AI-systemen ter informatie."
    sources:
      - source: Artikel 24 - Verplichtingen van distributeurs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4246-1-1
  - conclusionId: "16.2.1"
    conclusion: "Op basis van de ingevulde antwoorden is de AI-verordening op jou van toepassing. Je bent een distributeur van een AI-model voor algemene doeleinden."
    obligation: "Er zijn geen verplichtingen voor distributeurs van AI-model voor algemene doeleinden, alleen voor hoog-risico AI-systemen. In de bronnen is Artikel 24 opgenomen, deze bevat de verplichtingen voor distributeurs van hoog-risico AI-systemen ter informatie."
    sources:
      - source: Artikel 24 - Verplichtingen van distributeurs
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4246-1-1


## COnclusies voor geen rol (15)
  - conclusionId: "11.0"
    conclusion: "Je hebt geantwoord dat er geen sprake is van een algoritme, hierdoor is de AI-verordening niet voor jou van toepassing. Op basis van je antwoorden is het niet nodig om door te gaan naar Stap 2 – bepalen risicogroep. "
    obligation: "Houd je aan bestaande wet- en regelgeving (bijv. AVG wanneer je persoonsgegevens verwerkt)."
  - conclusionId: "11.2"
    conclusion: "Op basis van jouw antwoorden op de vragen is de AI-verordening niet op jou van toepassing, omdat je een uitzonderingsgrond hebt geselecteerd."
    obligation: "Zorg ervoor dat het algoritme voldoet aan bestaande wet- en regelgeving (bijv. AVG wanneer het algoritme persoonsgegevens verwerkt). Verder dien je te registreren in het algoritmeregister."
    sources:
      - source: Artikel 2 - Toepassingsgebied
        url: https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e1978-1-1
  - conclusionId: "11.3"
    conclusion: "Op basis van jouw antwoorden op de vragen is de AI-verordening niet op jou van toepassing, omdat het algoritme niet valt onder de definitie van een AI-systeem of AI-model volgens de AI-verordening. Volgens de handreiking algoritmeregister is de toepassing een impactvol algoritme."
    obligation: "Omdat het een algoritme met impact betreft, dien je in algoritmeregister te publiceren. Zorg ervoor dat het algoritme voldoet aan bestaande wet- en regelgeving (bijv. AVG wanneer het algoritme persoonsgegevens verwerkt)."
    sources:
      - source: Handreiking Algoritmeregister
        url: https://www.digitaleoverheid.nl/wp-content/uploads/sites/8/2023/12/Handreiking-Algoritmeregister-versie-1.0.pdf
  - conclusionId: "11.4"
    conclusion: "Op basis van jouw antwoorden op de vragen is de AI-verordening niet op jou van toepassing, omdat het algoritme niet valt onder de definitie van een AI-systeem of AI-model volgens de AI-verordening. Volgens de handreiking algoritmeregister is de toepassing een impactvol algoritme en val je in de uitzonderingsgrond."
    obligation: "Je hoeft vanwege uitzonderingsgrond niet te publiceren in het algoritmeregister. Zorg ervoor dat het algoritme voldoet aan bestaande wet- en regelgeving (bijv. AVG wanneer het algoritme persoonsgegevens verwerkt)."
    sources:
      - source: Handreiking Algoritmeregister
        url: https://www.digitaleoverheid.nl/wp-content/uploads/sites/8/2023/12/Handreiking-Algoritmeregister-versie-1.0.pdf
  - conclusionId: "11.5"
    conclusion: "Op basis van jouw antwoorden op de vragen is de AI-verordening niet op jou van toepassing, omdat het algoritme niet valt onder de definitie van een AI-systeem of AI-model volgens de AI-verordening. Volgens de handreiking algoritmeregister is de toepassing geen impactvol algoritme."
    obligation: "Zorg ervoor dat het algoritme voldoet aan bestaande wet- en regelgeving (bijv. AVG wanneer het algoritme persoonsgegevens verwerkt)."
    sources:
      - source: Handreiking Algoritmeregister
        url: https://www.digitaleoverheid.nl/wp-content/uploads/sites/8/2023/12/Handreiking-Algoritmeregister-versie-1.0.pdf
  - conclusionId: "11.6"
    conclusion: "Op basis van jouw antwoorden op de vragen is de AI-verordening niet op jou van toepassing, omdat je geen aanbieder, gebruiksverantwoordelijke, importeur of distributeur bent. Controleer echter zorgvuldig of een van deze rollen mogelijk toch op jou van toepassing is."
    obligation: "Er is geen sprake van een verplichting."
